{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d3d2ac-3f5d-449d-851f-305f00686335",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "- htd on resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93857d92-bc9f-4532-93a1-6c34e0913e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "EXP_DIR = \"/home/fmokadem/NAS/tdcnn/\"\n",
    "sys.path.append(EXP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3741a15-e1ba-4944-97fd-2a98b7b62ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import models\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4466e8-95ac-425e-9cac-a56e502a5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.dataset import load_mnist\n",
    "from common._logging import setup_logger\n",
    "from common.utils import (\n",
    "    count_parameters, \n",
    "    measure_inference_time, \n",
    "    calculate_accuracy, \n",
    "    get_flops, \n",
    "    get_conv2d_layers,\n",
    "    infer_rank, \n",
    "    calculate_layer_params,\n",
    "    replace_conv2d_with_tucker,\n",
    "    fine_tune\n",
    ")\n",
    "from common.load_models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3a1b6c-41f3-49c7-8956-f89d578ac0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'vgg'\n",
    "FINETUNE = True\n",
    "MAX_CFG = 250\n",
    "ACCU_RQT = .90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970a0ecf-89d9-4a87-ba02-060ad4595493",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(EXP_DIR, f'finetuned/saved_models/{MODEL_NAME}16_mnist.pth')\n",
    "LOG_DIR = os.path.join(EXP_DIR, 'logs')\n",
    "LOG_PREFIX = 'htd_vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e247114-c0a4-4336-beba-8c8313bfa166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:21:14,427 - MainProcess - INFO - Logging to /home/fmokadem/NAS/tdcnn/logs/htd_vgg16_20250330_082114.log\n",
      "2025-03-30 08:21:14,428 - MainProcess - INFO - Starting HTD experiment for vgg\n"
     ]
    }
   ],
   "source": [
    "logger = setup_logger(LOG_PREFIX, LOG_DIR, LOG_PREFIX)\n",
    "logger.info(f\"Starting HTD experiment for {MODEL_NAME}\")\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad31f0a-d456-4517-b6e1-763e3c682ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:21:14,541 - MainProcess - INFO - Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# use gpu 0 only\n",
    "device_idx = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(device_idx)\n",
    "    device = f'cuda:{device_idx}'\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c051af6-9518-4d56-8ad1-d7a34f68dc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:21:14,647 - MainProcess - INFO - MNIST loaded: 60000 train, 10000 test samples\n",
      "/home/fmokadem/NAS/tdcnn/common/load_models.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_model = torch.load(model_path, map_location=device)\n",
      "2025-03-30 08:21:16,749 - MainProcess - INFO - Loaded vgg from /home/fmokadem/NAS/tdcnn/finetuned/saved_models/vgg16_mnist.pth\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_loader, test_loader = load_mnist()\n",
    "logger.info(f\"MNIST loaded: {len(train_loader.dataset)} train, {len(test_loader.dataset)} test samples\")\n",
    "\n",
    "# Load model\n",
    "model = load_model(MODEL_NAME, MODEL_PATH, device)\n",
    "logger.info(f\"Loaded {MODEL_NAME} from {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d58c92b-5c2c-468e-86f0-513cfb10487e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Grayscale(num_output_channels=3)\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b020e5d-9424-4990-b589-c05aa99042c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 244, 244]           1,792\n",
      "              ReLU-2         [-1, 64, 244, 244]               0\n",
      "            Conv2d-3         [-1, 64, 244, 244]          36,928\n",
      "              ReLU-4         [-1, 64, 244, 244]               0\n",
      "         MaxPool2d-5         [-1, 64, 122, 122]               0\n",
      "            Conv2d-6        [-1, 128, 122, 122]          73,856\n",
      "              ReLU-7        [-1, 128, 122, 122]               0\n",
      "            Conv2d-8        [-1, 128, 122, 122]         147,584\n",
      "              ReLU-9        [-1, 128, 122, 122]               0\n",
      "        MaxPool2d-10          [-1, 128, 61, 61]               0\n",
      "           Conv2d-11          [-1, 256, 61, 61]         295,168\n",
      "             ReLU-12          [-1, 256, 61, 61]               0\n",
      "           Conv2d-13          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-14          [-1, 256, 61, 61]               0\n",
      "           Conv2d-15          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-16          [-1, 256, 61, 61]               0\n",
      "        MaxPool2d-17          [-1, 256, 30, 30]               0\n",
      "           Conv2d-18          [-1, 512, 30, 30]       1,180,160\n",
      "             ReLU-19          [-1, 512, 30, 30]               0\n",
      "           Conv2d-20          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-21          [-1, 512, 30, 30]               0\n",
      "           Conv2d-22          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-23          [-1, 512, 30, 30]               0\n",
      "        MaxPool2d-24          [-1, 512, 15, 15]               0\n",
      "           Conv2d-25          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-26          [-1, 512, 15, 15]               0\n",
      "           Conv2d-27          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-28          [-1, 512, 15, 15]               0\n",
      "           Conv2d-29          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-30          [-1, 512, 15, 15]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 134,301,514\n",
      "Trainable params: 134,301,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 258.50\n",
      "Params size (MB): 512.32\n",
      "Estimated Total Size (MB): 771.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 244, 244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc50a506-356d-4e8d-abf9-4e23b6e7ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:21:16,984 - MainProcess - INFO - Found 13 Conv2D layers in vgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features.0': Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.5': Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.7': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.10': Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.12': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.14': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.17': Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.19': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.21': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.24': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.26': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " 'features.28': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Conv2D layers\n",
    "conv_layers = get_conv2d_layers(model)\n",
    "logger.info(f\"Found {len(conv_layers)} Conv2D layers in {MODEL_NAME}\")\n",
    "conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db6ca7c6-4dc5-4fe6-8f06-859c006c6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:21:17,000 - MainProcess - INFO - Layer features.0: initial rank R_i = 3, parameters = 1728\n",
      "2025-03-30 08:21:17,001 - MainProcess - INFO - Layer features.2: initial rank R_i = 64, parameters = 36864\n",
      "2025-03-30 08:21:17,002 - MainProcess - INFO - Layer features.5: initial rank R_i = 64, parameters = 73728\n",
      "2025-03-30 08:21:17,002 - MainProcess - INFO - Layer features.7: initial rank R_i = 128, parameters = 147456\n",
      "2025-03-30 08:21:17,003 - MainProcess - INFO - Layer features.10: initial rank R_i = 128, parameters = 294912\n",
      "2025-03-30 08:21:17,004 - MainProcess - INFO - Layer features.12: initial rank R_i = 256, parameters = 589824\n",
      "2025-03-30 08:21:17,004 - MainProcess - INFO - Layer features.14: initial rank R_i = 256, parameters = 589824\n",
      "2025-03-30 08:21:17,005 - MainProcess - INFO - Layer features.17: initial rank R_i = 256, parameters = 1179648\n",
      "2025-03-30 08:21:17,006 - MainProcess - INFO - Layer features.19: initial rank R_i = 512, parameters = 2359296\n",
      "2025-03-30 08:21:17,007 - MainProcess - INFO - Layer features.21: initial rank R_i = 512, parameters = 2359296\n",
      "2025-03-30 08:21:17,008 - MainProcess - INFO - Layer features.24: initial rank R_i = 512, parameters = 2359296\n",
      "2025-03-30 08:21:17,008 - MainProcess - INFO - Layer features.26: initial rank R_i = 512, parameters = 2359296\n",
      "2025-03-30 08:21:17,009 - MainProcess - INFO - Layer features.28: initial rank R_i = 512, parameters = 2359296\n"
     ]
    }
   ],
   "source": [
    "# Initialize layer information\n",
    "# Conv2 layers in Pytorch are (Cin, Cout, ks, ks), i.e. a 4D tensor with rank 4, called modes 0 to 3\n",
    "# we are interested in low rank approximating of modes 0 and 1, i.e. compressing the information in  the channels\n",
    "# each mode is almost always full rank, i.e. of rank == size\n",
    "# therefore for the pupose of this exp rank of a layer is the min(Cin, Cout) \n",
    "\n",
    "\n",
    "# TODO: complexity ranks in decreasing order layers that are closest to the middle.  \n",
    "layer_info = {}\n",
    "for name, layer in conv_layers.items():\n",
    "    r_i = infer_rank(layer)\n",
    "    layer_info[name] = {\n",
    "        'layer': layer,\n",
    "        'r_i': r_i,\n",
    "        'params': calculate_layer_params(layer),\n",
    "        'complexity': None\n",
    "    }\n",
    "    logger.info(f\"Layer {name}: initial rank R_i = {r_i}, parameters = {layer_info[name]['params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2242b8e0-52ea-43f2-84b5-8e9ad7b2dae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features.0': {'layer': Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 3,\n",
       "  'params': 1728,\n",
       "  'complexity': None},\n",
       " 'features.2': {'layer': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 64,\n",
       "  'params': 36864,\n",
       "  'complexity': None},\n",
       " 'features.5': {'layer': Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 64,\n",
       "  'params': 73728,\n",
       "  'complexity': None},\n",
       " 'features.7': {'layer': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 128,\n",
       "  'params': 147456,\n",
       "  'complexity': None},\n",
       " 'features.10': {'layer': Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 128,\n",
       "  'params': 294912,\n",
       "  'complexity': None},\n",
       " 'features.12': {'layer': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 256,\n",
       "  'params': 589824,\n",
       "  'complexity': None},\n",
       " 'features.14': {'layer': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 256,\n",
       "  'params': 589824,\n",
       "  'complexity': None},\n",
       " 'features.17': {'layer': Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 256,\n",
       "  'params': 1179648,\n",
       "  'complexity': None},\n",
       " 'features.19': {'layer': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 512,\n",
       "  'params': 2359296,\n",
       "  'complexity': None},\n",
       " 'features.21': {'layer': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 512,\n",
       "  'params': 2359296,\n",
       "  'complexity': None},\n",
       " 'features.24': {'layer': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 512,\n",
       "  'params': 2359296,\n",
       "  'complexity': None},\n",
       " 'features.26': {'layer': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 512,\n",
       "  'params': 2359296,\n",
       "  'complexity': None},\n",
       " 'features.28': {'layer': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  'r_i': 512,\n",
       "  'params': 2359296,\n",
       "  'complexity': None}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58d648df-fefc-48fc-8972-67241818c1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:22:52,744 - MainProcess - INFO - Baseline vgg: params=134301514, FLOPs=15519169546, accuracy=0.9956, inference_time=0.1387s\n"
     ]
    }
   ],
   "source": [
    "# Compute baseline metrics\n",
    "baseline_params = count_parameters(model)\n",
    "baseline_flops = get_flops(model)\n",
    "baseline_accuracy = calculate_accuracy(model, test_loader, device)\n",
    "baseline_inference_time = measure_inference_time(model, test_loader, device, num_runs=3)\n",
    "\n",
    "logger.info(f\"Baseline {MODEL_NAME}: params={baseline_params}, \"\n",
    "            f\"FLOPs={baseline_flops}, accuracy={baseline_accuracy:.4f}, \"\n",
    "            f\"inference_time={baseline_inference_time:.4f}s\")\n",
    "\n",
    "# Timestamp for unique file naming\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b8799e-b51c-493e-88ae-a96c3ea13517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:22:52,749 - MainProcess - INFO - Total possible configurations: 6059305734288801022, will try: 250\n"
     ]
    }
   ],
   "source": [
    "# Generate possible ranks per layer, that is 1 up to it's rank - 1 \n",
    "# if layer is of rank 1, then possible ranks are just 1\n",
    "possible_ranks = {}\n",
    "for name, info in layer_info.items():\n",
    "    r_i = info['r_i']\n",
    "    ranks = [1] + list(range(2, r_i)) \n",
    "    possible_ranks[name] = ranks\n",
    "\n",
    "total_possible_configs = abs(np.prod([max(1, layer_info[name]['r_i'] - 1) for name in layer_info.keys()]))\n",
    "num_configs_to_try = min(total_possible_configs, MAX_CFG)\n",
    "logger.info(f\"Total possible configurations: {total_possible_configs}, will try: {num_configs_to_try}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9262c9c-1d58-4e50-b60e-ab2ee9f7b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def construct_layer_dict(model):\n",
    "    layer_dict = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            W = module.weight.data\n",
    "            cin = module.in_channels\n",
    "            cout = module.out_channels\n",
    "            layer_dict[name] = (W, cin, cout)\n",
    "    return layer_dict\n",
    "\n",
    "layer_dict = construct_layer_dict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "369c2b8a-708f-4fcb-b449-1e426a6c7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorly.decomposition import partial_tucker\n",
    "import tensorly as tl    \n",
    "from tensorly.tucker_tensor import tucker_to_tensor\n",
    "from tensorly.metrics.regression import MSE\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "# # Heuristic: layers with bigger cin*cout more suseptible to lower ranks \n",
    "# def get_size_probs(cin, cout, rank_candidates, beta=1.0):\n",
    "#     size = cin * cout\n",
    "#     preference = np.log(size + 1)  # +1 to avoid log(0), though unlikely\n",
    "#     scores = [-beta * r / preference for r in rank_candidates]\n",
    "#     probs = np.exp(scores) / np.sum(np.exp(scores))\n",
    "#     return probs\n",
    "\n",
    "# # Heuristic: Layers with higher reconstruction erros are less suseptible to low ranks \n",
    "# def compute_sensitivity(W, cin, cout):\n",
    "#     rank = [max(1, cout // 2), max(1, cin // 2)]\n",
    "#     (core, factors) = partial_tucker(W, modes=[0, 1], rank=rank, init='svd')\n",
    "       \n",
    "#     reconstructed_W = tucker_to_tensor(core, factors)\n",
    "#     return MSE(W, reconstructed_W) \n",
    "\n",
    "# # Precompute sensitivity for all layers\n",
    "# def precompute_sensitivities(layer_dict):\n",
    "#     sensitivities = {}\n",
    "#     for name, (W, cin, cout) in layer_dict.items():\n",
    "#         sensitivities[name] = compute_sensitivity(W, cin, cout).to('cpu')\n",
    "#     # Normalize sensitivities to [0, 1]\n",
    "#     max_error = max(list(sensitivities.values()))\n",
    "#     if max_error > 0:  # Avoid division by zero\n",
    "#         sensitivities = {name: err / max_error for name, err in sensitivities.items()}\n",
    "#     return sensitivities\n",
    "    \n",
    "# def get_sensitivity_probs(sensitivity, rank_candidates, alpha=1.0):\n",
    "#     max_rank = max(rank_candidates)\n",
    "#     scores = [(r / max_rank) ** (alpha * sensitivity) for r in rank_candidates]\n",
    "#     probs = scores / np.sum(scores)\n",
    "#     return probs\n",
    "\n",
    "# def get_rank_candidates(channels, r=(75, 49, -25)):\n",
    "#     s, f, stride = r\n",
    "#     percentages = np.arange(s, f, stride) / 100\n",
    "#     candidates = set([max(1, int(channels * p)) for p in percentages])\n",
    "#     return candidates\n",
    "# def softmax(x: np.ndarray) -> np.ndarray:\n",
    "#     x_max = np.max(x)  # Avoid overflow\n",
    "#     exp_x = np.exp(x - x_max)  # Shift values\n",
    "#     return exp_x / np.sum(exp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e089b161-e0ca-4758-b8c1-eb0236359aeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.special import softmax\n",
    "\n",
    "def get_rank_candidates(channels, r=(90, 24, -5)):\n",
    "    s, f, stride = r\n",
    "    percentages = np.arange(s, f, stride) / 100\n",
    "    candidates = set([max(1, int(channels * p)) for p in percentages])\n",
    "    return candidates\n",
    "\n",
    "def compute_sensitivity(W, cin, cout):\n",
    "    rank = [max(1, cout // 2), max(1, cin // 2)]\n",
    "    (core, factors) = partial_tucker(W, modes=[0, 1], rank=rank, init='svd')\n",
    "    reconstructed_W = tucker_to_tensor(core, factors)\n",
    "    return MSE(W, reconstructed_W)\n",
    "\n",
    "def precompute_sensitivities(layer_dict):\n",
    "    sensitivities = {}\n",
    "    for name, (W, cin, cout) in layer_dict.items():\n",
    "        sensitivities[name] = compute_sensitivity(W, cin, cout).to('cpu').item()\n",
    "    max_error = max(sensitivities.values())\n",
    "    if max_error > 0:\n",
    "        sensitivities = {name: err / max_error for name, err in sensitivities.items()}\n",
    "    return sensitivities\n",
    "\n",
    "def get_sensitivity_scores(sensitivity, rank_candidates, alpha=1.0):\n",
    "    max_rank = max(rank_candidates)\n",
    "    return [(r / max_rank) ** (alpha * sensitivity) for r in rank_candidates]\n",
    "\n",
    "def get_size_based_scores(cin, cout, rank_candidates, beta=1.0):\n",
    "    size = cin * cout\n",
    "    preference = np.log(size + 1)\n",
    "    return [-beta * r / preference for r in rank_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a60b331-3e2d-4dc9-84c9-8b8ea91c8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_configs(layer_dict, sensitivities, num_cfg=500, alpha=1.0, beta=1.0):\n",
    "    for _ in range(num_cfg):\n",
    "        config = {}\n",
    "        for name, (W, cin, cout) in layer_dict.items():\n",
    "            cin_candidates = list(get_rank_candidates(cin))\n",
    "            cout_candidates = list(get_rank_candidates(cout))\n",
    "            sensitivity = sensitivities[name]\n",
    "\n",
    "            # Combine scores for cin\n",
    "            cin_sen_scores = get_sensitivity_scores(sensitivity, cin_candidates, alpha)\n",
    "            cin_size_scores = get_size_based_scores(cin, cout, cin_candidates, beta)\n",
    "            cin_probs = softmax(np.array(cin_sen_scores) + np.array(cin_size_scores))\n",
    "\n",
    "            # Combine scores for cout\n",
    "            cout_sen_scores = get_sensitivity_scores(sensitivity, cout_candidates, alpha)\n",
    "            cout_size_scores = get_size_based_scores(cin, cout, cout_candidates, beta)\n",
    "            cout_probs = softmax(np.array(cout_sen_scores) + np.array(cout_size_scores))\n",
    "\n",
    "            # Sample ranks\n",
    "            cin_rank = random.choices(cin_candidates, weights=cin_probs)[0]\n",
    "            cout_rank = random.choices(cout_candidates, weights=cout_probs)[0]\n",
    "            config[name] = (cin_rank, cout_rank)\n",
    "        yield config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aae2233f-bc9c-4206-b4b2-f889c1217634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generator function to yield num_cfg configurations\n",
    "# def generate_configs(layer_dict, num_cfg):\n",
    "    \n",
    "    \n",
    "#     # Precompute rank candidates for each layer\n",
    "#     rank_candidates = {}\n",
    "#     for name, (W, cin, cout) in layer_dict.items():\n",
    "#         cin_candidates = get_rank_candidates(cin)  \n",
    "#         cout_candidates = get_rank_candidates(cout)  \n",
    "        \n",
    "#         rank_pairs = list(itertools.product(cin_candidates, cout_candidates))\n",
    "#         rank_candidates[name] = rank_pairs\n",
    "#         # we sort to keep higher ranks on top of the search \n",
    "#         # no heuristic, budget num_cfg accross all layers equally \n",
    "#         # num_cfg / len(layer_dict.keys) searches per layer\n",
    "#         # spl = int(num_cfg ** (1 / len(layer_dict.keys())))\n",
    "#         # rank_candidates[name] = sorted(rank_pairs, key=lambda x: (-x[0], -x[1]))[:spl]\n",
    "    \n",
    "#     # Yield exactly num_cfg random configurations\n",
    "#     for config in itertools.product(*rank_candidates.values()):\n",
    "#         yield dict(zip(layer_dict.keys(), config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4ddbb0c-76db-478e-9c9f-ec4e1976d724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features.0': (1, 16),\n",
       " 'features.2': (19, 19),\n",
       " 'features.5': (25, 32),\n",
       " 'features.7': (38, 38),\n",
       " 'features.10': (32, 64),\n",
       " 'features.12': (140, 76),\n",
       " 'features.14': (64, 64),\n",
       " 'features.17': (76, 128),\n",
       " 'features.19': (179, 128),\n",
       " 'features.21': (128, 128),\n",
       " 'features.24': (128, 128),\n",
       " 'features.26': (128, 128),\n",
       " 'features.28': (128, 128)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivities = precompute_sensitivities(layer_dict)\n",
    "configs = generate_configs(layer_dict, sensitivities, num_cfg=500, alpha=1.0, beta=1.0)\n",
    "next(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a24cd2e-a6f6-44a5-9e24-e3335ed19bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "configs = [config for config in generate_configs(layer_dict, sensitivities, num_cfg=500, alpha=1.0, beta=1.0)]\n",
    "\n",
    "def plot_compression_dist_boxplot(layer_dict, configs):\n",
    "    # Step 1: Calculate average rin and rout per layer across configs\n",
    "    avg_ranks = {name: {'rin': [], 'rout': []} for name in layer_dict.keys()}\n",
    "    for config in configs:\n",
    "        for name, (rin, rout) in config.items():\n",
    "            avg_ranks[name]['rin'].append(rin)\n",
    "            avg_ranks[name]['rout'].append(rout)\n",
    "    \n",
    "    # Step 2: Compute compression rates for each config and layer\n",
    "    compression_rates = {name: [] for name in layer_dict.keys()}\n",
    "    for config in configs:\n",
    "        for name, (rin, rout) in config.items():\n",
    "            cin, cout = layer_dict[name][1], layer_dict[name][2]  # Extract cin, cout\n",
    "            if rin > 0 and rout > 0:  # Avoid division by zero\n",
    "                rate = (cin * cout) / (rin * rout)  # Compression rate for this config\n",
    "                compression_rates[name].append(rate)\n",
    "    \n",
    "    # Step 3: Prepare data for plotting\n",
    "    layer_names = list(layer_dict.keys())\n",
    "    data = [compression_rates[name] for name in layer_names if compression_rates[name]]  # Filter out empty lists\n",
    "    \n",
    "    # Step 4: Create box plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(data, labels=layer_names)\n",
    "    plt.title('Compression Rate Distribution per Layer')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Compression Rate ((cin * cout) / (rin * rout))')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac57ff0a-77cd-4e6d-ac16-9426f1453f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2462655/1213876075.py:28: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(data, labels=layer_names)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_compression_dist_boxplot(layer_dict, configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0541106f-2a5f-4fe7-8315-abacb437666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_model(model):\n",
    "    # Check if the model name is valid\n",
    "    model_name = MODEL_NAME\n",
    "    \n",
    "    if model_name == 'vgg':\n",
    "        model_cp = models.vgg16(weights=None)\n",
    "        model_cp.classifier[6] = nn.Linear(4096, 10)\n",
    "        \n",
    "    elif model_name == 'alexnet':\n",
    "        model_cp = models.alexnet(weights=None)\n",
    "        model_cp.classifier[6] = nn.Linear(4096, 10)\n",
    "        \n",
    "    elif model_name == 'resnet':\n",
    "        model_cp = models.resnet18(weights=None)\n",
    "        model_cp.fc = nn.Linear(512, 10)\n",
    "\n",
    "    model_cp.load_state_dict(model.state_dict())   \n",
    "    return model_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3024b5c-1628-4d25-a3e1-a04c2d947b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_config(config, device_idx):\n",
    "    try:        \n",
    "        # Explicitly create a new scope to help with garbage collection\n",
    "        with torch.enable_grad():\n",
    "\n",
    "            config_str = \", \".join([f\"{k}:{v}\" for k, v in config.items()])\n",
    "            logger.info(f\"Compressing to:{config_str}\")\n",
    "            \n",
    "            # Apply the configuration\n",
    "            model.to('cpu')\n",
    "            compressed_model = duplicate_model(model)\n",
    "            compressed_model.to(device)\n",
    "\n",
    "            for name, rank in config.items():\n",
    "                layer = layer_info[name]['layer']\n",
    "                compressed_model = replace_conv2d_with_tucker(compressed_model, name, layer, rank)\n",
    "\n",
    "            # verify compressed model is still on gpu\n",
    "            compressed_model.to(device)\n",
    "\n",
    "            # Finetune for 3 epochs \n",
    "            if FINETUNE: \n",
    "                logger.info(f\"finetuning:{config_str}\")\n",
    "                compressed_model = fine_tune(compressed_model, train_loader, device, epochs=3, lr=0.001)\n",
    "                \n",
    "            # Evaluate the model\n",
    "            accuracy = calculate_accuracy(compressed_model, test_loader, device)\n",
    "            params = count_parameters(compressed_model)\n",
    "            flops = get_flops(compressed_model)\n",
    "            inference_time = measure_inference_time(compressed_model, test_loader, device, num_runs=3)\n",
    "            compression_rate = baseline_params / params if params > 0 else float('inf')\n",
    "            \n",
    "            result = {\n",
    "                'config_str': config_str,\n",
    "                'params': params,\n",
    "                'flops': flops,\n",
    "                'accuracy': accuracy,\n",
    "                'inference_time': inference_time,\n",
    "                'compression_rate': compression_rate,\n",
    "                'accepted': True if accuracy >= acceptance_threshold else False\n",
    "            }\n",
    "            result_str = json.dumps(result, indent=4, default=str)\n",
    "            logger.info(f\"compressed_model:\\n{result_str}\")\n",
    "\n",
    "            return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing config: {config}. Error: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        # Explicit cleanup\n",
    "        if 'compressed_model' in locals():\n",
    "            del compressed_model\n",
    "        \n",
    "        # Clear CUDA cache\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4777eedf-946d-424e-95e2-267f377bdcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:23:03,371 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(22, 28), features.5:(22, 32), features.7:(44, 38), features.10:(32, 64), features.12:(89, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 08:23:03,372 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 19), features.5:(28, 38), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 08:23:03,375 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 25), features.5:(22, 32), features.7:(32, 38), features.10:(70, 64), features.12:(64, 89), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 08:23:03,377 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 16), features.5:(19, 64), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 89), features.17:(76, 128), features.19:(153, 128), features.21:(153, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 08:23:03,574 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 19), 'features.5': (28, 38), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA error: invalid argument\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "2025-03-30 08:23:03,789 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 16), features.5:(35, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 102), features.17:(76, 128), features.19:(153, 128), features.21:(128, 179), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 08:23:03,866 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 25), 'features.5': (22, 32), 'features.7': (32, 38), 'features.10': (70, 64), 'features.12': (64, 89), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA error: invalid argument\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "2025-03-30 08:23:03,868 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(19, 16), features.5:(19, 32), features.7:(57, 32), features.10:(51, 76), features.12:(64, 76), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=16, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=25, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=28, which is larger than max(matrix.shape)=18. Setting n_eigenvecs to 18.\n",
      "  warnings.warn(\n",
      "2025-03-30 08:23:25,588 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 16), features.5:(35, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 102), features.17:(76, 128), features.19:(153, 128), features.21:(128, 179), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 08:23:25,787 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 16), features.5:(19, 64), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 89), features.17:(76, 128), features.19:(153, 128), features.21:(153, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 08:23:26,404 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(19, 16), features.5:(19, 32), features.7:(57, 32), features.10:(51, 76), features.12:(64, 76), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 08:23:30,333 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(22, 28), features.5:(22, 32), features.7:(44, 38), features.10:(32, 64), features.12:(89, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1435\n",
      "Epoch 1/3, Loss: 0.1591\n",
      "Epoch 1/3, Loss: 0.1302\n",
      "Epoch 1/3, Loss: 0.0627\n",
      "Epoch 2/3, Loss: 0.0319\n",
      "Epoch 2/3, Loss: 0.0320\n",
      "Epoch 2/3, Loss: 0.0353\n",
      "Epoch 2/3, Loss: 0.0256\n",
      "Epoch 3/3, Loss: 0.0258\n",
      "Epoch 3/3, Loss: 0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:13:49,869 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 25), features.2:(19, 16), features.5:(19, 32), features.7:(57, 32), features.10:(51, 76), features.12:(64, 76), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121416174,\n",
      "    \"flops\": 4815441354,\n",
      "    \"accuracy\": 0.9925,\n",
      "    \"inference_time\": 0.5298755553624179,\n",
      "    \"compression_rate\": 1.106125399734635,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:13:50,100 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 16), features.5:(19, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 76), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 09:14:07,675 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 16), features.5:(19, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 76), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:16:48,999 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(16, 16), features.5:(35, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 102), features.17:(76, 128), features.19:(153, 128), features.21:(128, 179), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121565134,\n",
      "    \"flops\": 4900492810,\n",
      "    \"accuracy\": 0.9926,\n",
      "    \"inference_time\": 0.43219397933619796,\n",
      "    \"compression_rate\": 1.1047700074924443,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:16:49,174 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(22, 19), features.5:(25, 44), features.7:(51, 51), features.10:(57, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 09:17:08,856 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(22, 19), features.5:(25, 44), features.7:(51, 51), features.10:(57, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:20:40,135 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(16, 16), features.5:(19, 64), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 89), features.17:(76, 128), features.19:(153, 128), features.21:(153, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121566835,\n",
      "    \"flops\": 4904639386,\n",
      "    \"accuracy\": 0.9926,\n",
      "    \"inference_time\": 0.4994202303025879,\n",
      "    \"compression_rate\": 1.1047545492156639,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:20:40,303 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(28, 38), features.5:(16, 57), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=19, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "2025-03-30 09:20:59,106 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(28, 38), features.5:(16, 57), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 09:24:33,538 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 28), features.2:(22, 28), features.5:(22, 32), features.7:(44, 38), features.10:(32, 64), features.12:(89, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121462322,\n",
      "    \"flops\": 4973221550,\n",
      "    \"accuracy\": 0.9919,\n",
      "    \"inference_time\": 0.5923961590809427,\n",
      "    \"compression_rate\": 1.1057051420439665,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:24:33,751 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 19), features.5:(19, 76), features.7:(32, 44), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(179, 128)\n",
      "2025-03-30 09:24:54,274 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 19), features.5:(19, 76), features.7:(32, 44), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(179, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1414\n",
      "Epoch 1/3, Loss: 0.1533\n",
      "Epoch 2/3, Loss: 0.0333\n",
      "Epoch 1/3, Loss: 0.1614\n",
      "Epoch 1/3, Loss: 0.0647\n",
      "Epoch 3/3, Loss: 0.0275\n",
      "Epoch 2/3, Loss: 0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:57:03,089 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(19, 16), features.5:(19, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 76), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121420990,\n",
      "    \"flops\": 4712633866,\n",
      "    \"accuracy\": 0.9928,\n",
      "    \"inference_time\": 0.6536682588532725,\n",
      "    \"compression_rate\": 1.1060815267607356,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:57:03,366 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(25, 32), features.5:(57, 96), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 09:57:24,558 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(25, 32), features.5:(57, 96), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0346\n",
      "Epoch 3/3, Loss: 0.0253\n",
      "Epoch 1/3, Loss: 0.0645\n",
      "Epoch 2/3, Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:12:03,778 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 25), features.2:(22, 19), features.5:(25, 44), features.7:(51, 51), features.10:(57, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121425993,\n",
      "    \"flops\": 5030047242,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.6612966323860638,\n",
      "    \"compression_rate\": 1.106035953932862,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:12:03,956 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 19), features.5:(19, 32), features.7:(32, 38), features.10:(57, 64), features.12:(89, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 10:12:27,892 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 19), features.5:(19, 32), features.7:(32, 38), features.10:(57, 64), features.12:(89, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0270\n",
      "Epoch 2/3, Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:23:44,279 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(28, 38), features.5:(16, 57), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121383846,\n",
      "    \"flops\": 5048411658,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.6547147422839122,\n",
      "    \"compression_rate\": 1.106419992657013,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:23:44,580 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(28, 16), features.5:(25, 44), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=19, which is larger than max(matrix.shape)=18. Setting n_eigenvecs to 18.\n",
      "  warnings.warn(\n",
      "2025-03-30 10:24:06,420 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(28, 16), features.5:(25, 44), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1451\n",
      "Epoch 3/3, Loss: 0.0216\n",
      "Epoch 3/3, Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:37:00,680 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(16, 19), features.5:(19, 76), features.7:(32, 44), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(179, 128)\",\n",
      "    \"params\": 121466873,\n",
      "    \"flops\": 4804355594,\n",
      "    \"accuracy\": 0.994,\n",
      "    \"inference_time\": 0.4654957544525211,\n",
      "    \"compression_rate\": 1.1056637145833168,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:37:00,904 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(25, 22), features.5:(22, 38), features.7:(44, 38), features.10:(32, 64), features.12:(64, 76), features.14:(64, 115), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 10:37:20,735 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(25, 22), features.5:(22, 38), features.7:(44, 38), features.10:(32, 64), features.12:(64, 76), features.14:(64, 115), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 10:38:57,123 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(25, 32), features.5:(57, 96), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121392169,\n",
      "    \"flops\": 5370968074,\n",
      "    \"accuracy\": 0.9937,\n",
      "    \"inference_time\": 0.5145356887971266,\n",
      "    \"compression_rate\": 1.1063441332858959,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:38:57,354 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(19, 41), features.5:(16, 38), features.7:(32, 44), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=25, which is larger than max(matrix.shape)=18. Setting n_eigenvecs to 18.\n",
      "  warnings.warn(\n",
      "2025-03-30 10:39:18,401 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(19, 41), features.5:(16, 38), features.7:(32, 44), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0693\n",
      "Epoch 2/3, Loss: 0.0332\n",
      "Epoch 1/3, Loss: 0.0719\n",
      "Epoch 1/3, Loss: 0.0663\n",
      "Epoch 2/3, Loss: 0.0278\n",
      "Epoch 3/3, Loss: 0.0267\n",
      "Epoch 2/3, Loss: 0.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:09:54,101 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(16, 19), features.5:(19, 32), features.7:(32, 38), features.10:(57, 64), features.12:(89, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121469450,\n",
      "    \"flops\": 4790243594,\n",
      "    \"accuracy\": 0.9922,\n",
      "    \"inference_time\": 0.643545289454693,\n",
      "    \"compression_rate\": 1.1056402576944244,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:09:54,357 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(28, 28), features.5:(25, 32), features.7:(32, 44), features.10:(38, 64), features.12:(76, 64), features.14:(89, 64), features.17:(89, 153), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:09:54,357 - MainProcess - INFO - Evaluated 10 configurations, found 10 accepted models\n",
      "2025-03-30 11:10:16,043 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(28, 28), features.5:(25, 32), features.7:(32, 44), features.10:(38, 64), features.12:(76, 64), features.14:(89, 64), features.17:(89, 153), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0213\n",
      "Epoch 3/3, Loss: 0.0213\n",
      "Epoch 2/3, Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:22:10,737 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 25), features.2:(19, 41), features.5:(16, 38), features.7:(32, 44), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121435276,\n",
      "    \"flops\": 5007744010,\n",
      "    \"accuracy\": 0.994,\n",
      "    \"inference_time\": 0.47041424064879206,\n",
      "    \"compression_rate\": 1.1059514041043559,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:22:10,913 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(19, 19), features.5:(28, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(128, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:22:31,926 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(19, 19), features.5:(28, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(128, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:24:15,050 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(28, 16), features.5:(25, 44), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121349877,\n",
      "    \"flops\": 4783858698,\n",
      "    \"accuracy\": 0.9934,\n",
      "    \"inference_time\": 0.524871070420413,\n",
      "    \"compression_rate\": 1.106729708510541,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:24:15,274 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(35, 19), features.5:(16, 70), features.7:(32, 44), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=22, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "2025-03-30 11:24:37,523 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(35, 19), features.5:(16, 70), features.7:(32, 44), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:25:13,472 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (25, 22), 'features.5': (22, 38), 'features.7': (44, 38), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 115), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.11 GiB memory in use. Including non-PyTorch memory, this process has 37.24 GiB memory in use. Of the allocated memory 36.59 GiB is allocated by PyTorch, and 247.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:25:13,478 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (35, 19), 'features.5': (16, 70), 'features.7': (32, 44), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.11 GiB memory in use. Including non-PyTorch memory, this process has 37.24 GiB memory in use. Of the allocated memory 36.60 GiB is allocated by PyTorch, and 240.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:25:13,484 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (19, 19), 'features.5': (28, 38), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (128, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 5.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.11 GiB memory in use. Including non-PyTorch memory, this process has 37.24 GiB memory in use. Of the allocated memory 36.63 GiB is allocated by PyTorch, and 210.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:25:13,512 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 16), features.5:(28, 44), features.7:(44, 44), features.10:(32, 64), features.12:(102, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(153, 153)\n",
      "2025-03-30 11:25:13,578 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(25, 32), features.5:(22, 44), features.7:(32, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(89, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 11:25:13,580 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 25), features.5:(32, 44), features.7:(32, 38), features.10:(32, 89), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(179, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:25:30,948 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 16), features.5:(28, 44), features.7:(44, 44), features.10:(32, 64), features.12:(102, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(153, 153)\n",
      "2025-03-30 11:25:34,363 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(25, 32), features.5:(22, 44), features.7:(32, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(89, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 11:25:34,643 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 25), features.5:(32, 44), features.7:(32, 38), features.10:(32, 89), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(179, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:26:28,093 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (25, 32), 'features.5': (22, 44), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 71.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.49 GiB memory in use. Including non-PyTorch memory, this process has 36.79 GiB memory in use. Of the allocated memory 35.96 GiB is allocated by PyTorch, and 434.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:26:28,100 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 25), 'features.5': (32, 44), 'features.7': (32, 38), 'features.10': (32, 89), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (179, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 71.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.49 GiB memory in use. Including non-PyTorch memory, this process has 36.79 GiB memory in use. Of the allocated memory 35.96 GiB is allocated by PyTorch, and 434.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:26:28,110 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 19), features.5:(22, 44), features.7:(38, 38), features.10:(44, 76), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:26:28,150 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 16), features.5:(22, 32), features.7:(38, 32), features.10:(51, 76), features.12:(64, 64), features.14:(76, 102), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=22, which is larger than max(matrix.shape)=18. Setting n_eigenvecs to 18.\n",
      "  warnings.warn(\n",
      "2025-03-30 11:26:48,129 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 16), features.5:(22, 32), features.7:(38, 32), features.10:(51, 76), features.12:(64, 64), features.14:(76, 102), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 11:26:48,131 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 19), features.5:(22, 44), features.7:(38, 38), features.10:(44, 76), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:27:12,868 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 16), 'features.5': (22, 32), 'features.7': (38, 32), 'features.10': (51, 76), 'features.12': (64, 64), 'features.14': (76, 102), 'features.17': (76, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 235.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.49 GiB memory in use. Including non-PyTorch memory, this process has 36.63 GiB memory in use. Of the allocated memory 35.94 GiB is allocated by PyTorch, and 294.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:27:12,875 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (28, 28), 'features.5': (25, 32), 'features.7': (32, 44), 'features.10': (38, 64), 'features.12': (76, 64), 'features.14': (89, 64), 'features.17': (89, 153), 'features.19': (128, 153), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 171.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.49 GiB memory in use. Including non-PyTorch memory, this process has 36.69 GiB memory in use. Of the allocated memory 35.99 GiB is allocated by PyTorch, and 310.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:27:12,881 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 19), 'features.5': (22, 44), 'features.7': (38, 38), 'features.10': (44, 76), 'features.12': (64, 64), 'features.14': (89, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 171.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.49 GiB memory in use. Including non-PyTorch memory, this process has 36.69 GiB memory in use. Of the allocated memory 35.95 GiB is allocated by PyTorch, and 342.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:27:12,888 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (19, 16), 'features.5': (28, 44), 'features.7': (44, 44), 'features.10': (32, 64), 'features.12': (102, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (153, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 117.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.49 GiB memory in use. Including non-PyTorch memory, this process has 36.74 GiB memory in use. Of the allocated memory 35.97 GiB is allocated by PyTorch, and 378.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:27:12,919 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 22), features.5:(19, 32), features.7:(51, 32), features.10:(38, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:27:12,921 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(35, 22), features.5:(16, 57), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 179), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:27:12,997 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 32), features.5:(19, 44), features.7:(38, 32), features.10:(38, 89), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(179, 153), features.28:(128, 128)\n",
      "2025-03-30 11:27:12,998 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 19), features.5:(16, 32), features.7:(57, 44), features.10:(51, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:27:32,877 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(35, 22), features.5:(16, 57), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 179), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:27:32,931 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 19), features.5:(16, 32), features.7:(57, 44), features.10:(51, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:27:36,124 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 22), features.5:(19, 32), features.7:(51, 32), features.10:(38, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:27:38,102 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 32), features.5:(19, 44), features.7:(38, 32), features.10:(38, 89), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(179, 153), features.28:(128, 128)\n",
      "2025-03-30 11:29:33,765 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (35, 22), 'features.5': (16, 57), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 179), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 141.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.50 GiB memory in use. Including non-PyTorch memory, this process has 36.72 GiB memory in use. Of the allocated memory 35.79 GiB is allocated by PyTorch, and 539.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:29:33,790 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 32), 'features.5': (19, 44), 'features.7': (38, 32), 'features.10': (38, 89), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (179, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 331.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.50 GiB memory in use. Including non-PyTorch memory, this process has 36.53 GiB memory in use. Of the allocated memory 35.93 GiB is allocated by PyTorch, and 208.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:29:33,801 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(19, 16), features.5:(16, 51), features.7:(32, 32), features.10:(32, 89), features.12:(64, 76), features.14:(64, 76), features.17:(76, 153), features.19:(128, 128), features.21:(153, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:29:33,824 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 19), features.5:(32, 32), features.7:(38, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=32, which is larger than max(matrix.shape)=18. Setting n_eigenvecs to 18.\n",
      "  warnings.warn(\n",
      "2025-03-30 11:29:52,777 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(19, 16), features.5:(16, 51), features.7:(32, 32), features.10:(32, 89), features.12:(64, 76), features.14:(64, 76), features.17:(76, 153), features.19:(128, 128), features.21:(153, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:29:56,373 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 19), features.5:(32, 32), features.7:(38, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:30:25,803 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (19, 16), 'features.5': (16, 51), 'features.7': (32, 32), 'features.10': (32, 89), 'features.12': (64, 76), 'features.14': (64, 76), 'features.17': (76, 153), 'features.19': (128, 128), 'features.21': (153, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 605.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.50 GiB memory in use. Including non-PyTorch memory, this process has 36.27 GiB memory in use. Of the allocated memory 32.74 GiB is allocated by PyTorch, and 3.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:30:26,012 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 19), features.5:(32, 32), features.7:(32, 32), features.10:(38, 64), features.12:(76, 64), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:30:44,958 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 19), features.5:(32, 32), features.7:(32, 32), features.10:(38, 64), features.12:(76, 64), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:32:45,943 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 19), 'features.5': (32, 32), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (76, 64), 'features.14': (76, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 11.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.04 GiB memory in use. Including non-PyTorch memory, this process has 37.30 GiB memory in use. Of the allocated memory 36.58 GiB is allocated by PyTorch, and 323.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:32:45,948 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (19, 22), 'features.5': (19, 32), 'features.7': (51, 32), 'features.10': (38, 76), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.04 GiB memory in use. Including non-PyTorch memory, this process has 37.30 GiB memory in use. Of the allocated memory 36.61 GiB is allocated by PyTorch, and 303.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:32:45,958 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 19), 'features.5': (32, 32), 'features.7': (38, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 35.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.04 GiB memory in use. Including non-PyTorch memory, this process has 37.28 GiB memory in use. Of the allocated memory 36.58 GiB is allocated by PyTorch, and 301.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:32:45,989 - MainProcess - INFO - Compressing to:features.0:(1, 38), features.2:(19, 19), features.5:(22, 38), features.7:(38, 51), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:32:45,992 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 16), features.5:(32, 32), features.7:(38, 38), features.10:(51, 89), features.12:(102, 64), features.14:(102, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 11:32:46,051 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 19), features.5:(16, 44), features.7:(44, 32), features.10:(57, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=38, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "2025-03-30 11:33:03,306 - MainProcess - INFO - finetuning:features.0:(1, 38), features.2:(19, 19), features.5:(22, 38), features.7:(38, 51), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:33:03,313 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 16), features.5:(32, 32), features.7:(38, 38), features.10:(51, 89), features.12:(102, 64), features.14:(102, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 11:33:09,090 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 19), features.5:(16, 44), features.7:(44, 32), features.10:(57, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:36:56,958 - MainProcess - ERROR - Error processing config: {'features.0': (1, 38), 'features.2': (19, 19), 'features.5': (22, 38), 'features.7': (38, 51), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 113.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 7.52 GiB memory in use. Including non-PyTorch memory, this process has 36.72 GiB memory in use. Of the allocated memory 31.46 GiB is allocated by PyTorch, and 4.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:36:57,164 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 19), features.5:(16, 32), features.7:(38, 44), features.10:(32, 64), features.12:(76, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 11:37:16,315 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 19), features.5:(16, 32), features.7:(38, 44), features.10:(32, 64), features.12:(76, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1441\n",
      "Epoch 1/3, Loss: 0.0549\n",
      "Epoch 1/3, Loss: 0.1483\n",
      "Epoch 1/3, Loss: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:54:41,281 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 19), 'features.5': (16, 32), 'features.7': (38, 44), 'features.10': (32, 64), 'features.12': (76, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 633.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 6.47 GiB memory in use. Including non-PyTorch memory, this process has 37.27 GiB memory in use. Of the allocated memory 33.44 GiB is allocated by PyTorch, and 3.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:54:41,454 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 22), features.5:(22, 44), features.7:(44, 32), features.10:(44, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 11:55:02,706 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 22), features.5:(22, 44), features.7:(44, 32), features.10:(44, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 11:57:01,332 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 22), 'features.5': (22, 44), 'features.7': (44, 32), 'features.10': (44, 76), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 91.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 6.47 GiB memory in use. Including non-PyTorch memory, this process has 37.79 GiB memory in use. Of the allocated memory 32.76 GiB is allocated by PyTorch, and 4.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:57:01,565 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(19, 22), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 11:57:23,996 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(19, 22), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:05:36,151 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (19, 22), 'features.5': (22, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 121.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 6.10 GiB memory in use. Including non-PyTorch memory, this process has 38.14 GiB memory in use. Of the allocated memory 33.56 GiB is allocated by PyTorch, and 4.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 12:05:36,418 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 28), features.5:(19, 32), features.7:(32, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 12:05:59,269 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 28), features.5:(19, 32), features.7:(32, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 12:06:34,543 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 28), 'features.5': (19, 32), 'features.7': (32, 38), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 31.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 6.29 GiB memory in use. Including non-PyTorch memory, this process has 38.03 GiB memory in use. Of the allocated memory 33.32 GiB is allocated by PyTorch, and 4.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 12:06:34,885 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 16), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(76, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 12:06:55,944 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 16), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(76, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 12:07:49,006 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 16), 'features.5': (19, 32), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 243.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 6.29 GiB memory in use. Including non-PyTorch memory, this process has 37.83 GiB memory in use. Of the allocated memory 34.98 GiB is allocated by PyTorch, and 2.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 12:07:49,078 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 16), 'features.5': (32, 32), 'features.7': (38, 38), 'features.10': (51, 89), 'features.12': (102, 64), 'features.14': (102, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 391.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 6.29 GiB memory in use. Including non-PyTorch memory, this process has 37.68 GiB memory in use. Of the allocated memory 33.13 GiB is allocated by PyTorch, and 4.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 12:07:49,110 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(16, 48), features.5:(32, 32), features.7:(32, 51), features.10:(32, 76), features.12:(102, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 12:07:49,113 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(16, 16), features.5:(35, 32), features.7:(38, 38), features.10:(32, 64), features.12:(89, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 153)\n",
      "2025-03-30 12:08:10,000 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(16, 48), features.5:(32, 32), features.7:(32, 51), features.10:(32, 76), features.12:(102, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 12:08:12,338 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(16, 16), features.5:(35, 32), features.7:(38, 38), features.10:(32, 64), features.12:(89, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:08:54,132 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (16, 48), 'features.5': (32, 32), 'features.7': (32, 51), 'features.10': (32, 76), 'features.12': (102, 102), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 569.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 6.29 GiB memory in use. Including non-PyTorch memory, this process has 37.51 GiB memory in use. Of the allocated memory 33.56 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 12:08:54,337 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(32, 19), features.5:(25, 32), features.7:(32, 44), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 12:09:16,891 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(32, 19), features.5:(25, 32), features.7:(32, 44), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0325\n",
      "Epoch 1/3, Loss: 0.0690\n",
      "Epoch 1/3, Loss: 0.1547\n",
      "Epoch 3/3, Loss: 0.0215\n",
      "Epoch 3/3, Loss: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:32:27,457 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(16, 19), features.5:(16, 44), features.7:(44, 32), features.10:(57, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121449785,\n",
      "    \"flops\": 4768078346,\n",
      "    \"accuracy\": 0.9937,\n",
      "    \"inference_time\": 0.6054707864287553,\n",
      "    \"compression_rate\": 1.1058192816067973,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:32:27,742 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 22), features.5:(19, 32), features.7:(32, 32), features.10:(38, 102), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 12:32:49,738 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 22), features.5:(19, 32), features.7:(32, 32), features.10:(38, 102), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:38:06,833 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 22), features.2:(19, 19), features.5:(16, 32), features.7:(57, 44), features.10:(51, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121453071,\n",
      "    \"flops\": 4907028234,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.6317723961645884,\n",
      "    \"compression_rate\": 1.1057893628725124,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:38:07,026 - MainProcess - INFO - Compressing to:features.0:(1, 35), features.2:(19, 25), features.5:(25, 32), features.7:(32, 44), features.10:(44, 76), features.12:(76, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=35, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "2025-03-30 12:38:30,217 - MainProcess - INFO - finetuning:features.0:(1, 35), features.2:(19, 25), features.5:(25, 32), features.7:(32, 44), features.10:(44, 76), features.12:(76, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0324\n",
      "Epoch 3/3, Loss: 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:47:28,669 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(32, 19), features.5:(25, 32), features.7:(32, 44), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121387401,\n",
      "    \"flops\": 4858896906,\n",
      "    \"accuracy\": 0.9929,\n",
      "    \"inference_time\": 0.4065283129422781,\n",
      "    \"compression_rate\": 1.1063875895983637,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:47:28,836 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(22, 32), features.5:(25, 44), features.7:(32, 38), features.10:(32, 89), features.12:(76, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:47:45,605 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(22, 32), features.5:(25, 44), features.7:(32, 38), features.10:(32, 89), features.12:(76, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0262\n",
      "Epoch 1/3, Loss: 0.1487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:52:49,768 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 25), features.2:(16, 16), features.5:(35, 32), features.7:(38, 38), features.10:(32, 64), features.12:(89, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 153)\",\n",
      "    \"params\": 121519902,\n",
      "    \"flops\": 4885954314,\n",
      "    \"accuracy\": 0.9919,\n",
      "    \"inference_time\": 0.31090229534546027,\n",
      "    \"compression_rate\": 1.1051812237307432,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:52:49,947 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(48, 16), features.5:(28, 38), features.7:(38, 32), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 12:53:05,721 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(48, 16), features.5:(28, 38), features.7:(38, 32), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0640\n",
      "Epoch 2/3, Loss: 0.0264\n",
      "Epoch 2/3, Loss: 0.0260\n",
      "Epoch 2/3, Loss: 0.0326\n",
      "Epoch 1/3, Loss: 0.0583\n",
      "Epoch 3/3, Loss: 0.0201\n",
      "Epoch 3/3, Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 13:07:39,794 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(22, 32), features.5:(25, 44), features.7:(32, 38), features.10:(32, 89), features.12:(76, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121414805,\n",
      "    \"flops\": 5028115466,\n",
      "    \"accuracy\": 0.9937,\n",
      "    \"inference_time\": 0.2462309054761429,\n",
      "    \"compression_rate\": 1.1061378717364823,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 13:07:39,999 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 19), features.5:(16, 32), features.7:(32, 32), features.10:(51, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 13:07:55,679 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 19), features.5:(16, 32), features.7:(32, 32), features.10:(51, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 13:09:21,426 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(16, 22), features.5:(19, 32), features.7:(32, 32), features.10:(38, 102), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121456205,\n",
      "    \"flops\": 4711893770,\n",
      "    \"accuracy\": 0.9926,\n",
      "    \"inference_time\": 0.26740655119505147,\n",
      "    \"compression_rate\": 1.105760829592856,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 13:09:21,543 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 35), features.5:(16, 32), features.7:(57, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 13:09:35,721 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 35), features.5:(16, 32), features.7:(57, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0263\n",
      "Epoch 1/3, Loss: 0.1297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 13:15:17,975 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 35), features.2:(19, 25), features.5:(25, 32), features.7:(32, 44), features.10:(44, 76), features.12:(76, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121458513,\n",
      "    \"flops\": 4902399498,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.3103430301520475,\n",
      "    \"compression_rate\": 1.1057398175128326,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 13:15:18,112 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(35, 16), features.5:(22, 32), features.7:(38, 51), features.10:(57, 76), features.12:(102, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 13:15:34,095 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(35, 16), features.5:(22, 32), features.7:(38, 51), features.10:(57, 76), features.12:(102, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0342\n",
      "Epoch 3/3, Loss: 0.0207\n",
      "Epoch 1/3, Loss: 0.0686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 13:22:04,293 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(48, 16), features.5:(28, 38), features.7:(38, 32), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121425265,\n",
      "    \"flops\": 5043644938,\n",
      "    \"accuracy\": 0.9939,\n",
      "    \"inference_time\": 0.31146830054605085,\n",
      "    \"compression_rate\": 1.1060425851242737,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 13:22:04,449 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(22, 16), features.5:(28, 38), features.7:(32, 32), features.10:(38, 64), features.12:(76, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 13:22:04,449 - MainProcess - INFO - Evaluated 20 configurations, found 20 accepted models\n",
      "2025-03-30 13:22:21,086 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(22, 16), features.5:(28, 38), features.7:(32, 32), features.10:(38, 64), features.12:(76, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0267\n",
      "Epoch 1/3, Loss: 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 13:26:55,918 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(16, 19), features.5:(16, 32), features.7:(32, 32), features.10:(51, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121361058,\n",
      "    \"flops\": 4635249930,\n",
      "    \"accuracy\": 0.993,\n",
      "    \"inference_time\": 0.30927536391402,\n",
      "    \"compression_rate\": 1.1066277454502744,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 13:26:56,069 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 16), features.5:(16, 38), features.7:(38, 32), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 13:27:12,794 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 16), features.5:(16, 38), features.7:(38, 32), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0267\n",
      "Epoch 1/3, Loss: 0.1336\n",
      "Epoch 1/3, Loss: 0.1349\n",
      "Epoch 2/3, Loss: 0.0327\n",
      "Epoch 2/3, Loss: 0.0332\n",
      "Epoch 3/3, Loss: 0.0217\n",
      "Epoch 2/3, Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 13:41:13,835 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 22), features.2:(19, 35), features.5:(16, 32), features.7:(57, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121440208,\n",
      "    \"flops\": 5011657738,\n",
      "    \"accuracy\": 0.9939,\n",
      "    \"inference_time\": 0.30227054911813916,\n",
      "    \"compression_rate\": 1.1059064885659615,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 13:41:13,992 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 51), features.5:(19, 32), features.7:(64, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 13:41:30,785 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 51), features.5:(19, 32), features.7:(64, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0270\n",
      "Epoch 3/3, Loss: 0.0268\n",
      "Epoch 3/3, Loss: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 13:46:41,505 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(22, 16), features.5:(16, 38), features.7:(38, 32), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121352558,\n",
      "    \"flops\": 4673170442,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.23496502169631342,\n",
      "    \"compression_rate\": 1.1067052579147116,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 13:46:41,666 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 16), features.5:(16, 51), features.7:(32, 51), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 13:46:57,785 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 16), features.5:(16, 51), features.7:(32, 51), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 13:48:02,223 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(22, 16), features.5:(28, 38), features.7:(32, 32), features.10:(38, 64), features.12:(76, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121394178,\n",
      "    \"flops\": 4786304778,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.2206992207059435,\n",
      "    \"compression_rate\": 1.1063258239616731,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 13:48:02,337 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 22), features.5:(32, 51), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 13:48:19,077 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 22), features.5:(32, 51), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 13:48:52,140 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(35, 16), features.5:(22, 32), features.7:(38, 51), features.10:(57, 76), features.12:(102, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121425548,\n",
      "    \"flops\": 3817107722,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.2456621485910598,\n",
      "    \"compression_rate\": 1.1060400073302532,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 13:48:52,271 - MainProcess - INFO - Compressing to:features.0:(2, 41), features.2:(41, 16), features.5:(16, 44), features.7:(57, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 102), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 153), features.26:(153, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=41, which is larger than max(matrix.shape)=18. Setting n_eigenvecs to 18.\n",
      "  warnings.warn(\n",
      "2025-03-30 13:49:08,987 - MainProcess - INFO - finetuning:features.0:(2, 41), features.2:(41, 16), features.5:(16, 44), features.7:(57, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 102), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 153), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1372\n",
      "Epoch 1/3, Loss: 0.1873\n",
      "Epoch 1/3, Loss: 0.0654\n",
      "Epoch 2/3, Loss: 0.0358\n",
      "Epoch 2/3, Loss: 0.0330\n",
      "Epoch 1/3, Loss: 0.0603\n",
      "Epoch 3/3, Loss: 0.0276\n",
      "Epoch 2/3, Loss: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 14:08:34,521 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(19, 16), features.5:(16, 51), features.7:(32, 51), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121396654,\n",
      "    \"flops\": 4736116234,\n",
      "    \"accuracy\": 0.9923,\n",
      "    \"inference_time\": 0.47069007474652275,\n",
      "    \"compression_rate\": 1.1063032593962598,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 14:08:34,759 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(32, 22), features.5:(19, 38), features.7:(51, 57), features.10:(32, 128), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:08:57,274 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(32, 22), features.5:(19, 38), features.7:(51, 57), features.10:(32, 128), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0250\n",
      "Epoch 2/3, Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 14:16:17,216 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(16, 51), features.5:(19, 32), features.7:(64, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121467582,\n",
      "    \"flops\": 5152275978,\n",
      "    \"accuracy\": 0.9933,\n",
      "    \"inference_time\": 0.4481077199275833,\n",
      "    \"compression_rate\": 1.1056572608813435,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 14:16:17,343 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 16), features.5:(25, 38), features.7:(38, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 14:16:37,867 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 16), features.5:(25, 38), features.7:(38, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 14:20:11,478 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(19, 22), features.5:(32, 51), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121384667,\n",
      "    \"flops\": 4807591946,\n",
      "    \"accuracy\": 0.9943,\n",
      "    \"inference_time\": 0.35144321174378607,\n",
      "    \"compression_rate\": 1.1064125092504475,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 14:20:11,722 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(25, 19), features.5:(28, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:20:47,495 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(25, 19), features.5:(28, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:20:48,422 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (32, 22), 'features.5': (19, 38), 'features.7': (51, 57), 'features.10': (32, 128), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 260.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 31.21 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 7.86 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 30.51 GiB is allocated by PyTorch, and 303.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:20:48,442 - MainProcess - ERROR - Error processing config: {'features.0': (2, 41), 'features.2': (41, 16), 'features.5': (16, 44), 'features.7': (57, 32), 'features.10': (57, 64), 'features.12': (64, 64), 'features.14': (64, 102), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 153), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 100.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 31.37 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 7.86 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 306.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:20:48,445 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (25, 19), 'features.5': (28, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (76, 76), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 4.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 31.46 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 7.86 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 30.71 GiB is allocated by PyTorch, and 362.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:20:48,470 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 16), 'features.5': (25, 38), 'features.7': (38, 32), 'features.10': (32, 76), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 398.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 31.08 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 7.86 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 30.30 GiB is allocated by PyTorch, and 386.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:20:48,531 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(22, 19), features.5:(22, 38), features.7:(38, 32), features.10:(38, 64), features.12:(89, 64), features.14:(102, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:20:48,532 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(22, 25), features.5:(19, 32), features.7:(38, 32), features.10:(51, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(153, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:20:48,538 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 19), features.5:(25, 51), features.7:(32, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:20:48,538 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(25, 19), features.5:(19, 32), features.7:(70, 32), features.10:(44, 76), features.12:(89, 64), features.14:(64, 64), features.17:(89, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:21:19,167 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(22, 19), features.5:(22, 38), features.7:(38, 32), features.10:(38, 64), features.12:(89, 64), features.14:(102, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:21:21,240 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 19), features.5:(25, 51), features.7:(32, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:21:21,241 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(22, 25), features.5:(19, 32), features.7:(38, 32), features.10:(51, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(153, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:21:21,741 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (22, 19), 'features.5': (22, 38), 'features.7': (38, 32), 'features.10': (38, 64), 'features.12': (89, 64), 'features.14': (102, 64), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 31.45 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 7.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 30.76 GiB is allocated by PyTorch, and 298.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:21:21,749 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 19), 'features.5': (25, 51), 'features.7': (32, 38), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 66.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 31.40 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 7.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 304.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:21:21,754 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (22, 25), 'features.5': (19, 32), 'features.7': (38, 32), 'features.10': (51, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (76, 128), 'features.19': (153, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 68.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 31.40 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 7.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 30.70 GiB is allocated by PyTorch, and 303.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:21:21,826 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 16), features.5:(25, 32), features.7:(44, 38), features.10:(38, 64), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:21:21,834 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(16, 19), features.5:(16, 38), features.7:(38, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:21:21,847 - MainProcess - INFO - Compressing to:features.0:(2, 38), features.2:(16, 22), features.5:(19, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 102), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:21:23,785 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(25, 19), features.5:(19, 32), features.7:(70, 32), features.10:(44, 76), features.12:(89, 64), features.14:(64, 64), features.17:(89, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=38, which is larger than max(matrix.shape)=18. Setting n_eigenvecs to 18.\n",
      "  warnings.warn(\n",
      "2025-03-30 14:21:50,727 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(16, 19), features.5:(16, 38), features.7:(38, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:21:53,951 - MainProcess - INFO - finetuning:features.0:(2, 38), features.2:(16, 22), features.5:(19, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 102), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:21:55,458 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 16), features.5:(25, 32), features.7:(44, 38), features.10:(38, 64), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:21:56,350 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (16, 19), 'features.5': (16, 38), 'features.7': (38, 32), 'features.10': (38, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 54.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 31.00 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.27 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 29.52 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:21:56,369 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 16), features.5:(28, 38), features.7:(44, 32), features.10:(44, 64), features.12:(64, 76), features.14:(89, 89), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:21:56,541 - MainProcess - ERROR - Error processing config: {'features.0': (2, 38), 'features.2': (16, 22), 'features.5': (19, 38), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 102), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 136.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.92 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.27 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 30.20 GiB is allocated by PyTorch, and 329.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:21:56,563 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (25, 19), 'features.5': (19, 32), 'features.7': (70, 32), 'features.10': (44, 76), 'features.12': (89, 64), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 136.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.92 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.27 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 30.27 GiB is allocated by PyTorch, and 260.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:21:56,577 - MainProcess - INFO - Compressing to:features.0:(1, 28), features.2:(28, 19), features.5:(19, 76), features.7:(32, 32), features.10:(38, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(179, 128), features.24:(128, 153), features.26:(153, 153), features.28:(128, 153)\n",
      "2025-03-30 14:21:56,603 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(22, 16), features.5:(28, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(89, 89), features.17:(76, 128), features.19:(128, 128), features.21:(179, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=28, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "2025-03-30 14:22:26,535 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 16), features.5:(28, 38), features.7:(44, 32), features.10:(44, 64), features.12:(64, 76), features.14:(89, 89), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:22:28,256 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(22, 16), features.5:(28, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(89, 89), features.17:(76, 128), features.19:(128, 128), features.21:(179, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:22:32,342 - MainProcess - INFO - finetuning:features.0:(1, 28), features.2:(28, 19), features.5:(19, 76), features.7:(32, 32), features.10:(38, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(179, 128), features.24:(128, 153), features.26:(153, 153), features.28:(128, 153)\n",
      "2025-03-30 14:22:33,228 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 16), 'features.5': (25, 32), 'features.7': (44, 38), 'features.10': (38, 64), 'features.12': (64, 76), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 14.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.44 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 29.45 GiB is allocated by PyTorch, and 603.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:22:33,233 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (22, 16), 'features.5': (28, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (89, 89), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (179, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 14.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.44 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 29.44 GiB is allocated by PyTorch, and 615.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:22:33,252 - MainProcess - ERROR - Error processing config: {'features.0': (1, 28), 'features.2': (28, 19), 'features.5': (19, 76), 'features.7': (32, 32), 'features.10': (38, 76), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (179, 128), 'features.24': (128, 153), 'features.26': (153, 153), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 14.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.44 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 566.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:22:33,363 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(22, 19), features.5:(16, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:22:33,368 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(22, 16), features.5:(28, 44), features.7:(32, 32), features.10:(32, 64), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:22:33,375 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(32, 19), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 115), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:23:00,906 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(22, 19), features.5:(16, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:23:03,979 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(22, 16), features.5:(28, 44), features.7:(32, 32), features.10:(32, 64), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:23:05,331 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(32, 19), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 115), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:23:06,219 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (22, 19), 'features.5': (16, 38), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 34.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.42 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 29.12 GiB is allocated by PyTorch, and 919.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:23:06,224 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (22, 16), 'features.5': (28, 44), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 102), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 34.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.42 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 29.44 GiB is allocated by PyTorch, and 595.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:23:06,226 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 16), features.5:(25, 32), features.7:(32, 38), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:23:06,228 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (32, 19), 'features.5': (16, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 115), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 34.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.42 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 29.60 GiB is allocated by PyTorch, and 432.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:23:06,257 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(16, 22), features.5:(38, 57), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:23:06,260 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 22), features.5:(16, 32), features.7:(44, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 14:23:34,499 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 22), features.5:(16, 32), features.7:(44, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 14:23:34,502 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 16), features.5:(25, 32), features.7:(32, 38), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:23:40,996 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(16, 22), features.5:(38, 57), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:23:42,502 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 22), 'features.5': (16, 32), 'features.7': (44, 44), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 248.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.21 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 29.11 GiB is allocated by PyTorch, and 715.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:23:42,511 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 16), 'features.5': (25, 32), 'features.7': (32, 38), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 54.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.41 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.32 GiB memory in use. Of the allocated memory 29.47 GiB is allocated by PyTorch, and 545.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:23:42,621 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 22), features.5:(19, 38), features.7:(51, 38), features.10:(38, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:23:42,627 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 25), features.5:(25, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 179)\n",
      "2025-03-30 14:24:19,600 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 22), features.5:(19, 38), features.7:(51, 38), features.10:(38, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:24:22,831 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 25), features.5:(25, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 179)\n",
      "2025-03-30 14:24:23,682 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 25), 'features.5': (25, 38), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 179)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 374.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.08 GiB is allocated by PyTorch, and 777.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:24:23,761 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 16), features.5:(16, 38), features.7:(32, 51), features.10:(38, 64), features.12:(64, 76), features.14:(76, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:24:23,769 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 16), 'features.5': (28, 38), 'features.7': (44, 32), 'features.10': (44, 64), 'features.12': (64, 76), 'features.14': (89, 89), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 106.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.50 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.59 GiB is allocated by PyTorch, and 518.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:24:23,850 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (19, 22), 'features.5': (19, 38), 'features.7': (51, 38), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (89, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 153), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 204.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.41 GiB memory in use. Process 3634912 has 2.94 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.59 GiB is allocated by PyTorch, and 422.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:24:23,855 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 25), features.5:(22, 64), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(153, 128), features.28:(153, 128)\n",
      "2025-03-30 14:24:23,876 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(32, 16), features.5:(41, 32), features.7:(32, 44), features.10:(32, 64), features.12:(64, 89), features.14:(64, 128), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:24:47,972 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 16), features.5:(16, 38), features.7:(32, 51), features.10:(38, 64), features.12:(64, 76), features.14:(76, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:24:51,328 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 25), features.5:(22, 64), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(153, 128), features.28:(153, 128)\n",
      "2025-03-30 14:24:51,619 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(32, 16), features.5:(41, 32), features.7:(32, 44), features.10:(32, 64), features.12:(64, 89), features.14:(64, 128), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:24:53,218 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (32, 16), 'features.5': (41, 32), 'features.7': (32, 44), 'features.10': (32, 64), 'features.12': (64, 89), 'features.14': (64, 128), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 100.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.51 GiB memory in use. Process 3634912 has 2.95 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.80 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:24:53,222 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (19, 25), 'features.5': (22, 64), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (153, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 100.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.51 GiB memory in use. Process 3634912 has 2.95 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.80 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:24:53,228 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 16), 'features.5': (16, 38), 'features.7': (32, 51), 'features.10': (38, 64), 'features.12': (64, 76), 'features.14': (76, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 100.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.51 GiB memory in use. Process 3634912 has 2.95 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.80 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:24:53,602 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(25, 19), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(102, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:24:53,603 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 25), features.5:(25, 32), features.7:(51, 51), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(179, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:24:53,605 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 16), features.5:(19, 32), features.7:(32, 32), features.10:(38, 89), features.12:(64, 64), features.14:(64, 64), features.17:(64, 179), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:25:15,739 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 25), features.5:(25, 32), features.7:(51, 51), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(179, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:25:15,753 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 16), features.5:(19, 32), features.7:(32, 32), features.10:(38, 89), features.12:(64, 64), features.14:(64, 64), features.17:(64, 179), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:25:22,521 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(25, 19), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(102, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:25:23,353 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (25, 19), 'features.5': (16, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (102, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 298.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.31 GiB memory in use. Process 3634912 has 2.95 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.19 GiB is allocated by PyTorch, and 738.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:25:23,364 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 19), features.5:(28, 32), features.7:(32, 38), features.10:(38, 76), features.12:(89, 76), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:25:23,422 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (16, 22), 'features.5': (38, 57), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 54.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.55 GiB memory in use. Process 3634912 has 2.95 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.65 GiB is allocated by PyTorch, and 515.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:25:23,510 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 25), 'features.5': (25, 32), 'features.7': (51, 51), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (179, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 152.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.46 GiB memory in use. Process 3634912 has 2.95 GiB memory in use. Process 3734524 has 8.87 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.61 GiB is allocated by PyTorch, and 449.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:25:23,513 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 25), features.5:(38, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:25:23,553 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(25, 22), features.5:(48, 38), features.7:(38, 51), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:25:47,125 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(25, 22), features.5:(48, 38), features.7:(38, 51), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:25:50,127 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 19), features.5:(28, 32), features.7:(32, 38), features.10:(38, 76), features.12:(89, 76), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:25:50,220 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 25), features.5:(38, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:25:50,655 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (19, 25), 'features.5': (38, 38), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 194.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.27 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 393.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:25:50,776 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(28, 19), features.5:(16, 38), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:25:50,829 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 16), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (38, 89), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 179), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 338.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.13 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.39 GiB is allocated by PyTorch, and 348.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:25:50,844 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 19), features.5:(19, 32), features.7:(32, 44), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:26:10,473 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(28, 19), features.5:(16, 38), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:26:14,154 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 19), features.5:(19, 32), features.7:(32, 44), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:26:14,963 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (25, 22), 'features.5': (48, 38), 'features.7': (38, 51), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 152.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.31 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.11 GiB is allocated by PyTorch, and 818.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:26:14,969 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 19), 'features.5': (28, 32), 'features.7': (32, 38), 'features.10': (38, 76), 'features.12': (89, 76), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 54.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.41 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.16 GiB is allocated by PyTorch, and 867.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:26:14,974 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (28, 19), 'features.5': (16, 38), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 54.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.41 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.82 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:26:15,004 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 16), features.5:(54, 38), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:26:15,008 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(19, 16), features.5:(19, 38), features.7:(32, 44), features.10:(44, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:26:15,011 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(22, 16), features.5:(16, 51), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 128), features.19:(179, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:26:37,213 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 16), features.5:(54, 38), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:26:40,435 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(19, 16), features.5:(19, 38), features.7:(32, 44), features.10:(44, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:26:42,816 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(22, 16), features.5:(16, 51), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 128), features.19:(179, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:26:43,629 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 16), 'features.5': (54, 38), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.40 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.54 GiB is allocated by PyTorch, and 470.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:26:43,636 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 19), 'features.5': (19, 32), 'features.7': (32, 44), 'features.10': (44, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.40 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 519.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:26:43,643 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (22, 16), 'features.5': (16, 51), 'features.7': (44, 32), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (179, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.40 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.49 GiB is allocated by PyTorch, and 521.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:26:43,649 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (19, 16), 'features.5': (19, 38), 'features.7': (32, 44), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 456.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.02 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.10 GiB is allocated by PyTorch, and 529.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:26:43,715 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(35, 35), features.5:(22, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 76), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 14:26:43,716 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 28), features.5:(19, 32), features.7:(32, 38), features.10:(38, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\n",
      "2025-03-30 14:26:43,716 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 19), features.5:(19, 44), features.7:(51, 32), features.10:(38, 64), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:26:43,722 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 22), features.5:(19, 32), features.7:(38, 32), features.10:(32, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:27:02,958 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 22), features.5:(19, 32), features.7:(38, 32), features.10:(32, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:27:03,698 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 28), features.5:(19, 32), features.7:(32, 38), features.10:(38, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\n",
      "2025-03-30 14:27:07,410 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 19), features.5:(19, 44), features.7:(51, 32), features.10:(38, 64), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:27:07,696 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(35, 35), features.5:(22, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 76), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 14:27:08,391 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 22), 'features.5': (19, 32), 'features.7': (38, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 156.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.31 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.18 GiB is allocated by PyTorch, and 743.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:27:08,398 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (35, 35), 'features.5': (22, 38), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 352.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.12 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.07 GiB is allocated by PyTorch, and 658.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:27:08,561 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(25, 32), features.5:(44, 32), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(179, 128)\n",
      "2025-03-30 14:27:08,562 - MainProcess - INFO - Compressing to:features.0:(1, 32), features.2:(16, 16), features.5:(19, 44), features.7:(57, 32), features.10:(44, 102), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=32, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "2025-03-30 14:27:28,399 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(25, 32), features.5:(44, 32), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(179, 128)\n",
      "2025-03-30 14:27:31,488 - MainProcess - INFO - finetuning:features.0:(1, 32), features.2:(16, 16), features.5:(19, 44), features.7:(57, 32), features.10:(44, 102), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:27:32,286 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (25, 32), 'features.5': (44, 32), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (76, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (179, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 86.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.38 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.33 GiB is allocated by PyTorch, and 660.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:27:32,379 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 19), features.5:(19, 32), features.7:(44, 38), features.10:(32, 76), features.12:(102, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:27:32,428 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 19), 'features.5': (19, 44), 'features.7': (51, 32), 'features.10': (38, 64), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 50.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.41 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.64 GiB is allocated by PyTorch, and 384.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:27:32,432 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 28), 'features.5': (19, 32), 'features.7': (32, 38), 'features.10': (38, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 22.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.44 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.70 GiB is allocated by PyTorch, and 349.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:27:32,438 - MainProcess - ERROR - Error processing config: {'features.0': (1, 32), 'features.2': (16, 16), 'features.5': (19, 44), 'features.7': (57, 32), 'features.10': (44, 102), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 22.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.44 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.70 GiB is allocated by PyTorch, and 349.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:27:32,496 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 19), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:27:32,547 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 19), features.5:(19, 32), features.7:(44, 38), features.10:(32, 64), features.12:(64, 76), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 14:27:32,548 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 19), features.5:(25, 32), features.7:(32, 38), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:27:54,110 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 19), features.5:(19, 32), features.7:(44, 38), features.10:(32, 76), features.12:(102, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:27:54,174 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 19), features.5:(25, 32), features.7:(32, 38), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:27:58,329 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 19), features.5:(19, 32), features.7:(44, 38), features.10:(32, 64), features.12:(64, 76), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 14:27:58,613 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 19), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:28:00,057 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 19), 'features.5': (19, 32), 'features.7': (44, 38), 'features.10': (32, 76), 'features.12': (102, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 34.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.43 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.36 GiB is allocated by PyTorch, and 686.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:28:00,061 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 19), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 34.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.43 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.36 GiB is allocated by PyTorch, and 686.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:28:00,065 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (19, 19), 'features.5': (19, 32), 'features.7': (44, 38), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 34.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.43 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.36 GiB is allocated by PyTorch, and 686.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:28:00,082 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 25), features.5:(35, 38), features.7:(38, 57), features.10:(32, 64), features.12:(76, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:28:00,222 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 16), features.5:(16, 32), features.7:(64, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 14:28:00,223 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 19), features.5:(16, 44), features.7:(44, 38), features.10:(32, 64), features.12:(64, 76), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 14:28:22,242 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 25), features.5:(35, 38), features.7:(38, 57), features.10:(32, 64), features.12:(76, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:28:24,929 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 19), features.5:(16, 44), features.7:(44, 38), features.10:(32, 64), features.12:(64, 76), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 14:28:27,777 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 16), features.5:(16, 32), features.7:(64, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 14:28:28,552 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 19), 'features.5': (16, 44), 'features.7': (44, 38), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 10.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.45 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.22 GiB is allocated by PyTorch, and 849.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:28:28,572 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 35), features.5:(16, 96), features.7:(38, 38), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:28:28,698 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 19), 'features.5': (25, 32), 'features.7': (32, 38), 'features.10': (44, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 378.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.09 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.28 GiB is allocated by PyTorch, and 418.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:28:28,702 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 25), 'features.5': (35, 38), 'features.7': (38, 57), 'features.10': (32, 64), 'features.12': (76, 76), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 378.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.09 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.31 GiB is allocated by PyTorch, and 393.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:28:28,707 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 16), 'features.5': (16, 32), 'features.7': (64, 32), 'features.10': (38, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 314.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.16 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.06 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 387.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:28:28,712 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 25), features.5:(32, 32), features.7:(38, 51), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:28:28,776 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 25), features.5:(32, 32), features.7:(57, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:28:28,779 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(28, 19), features.5:(28, 32), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:28:53,211 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(28, 19), features.5:(28, 32), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:28:53,666 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 25), features.5:(32, 32), features.7:(38, 51), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:28:53,674 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 35), features.5:(16, 96), features.7:(38, 38), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:29:01,152 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 25), features.5:(32, 32), features.7:(57, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:29:01,522 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 25), 'features.5': (32, 32), 'features.7': (38, 51), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 308.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 29.97 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.57 GiB is allocated by PyTorch, and 1.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:29:01,526 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 25), 'features.5': (32, 32), 'features.7': (57, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 306.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 29.97 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 27.89 GiB is allocated by PyTorch, and 1.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:29:01,783 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (28, 19), 'features.5': (28, 32), 'features.7': (32, 44), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 308.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 29.97 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 27.88 GiB is allocated by PyTorch, and 1.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:29:01,793 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(22, 16), features.5:(22, 51), features.7:(51, 38), features.10:(32, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 14:29:01,885 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 19), features.5:(28, 38), features.7:(38, 32), features.10:(32, 102), features.12:(76, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:29:01,888 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(28, 16), features.5:(16, 38), features.7:(57, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(179, 128)\n",
      "2025-03-30 14:29:24,269 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(28, 16), features.5:(16, 38), features.7:(57, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(179, 128)\n",
      "2025-03-30 14:29:24,277 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(22, 16), features.5:(22, 51), features.7:(51, 38), features.10:(32, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 14:29:24,674 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 35), 'features.5': (16, 96), 'features.7': (38, 38), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 68.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.21 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 303.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:29:24,679 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (22, 16), 'features.5': (22, 51), 'features.7': (51, 38), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 42.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.23 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 286.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:29:24,720 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 32), features.5:(19, 38), features.7:(32, 32), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 179)\n",
      "2025-03-30 14:29:24,722 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(28, 32), features.5:(16, 32), features.7:(51, 32), features.10:(76, 89), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:29:26,435 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 19), features.5:(28, 38), features.7:(38, 32), features.10:(32, 102), features.12:(76, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:29:48,711 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(28, 32), features.5:(16, 32), features.7:(51, 32), features.10:(76, 89), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:29:48,714 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 32), features.5:(19, 38), features.7:(32, 32), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 179)\n",
      "2025-03-30 14:29:49,254 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 32), 'features.5': (19, 38), 'features.7': (32, 32), 'features.10': (44, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 179)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 36.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 957.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:29:49,259 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (19, 19), 'features.5': (28, 38), 'features.7': (38, 32), 'features.10': (32, 102), 'features.12': (76, 76), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 36.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 952.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:29:49,274 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (28, 16), 'features.5': (16, 38), 'features.7': (57, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (179, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 102.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.17 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.97 GiB is allocated by PyTorch, and 817.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:29:49,297 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(19, 16), features.5:(16, 32), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 179), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:29:49,322 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 28), features.5:(19, 38), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:29:49,324 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 35), features.5:(19, 38), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(76, 76), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:30:12,074 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 28), features.5:(19, 38), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:30:14,699 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 35), features.5:(19, 38), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(76, 76), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:30:14,978 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(19, 16), features.5:(16, 32), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 179), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:30:16,436 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (19, 16), 'features.5': (16, 32), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (89, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 179), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 60.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.21 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 842.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:30:16,441 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 35), 'features.5': (19, 38), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (76, 76), 'features.17': (102, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 60.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.21 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 842.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:30:16,484 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(19, 16), features.5:(16, 32), features.7:(32, 44), features.10:(44, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:30:16,549 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(25, 19), features.5:(16, 44), features.7:(51, 38), features.10:(38, 76), features.12:(89, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:30:39,669 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(19, 16), features.5:(16, 32), features.7:(32, 44), features.10:(44, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:30:43,284 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(25, 19), features.5:(16, 44), features.7:(51, 38), features.10:(38, 76), features.12:(89, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:30:44,092 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (19, 16), 'features.5': (16, 32), 'features.7': (32, 44), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 164.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.11 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.94 GiB is allocated by PyTorch, and 792.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:30:44,096 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (19, 28), 'features.5': (19, 38), 'features.7': (32, 51), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 94.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.18 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.06 GiB is allocated by PyTorch, and 735.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:30:44,119 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (28, 32), 'features.5': (16, 32), 'features.7': (51, 32), 'features.10': (76, 89), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 486.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 29.80 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.67 GiB is allocated by PyTorch, and 745.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:30:44,153 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(35, 16), features.5:(19, 32), features.7:(38, 64), features.10:(57, 89), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 179), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:30:44,156 - MainProcess - INFO - Compressing to:features.0:(2, 38), features.2:(22, 16), features.5:(19, 32), features.7:(70, 38), features.10:(32, 76), features.12:(76, 115), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:30:44,157 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(25, 51), features.5:(19, 32), features.7:(51, 38), features.10:(38, 64), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(153, 128), features.21:(153, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:31:07,356 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(35, 16), features.5:(19, 32), features.7:(38, 64), features.10:(57, 89), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 179), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:31:10,378 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(25, 51), features.5:(19, 32), features.7:(51, 38), features.10:(38, 64), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(153, 128), features.21:(153, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:31:10,675 - MainProcess - INFO - finetuning:features.0:(2, 38), features.2:(22, 16), features.5:(19, 32), features.7:(70, 38), features.10:(32, 76), features.12:(76, 115), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:31:12,174 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (25, 51), 'features.5': (19, 32), 'features.7': (51, 38), 'features.10': (38, 64), 'features.12': (76, 64), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (153, 128), 'features.21': (153, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 30.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.08 GiB is allocated by PyTorch, and 777.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:31:12,196 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (35, 16), 'features.5': (19, 32), 'features.7': (38, 64), 'features.10': (57, 89), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 179), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 30.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.13 GiB is allocated by PyTorch, and 728.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:31:12,196 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (25, 19), 'features.5': (16, 44), 'features.7': (51, 38), 'features.10': (38, 76), 'features.12': (89, 76), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 30.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.08 GiB is allocated by PyTorch, and 777.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:31:12,200 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 22), features.5:(16, 44), features.7:(51, 32), features.10:(32, 64), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:31:12,282 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 16), features.5:(16, 64), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(89, 76), features.17:(115, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 14:31:12,297 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 16), features.5:(16, 57), features.7:(32, 32), features.10:(32, 76), features.12:(64, 76), features.14:(76, 76), features.17:(64, 128), features.19:(153, 179), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:31:34,141 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 22), features.5:(16, 44), features.7:(51, 32), features.10:(32, 64), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:31:38,200 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 16), features.5:(16, 57), features.7:(32, 32), features.10:(32, 76), features.12:(64, 76), features.14:(76, 76), features.17:(64, 128), features.19:(153, 179), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:31:38,200 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 16), features.5:(16, 64), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(89, 76), features.17:(115, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 14:31:38,733 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 16), 'features.5': (16, 64), 'features.7': (32, 51), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (89, 76), 'features.17': (115, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 296.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 29.98 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.98 GiB is allocated by PyTorch, and 615.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:31:38,836 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 19), features.5:(22, 38), features.7:(32, 32), features.10:(38, 76), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:31:38,911 - MainProcess - ERROR - Error processing config: {'features.0': (2, 38), 'features.2': (22, 16), 'features.5': (19, 32), 'features.7': (70, 38), 'features.10': (32, 76), 'features.12': (76, 115), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 40.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.23 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 283.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:31:38,916 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 16), 'features.5': (16, 57), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 76), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (153, 179), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 38.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.23 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.56 GiB is allocated by PyTorch, and 280.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:31:38,920 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 22), 'features.5': (16, 44), 'features.7': (51, 32), 'features.10': (32, 64), 'features.12': (64, 102), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 40.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.23 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.56 GiB is allocated by PyTorch, and 280.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:31:38,924 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 16), features.5:(32, 44), features.7:(32, 38), features.10:(38, 76), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:31:38,980 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 19), features.5:(19, 38), features.7:(32, 38), features.10:(44, 64), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(153, 128), features.28:(128, 153)\n",
      "2025-03-30 14:31:38,982 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(16, 19), features.5:(38, 32), features.7:(38, 32), features.10:(32, 102), features.12:(76, 64), features.14:(64, 64), features.17:(89, 128), features.19:(153, 153), features.21:(153, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 14:32:02,308 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 19), features.5:(22, 38), features.7:(32, 32), features.10:(38, 76), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:32:04,407 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 16), features.5:(32, 44), features.7:(32, 38), features.10:(38, 76), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:32:07,275 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 19), features.5:(19, 38), features.7:(32, 38), features.10:(44, 64), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(153, 128), features.28:(128, 153)\n",
      "2025-03-30 14:32:09,032 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(16, 19), features.5:(38, 32), features.7:(38, 32), features.10:(32, 102), features.12:(76, 64), features.14:(64, 64), features.17:(89, 128), features.19:(153, 153), features.21:(153, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 14:32:09,810 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (16, 19), 'features.5': (38, 32), 'features.7': (38, 32), 'features.10': (32, 102), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (153, 153), 'features.21': (153, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 14.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.26 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.17 GiB is allocated by PyTorch, and 706.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:32:09,841 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 19), 'features.5': (22, 38), 'features.7': (32, 32), 'features.10': (38, 76), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.21 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.12 GiB is allocated by PyTorch, and 705.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:32:09,841 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 19), 'features.5': (19, 38), 'features.7': (32, 38), 'features.10': (44, 64), 'features.12': (76, 64), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 179), 'features.26': (153, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.21 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.12 GiB is allocated by PyTorch, and 705.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:32:09,905 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(22, 32), features.5:(19, 38), features.7:(44, 44), features.10:(38, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:32:09,989 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 22), features.5:(16, 32), features.7:(38, 44), features.10:(38, 64), features.12:(89, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:32:09,989 - MainProcess - INFO - Compressing to:features.0:(1, 32), features.2:(22, 38), features.5:(22, 38), features.7:(51, 38), features.10:(44, 64), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:32:31,475 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(22, 32), features.5:(19, 38), features.7:(44, 44), features.10:(38, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 14:32:35,524 - MainProcess - INFO - finetuning:features.0:(1, 32), features.2:(22, 38), features.5:(22, 38), features.7:(51, 38), features.10:(44, 64), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 14:32:35,587 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 22), features.5:(16, 32), features.7:(38, 44), features.10:(38, 64), features.12:(89, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:32:36,057 - MainProcess - ERROR - Error processing config: {'features.0': (1, 32), 'features.2': (22, 38), 'features.5': (22, 38), 'features.7': (51, 38), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (89, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 96.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.18 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.40 GiB is allocated by PyTorch, and 385.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:32:36,130 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(35, 19), features.5:(25, 38), features.7:(32, 32), features.10:(57, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 14:32:36,221 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 16), 'features.5': (32, 44), 'features.7': (32, 38), 'features.10': (38, 76), 'features.12': (64, 76), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 34.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.33 GiB is allocated by PyTorch, and 517.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:32:36,226 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (22, 32), 'features.5': (19, 38), 'features.7': (44, 44), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 34.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.33 GiB is allocated by PyTorch, and 517.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:32:36,231 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 22), 'features.5': (16, 32), 'features.7': (38, 44), 'features.10': (38, 64), 'features.12': (89, 76), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 34.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.24 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.33 GiB is allocated by PyTorch, and 517.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:32:36,236 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(25, 19), features.5:(22, 32), features.7:(32, 32), features.10:(38, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:32:36,285 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 16), features.5:(19, 38), features.7:(44, 64), features.10:(38, 76), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:32:36,288 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(28, 16), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 89), features.14:(89, 64), features.17:(115, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:01,741 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(25, 19), features.5:(22, 32), features.7:(32, 32), features.10:(38, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:01,747 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(35, 19), features.5:(25, 38), features.7:(32, 32), features.10:(57, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:04,734 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 16), features.5:(19, 38), features.7:(44, 64), features.10:(38, 76), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:05,012 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(28, 16), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 89), features.14:(89, 64), features.17:(115, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:05,860 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 16), 'features.5': (19, 38), 'features.7': (44, 64), 'features.10': (38, 76), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 326.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 29.95 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 664.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:33:05,864 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (28, 16), 'features.5': (22, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 89), 'features.14': (89, 64), 'features.17': (115, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 10.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.26 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.21 GiB is allocated by PyTorch, and 661.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:33:05,950 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (35, 19), 'features.5': (25, 38), 'features.7': (32, 32), 'features.10': (57, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 10.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.26 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.19 GiB is allocated by PyTorch, and 687.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:33:06,093 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 19), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:06,098 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(16, 16), features.5:(19, 32), features.7:(32, 32), features.10:(38, 64), features.12:(76, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:06,098 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 54), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(89, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:29,018 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 54), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(89, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:31,957 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(16, 16), features.5:(19, 32), features.7:(32, 32), features.10:(38, 64), features.12:(76, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:32,232 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 19), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:32,881 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (25, 19), 'features.5': (22, 32), 'features.7': (32, 32), 'features.10': (38, 76), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 340.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 29.94 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.49 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:33:32,936 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 54), 'features.5': (19, 32), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (89, 64), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 604.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 29.68 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 28.43 GiB is allocated by PyTorch, and 865.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:33:32,945 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(25, 35), features.5:(25, 32), features.7:(32, 32), features.10:(44, 76), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:32,947 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 16), features.5:(16, 64), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 102), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:33:56,115 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(25, 35), features.5:(25, 32), features.7:(32, 32), features.10:(44, 76), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:34:00,513 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 16), features.5:(16, 64), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 102), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:34:01,341 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 19), 'features.5': (16, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (89, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 20.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.25 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.51 GiB is allocated by PyTorch, and 343.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:34:01,417 - MainProcess - INFO - Compressing to:features.0:(2, 44), features.2:(22, 22), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:34:01,491 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (25, 35), 'features.5': (25, 32), 'features.7': (32, 32), 'features.10': (44, 76), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 10.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.26 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.38 GiB is allocated by PyTorch, and 492.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:34:01,495 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 16), 'features.5': (16, 64), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 102), 'features.17': (76, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 10.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.26 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.41 GiB is allocated by PyTorch, and 455.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:34:01,501 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (16, 16), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (76, 76), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 10.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 30.26 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 9.26 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 29.37 GiB is allocated by PyTorch, and 497.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 14:34:01,511 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(22, 28), features.5:(16, 44), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(153, 128), features.21:(128, 153), features.24:(153, 128), features.26:(153, 153), features.28:(128, 153)\n",
      "2025-03-30 14:34:01,556 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 19), features.5:(16, 32), features.7:(32, 44), features.10:(32, 89), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:34:01,558 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(28, 25), features.5:(38, 38), features.7:(44, 38), features.10:(32, 76), features.12:(76, 89), features.14:(76, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(153, 153)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=44, which is larger than max(matrix.shape)=18. Setting n_eigenvecs to 18.\n",
      "  warnings.warn(\n",
      "2025-03-30 14:34:25,643 - MainProcess - INFO - finetuning:features.0:(2, 44), features.2:(22, 22), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:34:27,228 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 19), features.5:(16, 32), features.7:(32, 44), features.10:(32, 89), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 14:34:29,595 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(28, 25), features.5:(38, 38), features.7:(44, 38), features.10:(32, 76), features.12:(76, 89), features.14:(76, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(153, 153)\n",
      "2025-03-30 14:34:31,995 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(22, 28), features.5:(16, 44), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(153, 128), features.21:(128, 153), features.24:(153, 128), features.26:(153, 153), features.28:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0699\n",
      "Epoch 1/3, Loss: 0.1803\n",
      "Epoch 1/3, Loss: 0.1517\n",
      "Epoch 1/3, Loss: 0.0594\n",
      "Epoch 2/3, Loss: 0.0265\n",
      "Epoch 2/3, Loss: 0.0360\n",
      "Epoch 2/3, Loss: 0.0330\n",
      "Epoch 3/3, Loss: 0.0210\n",
      "Epoch 2/3, Loss: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:02:12,532 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 44), features.2:(22, 22), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121393325,\n",
      "    \"flops\": 2189062154,\n",
      "    \"accuracy\": 0.9923,\n",
      "    \"inference_time\": 0.2854183180823195,\n",
      "    \"compression_rate\": 1.1063335978316764,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 15:02:12,879 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 19), features.5:(16, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 15:02:30,000 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 19), features.5:(16, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0276\n",
      "Epoch 3/3, Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:06:54,780 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(19, 19), features.5:(16, 32), features.7:(32, 44), features.10:(32, 89), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121344319,\n",
      "    \"flops\": 4662884362,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.2681860903519227,\n",
      "    \"compression_rate\": 1.1067804006547681,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 15:06:54,936 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 22), features.5:(28, 32), features.7:(32, 44), features.10:(38, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 204), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 15:06:54,936 - MainProcess - INFO - Evaluated 30 configurations, found 30 accepted models\n",
      "2025-03-30 15:07:12,102 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 22), features.5:(28, 32), features.7:(32, 44), features.10:(38, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 204), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0207\n",
      "Epoch 1/3, Loss: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:09:17,617 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(22, 28), features.5:(16, 44), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(153, 128), features.21:(128, 153), features.24:(153, 128), features.26:(153, 153), features.28:(128, 153)\",\n",
      "    \"params\": 121628815,\n",
      "    \"flops\": 4920965806,\n",
      "    \"accuracy\": 0.9924,\n",
      "    \"inference_time\": 0.2571086883544922,\n",
      "    \"compression_rate\": 1.1041915848641624,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 15:09:17,744 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(22, 19), features.5:(19, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 15:09:35,288 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(22, 19), features.5:(19, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 15:11:28,791 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 25), features.2:(28, 25), features.5:(38, 38), features.7:(44, 38), features.10:(32, 76), features.12:(76, 89), features.14:(76, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(153, 153)\",\n",
      "    \"params\": 121595702,\n",
      "    \"flops\": 4012165550,\n",
      "    \"accuracy\": 0.9928,\n",
      "    \"inference_time\": 0.267251000535969,\n",
      "    \"compression_rate\": 1.1044922788471585,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 15:11:28,916 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(38, 28), features.5:(19, 51), features.7:(32, 32), features.10:(38, 76), features.12:(76, 64), features.14:(89, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 15:11:49,949 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(38, 28), features.5:(19, 51), features.7:(32, 32), features.10:(38, 76), features.12:(76, 64), features.14:(89, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0669\n",
      "Epoch 2/3, Loss: 0.0350\n",
      "Epoch 1/3, Loss: 0.1589\n",
      "Epoch 3/3, Loss: 0.0269\n",
      "Epoch 1/3, Loss: 0.0621\n",
      "Epoch 2/3, Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:24:20,864 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(16, 19), features.5:(16, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121340702,\n",
      "    \"flops\": 4594895882,\n",
      "    \"accuracy\": 0.9899,\n",
      "    \"inference_time\": 0.2814407637164851,\n",
      "    \"compression_rate\": 1.106813392261403,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 15:24:21,006 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 25), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\n",
      "2025-03-30 15:24:38,182 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 25), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0350\n",
      "Epoch 3/3, Loss: 0.0214\n",
      "Epoch 1/3, Loss: 0.1592\n",
      "Epoch 2/3, Loss: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:33:44,995 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 22), features.2:(16, 22), features.5:(28, 32), features.7:(32, 44), features.10:(38, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 204), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121491177,\n",
      "    \"flops\": 3538116618,\n",
      "    \"accuracy\": 0.992,\n",
      "    \"inference_time\": 0.25764030357328443,\n",
      "    \"compression_rate\": 1.1054425293780799,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 15:33:45,146 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 16), features.5:(38, 89), features.7:(38, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 15:34:04,334 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 16), features.5:(38, 89), features.7:(38, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0278\n",
      "Epoch 2/3, Loss: 0.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:38:22,861 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(22, 19), features.5:(19, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121344770,\n",
      "    \"flops\": 2177619466,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.28572214889931324,\n",
      "    \"compression_rate\": 1.1067762871032678,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 15:38:23,028 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(25, 16), features.5:(19, 32), features.7:(44, 44), features.10:(32, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 15:38:40,200 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(25, 16), features.5:(19, 32), features.7:(44, 44), features.10:(32, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0209\n",
      "Epoch 1/3, Loss: 0.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:42:24,079 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(38, 28), features.5:(19, 51), features.7:(32, 32), features.10:(38, 76), features.12:(76, 64), features.14:(89, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121438550,\n",
      "    \"flops\": 5253531146,\n",
      "    \"accuracy\": 0.9937,\n",
      "    \"inference_time\": 0.2823080490096106,\n",
      "    \"compression_rate\": 1.105921587502486,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 15:42:24,237 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 16), features.5:(16, 57), features.7:(44, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 15:42:41,826 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 16), features.5:(16, 57), features.7:(44, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0267\n",
      "Epoch 1/3, Loss: 0.0670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:47:09,948 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(19, 25), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\",\n",
      "    \"params\": 121455969,\n",
      "    \"flops\": 4764290058,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.284872288916521,\n",
      "    \"compression_rate\": 1.10576297818677,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 15:47:10,165 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(22, 22), features.5:(28, 38), features.7:(32, 44), features.10:(32, 89), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 15:47:27,344 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(22, 22), features.5:(28, 38), features.7:(32, 44), features.10:(32, 89), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0266\n",
      "Epoch 1/3, Loss: 0.1744\n",
      "Epoch 1/3, Loss: 0.0686\n",
      "Epoch 2/3, Loss: 0.0254\n",
      "Epoch 3/3, Loss: 0.0208\n",
      "Epoch 2/3, Loss: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:00:45,690 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(16, 16), features.5:(38, 89), features.7:(38, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\",\n",
      "    \"params\": 121450505,\n",
      "    \"flops\": 3616943114,\n",
      "    \"accuracy\": 0.9919,\n",
      "    \"inference_time\": 0.29255039524880183,\n",
      "    \"compression_rate\": 1.105812725933087,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 16:00:45,847 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(32, 16), features.5:(22, 38), features.7:(44, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 153), features.21:(153, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:01:03,365 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(32, 16), features.5:(22, 38), features.7:(44, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 153), features.21:(153, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0351\n",
      "Epoch 3/3, Loss: 0.0198\n",
      "Epoch 3/3, Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:07:08,803 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(25, 16), features.5:(19, 32), features.7:(44, 44), features.10:(32, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121440265,\n",
      "    \"flops\": 4829370890,\n",
      "    \"accuracy\": 0.9939,\n",
      "    \"inference_time\": 0.24605820133427903,\n",
      "    \"compression_rate\": 1.1059059694904323,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 16:07:08,964 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(19, 28), features.5:(16, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:07:26,092 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(19, 28), features.5:(16, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:09:21,749 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 25), features.2:(22, 22), features.5:(28, 38), features.7:(32, 44), features.10:(32, 89), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121467605,\n",
      "    \"flops\": 2446690826,\n",
      "    \"accuracy\": 0.9917,\n",
      "    \"inference_time\": 0.2666582393038804,\n",
      "    \"compression_rate\": 1.1056570515241493,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 16:09:21,887 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 22), features.5:(16, 44), features.7:(32, 32), features.10:(38, 64), features.12:(76, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:09:21,888 - MainProcess - INFO - Evaluated 40 configurations, found 40 accepted models\n",
      "2025-03-30 16:09:38,836 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 22), features.5:(16, 44), features.7:(32, 32), features.10:(38, 64), features.12:(76, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:13:12,352 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(16, 16), features.5:(16, 57), features.7:(44, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121394366,\n",
      "    \"flops\": 4708393994,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.30299731374040023,\n",
      "    \"compression_rate\": 1.106324110626353,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 16:13:12,481 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(16, 19), features.5:(19, 51), features.7:(32, 32), features.10:(32, 64), features.12:(76, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:13:26,230 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(16, 19), features.5:(19, 51), features.7:(32, 32), features.10:(32, 64), features.12:(76, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:13:59,705 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (19, 22), 'features.5': (16, 44), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (76, 64), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 94.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.69 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.88 GiB is allocated by PyTorch, and 419.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:13:59,712 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (16, 19), 'features.5': (19, 51), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (76, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 94.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.69 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.93 GiB is allocated by PyTorch, and 370.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:13:59,734 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(25, 22), features.5:(19, 32), features.7:(38, 38), features.10:(44, 76), features.12:(76, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 153), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:13:59,764 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(22, 16), features.5:(32, 44), features.7:(32, 32), features.10:(51, 64), features.12:(76, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 153), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:14:17,252 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(25, 22), features.5:(19, 32), features.7:(38, 38), features.10:(44, 76), features.12:(76, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 153), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:14:18,202 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(22, 16), features.5:(32, 44), features.7:(32, 32), features.10:(51, 64), features.12:(76, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 153), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:14:25,365 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (25, 22), 'features.5': (19, 32), 'features.7': (38, 38), 'features.10': (44, 76), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (76, 153), 'features.19': (128, 153), 'features.21': (128, 153), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 356.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.44 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.72 GiB is allocated by PyTorch, and 320.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:14:25,379 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (32, 16), 'features.5': (22, 38), 'features.7': (44, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (128, 153), 'features.21': (153, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 196.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.59 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.93 GiB is allocated by PyTorch, and 262.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:14:25,402 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(25, 22), features.5:(16, 32), features.7:(76, 32), features.10:(32, 64), features.12:(76, 76), features.14:(115, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:14:25,445 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 22), features.5:(19, 38), features.7:(44, 32), features.10:(44, 76), features.12:(64, 64), features.14:(89, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:14:45,156 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(25, 22), features.5:(16, 32), features.7:(76, 32), features.10:(32, 64), features.12:(76, 76), features.14:(115, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:14:46,220 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 22), features.5:(19, 38), features.7:(44, 32), features.10:(44, 76), features.12:(64, 64), features.14:(89, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:14:46,743 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (25, 22), 'features.5': (16, 32), 'features.7': (76, 32), 'features.10': (32, 64), 'features.12': (76, 76), 'features.14': (115, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 326.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.47 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.35 GiB is allocated by PyTorch, and 735.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:14:46,797 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(25, 16), features.5:(25, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 179), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:15:04,669 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(25, 16), features.5:(25, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:15:10,987 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (19, 28), 'features.5': (16, 32), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 36.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.75 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.98 GiB is allocated by PyTorch, and 376.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:15:10,998 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (25, 16), 'features.5': (25, 32), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 179), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 10.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.78 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.97 GiB is allocated by PyTorch, and 409.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:15:10,998 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 22), 'features.5': (19, 38), 'features.7': (44, 32), 'features.10': (44, 76), 'features.12': (64, 64), 'features.14': (89, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 10.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.78 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.97 GiB is allocated by PyTorch, and 409.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:15:11,003 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (22, 16), 'features.5': (32, 44), 'features.7': (32, 32), 'features.10': (51, 64), 'features.12': (76, 64), 'features.14': (89, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (153, 153), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 10.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.78 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.96 GiB is allocated by PyTorch, and 422.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:15:11,068 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 19), features.5:(22, 32), features.7:(38, 32), features.10:(32, 89), features.12:(64, 115), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:15:11,071 - MainProcess - INFO - Compressing to:features.0:(1, 38), features.2:(22, 16), features.5:(22, 57), features.7:(51, 32), features.10:(70, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:15:11,131 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(35, 16), features.5:(28, 32), features.7:(38, 38), features.10:(102, 64), features.12:(76, 76), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:15:11,134 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 28), features.5:(28, 44), features.7:(44, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:15:33,010 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 19), features.5:(22, 32), features.7:(38, 32), features.10:(32, 89), features.12:(64, 115), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:15:33,506 - MainProcess - INFO - finetuning:features.0:(1, 38), features.2:(22, 16), features.5:(22, 57), features.7:(51, 32), features.10:(70, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:15:33,890 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 28), features.5:(28, 44), features.7:(44, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:15:33,890 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(35, 16), features.5:(28, 32), features.7:(38, 38), features.10:(102, 64), features.12:(76, 76), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:15:35,785 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (35, 16), 'features.5': (28, 32), 'features.7': (38, 38), 'features.10': (102, 64), 'features.12': (76, 76), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 36.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.75 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.76 GiB is allocated by PyTorch, and 603.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:15:35,859 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(16, 19), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:15:54,507 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(16, 19), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:16:02,199 - MainProcess - ERROR - Error processing config: {'features.0': (1, 38), 'features.2': (22, 16), 'features.5': (22, 57), 'features.7': (51, 32), 'features.10': (70, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 322.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.47 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.77 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:16:02,384 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(16, 35), features.5:(25, 32), features.7:(38, 38), features.10:(32, 102), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:16:20,740 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(16, 35), features.5:(25, 32), features.7:(38, 38), features.10:(32, 102), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:16:22,011 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 19), 'features.5': (22, 32), 'features.7': (38, 32), 'features.10': (32, 89), 'features.12': (64, 115), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 18.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.10 GiB is allocated by PyTorch, and 266.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:16:22,011 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (16, 35), 'features.5': (25, 32), 'features.7': (38, 38), 'features.10': (32, 102), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 18.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.12 GiB is allocated by PyTorch, and 254.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:16:22,015 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 28), 'features.5': (28, 44), 'features.7': (44, 44), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 18.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.12 GiB is allocated by PyTorch, and 251.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:16:22,022 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (16, 19), 'features.5': (19, 32), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 18.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.12 GiB is allocated by PyTorch, and 253.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:16:22,059 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(25, 16), features.5:(41, 51), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:16:22,061 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 25), features.5:(19, 44), features.7:(38, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(179, 128), features.21:(128, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:16:22,150 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 16), features.5:(22, 44), features.7:(38, 38), features.10:(38, 89), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:16:22,152 - MainProcess - INFO - Compressing to:features.0:(1, 38), features.2:(25, 38), features.5:(22, 44), features.7:(44, 32), features.10:(32, 76), features.12:(64, 102), features.14:(64, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:16:44,214 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 25), features.5:(19, 44), features.7:(38, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(179, 128), features.21:(128, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:16:44,287 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(25, 16), features.5:(41, 51), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:16:45,140 - MainProcess - INFO - finetuning:features.0:(1, 38), features.2:(25, 38), features.5:(22, 44), features.7:(44, 32), features.10:(32, 76), features.12:(64, 102), features.14:(64, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:16:46,342 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 16), features.5:(22, 44), features.7:(38, 38), features.10:(38, 89), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:16:46,831 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 25), 'features.5': (19, 44), 'features.7': (38, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (179, 128), 'features.21': (128, 128), 'features.24': (128, 179), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 50.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.74 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.99 GiB is allocated by PyTorch, and 348.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:16:46,838 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (25, 16), 'features.5': (41, 51), 'features.7': (44, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 46.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.74 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.00 GiB is allocated by PyTorch, and 346.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:16:46,896 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 16), features.5:(25, 32), features.7:(32, 44), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:16:46,931 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(32, 22), features.5:(16, 32), features.7:(32, 32), features.10:(57, 76), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:06,875 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 16), features.5:(25, 32), features.7:(32, 44), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:07,683 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(32, 22), features.5:(16, 32), features.7:(32, 32), features.10:(57, 76), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:08,684 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 16), 'features.5': (25, 32), 'features.7': (32, 44), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.00 GiB is allocated by PyTorch, and 369.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:17:08,693 - MainProcess - ERROR - Error processing config: {'features.0': (1, 38), 'features.2': (25, 38), 'features.5': (22, 44), 'features.7': (44, 32), 'features.10': (32, 76), 'features.12': (64, 102), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 78.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.71 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.92 GiB is allocated by PyTorch, and 391.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:17:08,708 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(32, 25), features.5:(25, 32), features.7:(38, 32), features.10:(32, 76), features.12:(76, 89), features.14:(102, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:08,744 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 28), features.5:(22, 38), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:28,708 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(32, 25), features.5:(25, 32), features.7:(38, 32), features.10:(32, 76), features.12:(76, 89), features.14:(102, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:28,843 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 28), features.5:(22, 38), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:32,503 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 16), 'features.5': (22, 44), 'features.7': (38, 38), 'features.10': (38, 89), 'features.12': (64, 76), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 46.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.74 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.93 GiB is allocated by PyTorch, and 416.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:17:32,510 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (32, 25), 'features.5': (25, 32), 'features.7': (38, 32), 'features.10': (32, 76), 'features.12': (76, 89), 'features.14': (102, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 46.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.74 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.88 GiB is allocated by PyTorch, and 471.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:17:32,517 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (32, 22), 'features.5': (16, 32), 'features.7': (32, 32), 'features.10': (57, 76), 'features.12': (64, 76), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 42.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.74 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.86 GiB is allocated by PyTorch, and 496.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:17:32,588 - MainProcess - INFO - Compressing to:features.0:(1, 28), features.2:(16, 28), features.5:(22, 32), features.7:(38, 32), features.10:(32, 76), features.12:(76, 64), features.14:(89, 64), features.17:(64, 128), features.19:(179, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:32,606 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(22, 38), features.5:(19, 38), features.7:(32, 38), features.10:(51, 76), features.12:(76, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:32,606 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(25, 19), features.5:(22, 32), features.7:(51, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 179), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:53,727 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(22, 38), features.5:(19, 38), features.7:(32, 38), features.10:(51, 76), features.12:(76, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:54,118 - MainProcess - INFO - finetuning:features.0:(1, 28), features.2:(16, 28), features.5:(22, 32), features.7:(38, 32), features.10:(32, 76), features.12:(76, 64), features.14:(89, 64), features.17:(64, 128), features.19:(179, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:55,090 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(25, 19), features.5:(22, 32), features.7:(51, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 179), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:58,181 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (22, 38), 'features.5': (19, 38), 'features.7': (32, 38), 'features.10': (51, 76), 'features.12': (76, 64), 'features.14': (64, 76), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 179), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 22.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.93 GiB is allocated by PyTorch, and 445.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:17:58,196 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (25, 19), 'features.5': (22, 32), 'features.7': (51, 32), 'features.10': (57, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (153, 179), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.92 GiB is allocated by PyTorch, and 444.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:17:58,213 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(25, 16), features.5:(19, 32), features.7:(38, 32), features.10:(32, 89), features.12:(64, 64), features.14:(64, 76), features.17:(115, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:17:58,251 - MainProcess - INFO - Compressing to:features.0:(1, 32), features.2:(19, 19), features.5:(25, 64), features.7:(38, 32), features.10:(44, 64), features.12:(76, 102), features.14:(76, 102), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:18:18,048 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(25, 16), features.5:(19, 32), features.7:(38, 32), features.10:(32, 89), features.12:(64, 64), features.14:(64, 76), features.17:(115, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:18:18,182 - MainProcess - INFO - finetuning:features.0:(1, 32), features.2:(19, 19), features.5:(25, 64), features.7:(38, 32), features.10:(44, 64), features.12:(76, 102), features.14:(76, 102), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:18:20,802 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (25, 16), 'features.5': (19, 32), 'features.7': (38, 32), 'features.10': (32, 89), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (115, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.09 GiB is allocated by PyTorch, and 277.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:18:20,807 - MainProcess - ERROR - Error processing config: {'features.0': (1, 32), 'features.2': (19, 19), 'features.5': (25, 64), 'features.7': (38, 32), 'features.10': (44, 64), 'features.12': (76, 102), 'features.14': (76, 102), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.12 GiB is allocated by PyTorch, and 241.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:18:20,811 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 28), 'features.5': (22, 38), 'features.7': (44, 32), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.11 GiB is allocated by PyTorch, and 257.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:18:20,815 - MainProcess - ERROR - Error processing config: {'features.0': (1, 28), 'features.2': (16, 28), 'features.5': (22, 32), 'features.7': (38, 32), 'features.10': (32, 76), 'features.12': (76, 64), 'features.14': (89, 64), 'features.17': (64, 128), 'features.19': (179, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.11 GiB is allocated by PyTorch, and 255.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:18:20,842 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(19, 25), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 16:18:20,959 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(28, 16), features.5:(25, 32), features.7:(51, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:18:20,960 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(22, 16), features.5:(16, 38), features.7:(44, 38), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 153), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:18:20,960 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(22, 19), features.5:(16, 32), features.7:(32, 32), features.10:(32, 89), features.12:(64, 64), features.14:(76, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:18:42,639 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(19, 25), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 16:18:43,336 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(22, 19), features.5:(16, 32), features.7:(32, 32), features.10:(32, 89), features.12:(64, 64), features.14:(76, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:18:44,234 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(22, 16), features.5:(16, 38), features.7:(44, 38), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 153), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:18:44,237 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(28, 16), features.5:(25, 32), features.7:(51, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:18:47,077 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (22, 16), 'features.5': (16, 38), 'features.7': (44, 38), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 153), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 156.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.63 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.70 GiB is allocated by PyTorch, and 538.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:18:47,082 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (28, 16), 'features.5': (25, 32), 'features.7': (51, 44), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 156.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.63 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.90 GiB is allocated by PyTorch, and 340.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:18:47,088 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (19, 25), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 92.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.95 GiB is allocated by PyTorch, and 356.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:18:47,142 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 19), features.5:(28, 44), features.7:(32, 64), features.10:(44, 76), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:18:47,177 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(51, 16), features.5:(16, 32), features.7:(32, 51), features.10:(38, 64), features.12:(64, 76), features.14:(64, 115), features.17:(64, 128), features.19:(153, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:18:47,179 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 32), features.5:(16, 38), features.7:(44, 44), features.10:(38, 76), features.12:(64, 89), features.14:(76, 64), features.17:(76, 179), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:19:08,287 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 32), features.5:(16, 38), features.7:(44, 44), features.10:(38, 76), features.12:(64, 89), features.14:(76, 64), features.17:(76, 179), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:19:08,664 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(51, 16), features.5:(16, 32), features.7:(32, 51), features.10:(38, 64), features.12:(64, 76), features.14:(64, 115), features.17:(64, 128), features.19:(153, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:10,026 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 19), features.5:(28, 44), features.7:(32, 64), features.10:(44, 76), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:13,057 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (22, 19), 'features.5': (16, 32), 'features.7': (32, 32), 'features.10': (32, 89), 'features.12': (64, 64), 'features.14': (76, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 84.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.77 GiB is allocated by PyTorch, and 544.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:19:13,067 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (51, 16), 'features.5': (16, 32), 'features.7': (32, 51), 'features.10': (38, 64), 'features.12': (64, 76), 'features.14': (64, 115), 'features.17': (64, 128), 'features.19': (153, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 84.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.73 GiB is allocated by PyTorch, and 581.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:19:13,081 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 38), features.5:(16, 38), features.7:(44, 32), features.10:(32, 64), features.12:(89, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:13,112 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 38), features.5:(16, 51), features.7:(44, 32), features.10:(32, 64), features.12:(76, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:33,388 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 38), features.5:(16, 38), features.7:(44, 32), features.10:(32, 64), features.12:(89, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:33,389 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 38), features.5:(16, 51), features.7:(44, 32), features.10:(32, 64), features.12:(76, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:34,469 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 19), 'features.5': (28, 44), 'features.7': (32, 64), 'features.10': (44, 76), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.72 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.91 GiB is allocated by PyTorch, and 424.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:19:34,475 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 32), 'features.5': (16, 38), 'features.7': (44, 44), 'features.10': (38, 76), 'features.12': (64, 89), 'features.14': (76, 64), 'features.17': (76, 179), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.72 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.91 GiB is allocated by PyTorch, and 425.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:19:34,481 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 38), 'features.5': (16, 38), 'features.7': (44, 32), 'features.10': (32, 64), 'features.12': (89, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 28.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.97 GiB is allocated by PyTorch, and 389.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:19:34,516 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(22, 19), features.5:(22, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:19:34,600 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 38), features.5:(22, 51), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(179, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:34,603 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 16), features.5:(19, 32), features.7:(38, 44), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 153), features.19:(153, 153), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:54,827 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(22, 19), features.5:(22, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:19:56,193 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 38), features.5:(22, 51), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(179, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:56,196 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 16), features.5:(19, 32), features.7:(38, 44), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 153), features.19:(153, 153), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:59,733 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 38), 'features.5': (22, 51), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (179, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 86.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.87 GiB is allocated by PyTorch, and 442.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:19:59,751 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 16), 'features.5': (19, 32), 'features.7': (38, 44), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (76, 153), 'features.19': (153, 153), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 50.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.74 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.98 GiB is allocated by PyTorch, and 360.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:19:59,779 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 16), features.5:(16, 38), features.7:(38, 38), features.10:(57, 76), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:19:59,832 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 22), features.5:(19, 32), features.7:(32, 44), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:20:19,980 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 22), features.5:(19, 32), features.7:(32, 44), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:20:20,108 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 16), features.5:(16, 38), features.7:(38, 38), features.10:(57, 76), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:20:26,408 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 38), 'features.5': (16, 51), 'features.7': (44, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 8.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.78 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.15 GiB is allocated by PyTorch, and 227.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:20:26,441 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(28, 16), features.5:(38, 32), features.7:(32, 32), features.10:(51, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:20:44,347 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(28, 16), features.5:(38, 32), features.7:(32, 32), features.10:(51, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:20:54,795 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (19, 16), 'features.5': (16, 38), 'features.7': (38, 38), 'features.10': (57, 76), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 179), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 76.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.71 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.02 GiB is allocated by PyTorch, and 297.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:20:54,801 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (28, 16), 'features.5': (38, 32), 'features.7': (32, 32), 'features.10': (51, 64), 'features.12': (64, 76), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 76.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.71 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.99 GiB is allocated by PyTorch, and 328.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:20:54,806 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (22, 19), 'features.5': (22, 32), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (179, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 14.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.05 GiB is allocated by PyTorch, and 331.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:20:54,826 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 25), features.5:(22, 38), features.7:(44, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:20:54,898 - MainProcess - INFO - Compressing to:features.0:(1, 28), features.2:(19, 16), features.5:(28, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 102), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:20:54,900 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 19), features.5:(16, 76), features.7:(32, 51), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(153, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:21:15,146 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 25), features.5:(22, 38), features.7:(44, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:21:16,365 - MainProcess - INFO - finetuning:features.0:(1, 28), features.2:(19, 16), features.5:(28, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 102), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:21:16,890 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 19), features.5:(16, 76), features.7:(32, 51), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(153, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:21:26,342 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (19, 19), 'features.5': (16, 76), 'features.7': (32, 51), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 153), 'features.19': (153, 153), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 170.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.78 GiB is allocated by PyTorch, and 444.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:21:26,350 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 25), 'features.5': (22, 38), 'features.7': (44, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (102, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 174.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.84 GiB is allocated by PyTorch, and 380.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:21:26,356 - MainProcess - ERROR - Error processing config: {'features.0': (1, 28), 'features.2': (19, 16), 'features.5': (28, 32), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 102), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 180.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.61 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.90 GiB is allocated by PyTorch, and 315.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:21:26,417 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(28, 16), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:21:26,419 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 16), features.5:(16, 32), features.7:(32, 64), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:21:26,457 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(41, 57), features.5:(25, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:21:47,150 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(28, 16), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:21:47,538 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(41, 57), features.5:(25, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:21:47,539 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 16), features.5:(16, 32), features.7:(32, 64), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:21:52,477 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (28, 16), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 106.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.68 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.85 GiB is allocated by PyTorch, and 438.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:21:52,488 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 22), 'features.5': (19, 32), 'features.7': (32, 44), 'features.10': (44, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 12.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.07 GiB is allocated by PyTorch, and 304.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:21:52,499 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 16), 'features.5': (16, 32), 'features.7': (32, 64), 'features.10': (44, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.05 GiB is allocated by PyTorch, and 327.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:21:52,505 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (41, 57), 'features.5': (25, 32), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.97 GiB is allocated by PyTorch, and 409.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:21:52,539 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 25), features.5:(16, 44), features.7:(38, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:21:52,543 - MainProcess - INFO - Compressing to:features.0:(1, 38), features.2:(16, 22), features.5:(22, 32), features.7:(32, 32), features.10:(83, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 204), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:21:52,601 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(19, 35), features.5:(16, 51), features.7:(32, 38), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:21:52,604 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(28, 22), features.5:(38, 57), features.7:(51, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:22:14,769 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(19, 35), features.5:(16, 51), features.7:(32, 38), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:22:15,034 - MainProcess - INFO - finetuning:features.0:(1, 38), features.2:(16, 22), features.5:(22, 32), features.7:(32, 32), features.10:(83, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 204), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:22:16,131 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(28, 22), features.5:(38, 57), features.7:(51, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:22:16,303 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 25), features.5:(16, 44), features.7:(38, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:22:20,776 - MainProcess - ERROR - Error processing config: {'features.0': (1, 38), 'features.2': (16, 22), 'features.5': (22, 32), 'features.7': (32, 32), 'features.10': (83, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 204), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.00 GiB is allocated by PyTorch, and 368.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:22:20,780 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (19, 35), 'features.5': (16, 51), 'features.7': (32, 38), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.98 GiB is allocated by PyTorch, and 392.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:22:20,785 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (28, 22), 'features.5': (38, 57), 'features.7': (51, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.85 GiB is allocated by PyTorch, and 519.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:22:20,802 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(32, 22), features.5:(19, 64), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(179, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:22:20,860 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(28, 32), features.5:(38, 44), features.7:(32, 38), features.10:(44, 76), features.12:(64, 64), features.14:(64, 102), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:22:20,861 - MainProcess - INFO - Compressing to:features.0:(1, 41), features.2:(28, 22), features.5:(25, 32), features.7:(57, 44), features.10:(32, 64), features.12:(64, 102), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=41, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "2025-03-30 16:22:41,413 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(32, 22), features.5:(19, 64), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(179, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:22:41,801 - MainProcess - INFO - finetuning:features.0:(1, 41), features.2:(28, 22), features.5:(25, 32), features.7:(57, 44), features.10:(32, 64), features.12:(64, 102), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:22:43,302 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(28, 32), features.5:(38, 44), features.7:(32, 38), features.10:(44, 76), features.12:(64, 64), features.14:(64, 102), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:22:59,070 - MainProcess - ERROR - Error processing config: {'features.0': (1, 41), 'features.2': (28, 22), 'features.5': (25, 32), 'features.7': (57, 44), 'features.10': (32, 64), 'features.12': (64, 102), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 84.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.93 GiB is allocated by PyTorch, and 376.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:22:59,077 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (32, 22), 'features.5': (19, 64), 'features.7': (32, 51), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (179, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 48.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.74 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.94 GiB is allocated by PyTorch, and 407.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:22:59,085 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (28, 32), 'features.5': (38, 44), 'features.7': (32, 38), 'features.10': (44, 76), 'features.12': (64, 64), 'features.14': (64, 102), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 76.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.71 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.93 GiB is allocated by PyTorch, and 392.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:22:59,117 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(16, 19), features.5:(48, 38), features.7:(32, 38), features.10:(32, 76), features.12:(64, 64), features.14:(76, 89), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:22:59,119 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(22, 16), features.5:(25, 44), features.7:(44, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:22:59,175 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(32, 19), features.5:(19, 38), features.7:(44, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:23:19,725 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(16, 19), features.5:(48, 38), features.7:(32, 38), features.10:(32, 76), features.12:(64, 64), features.14:(76, 89), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:23:20,736 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(22, 16), features.5:(25, 44), features.7:(44, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:23:21,132 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(32, 19), features.5:(19, 38), features.7:(44, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:23:22,512 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (19, 25), 'features.5': (16, 44), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.01 GiB is allocated by PyTorch, and 366.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:23:22,518 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (16, 19), 'features.5': (48, 38), 'features.7': (32, 38), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (76, 89), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.00 GiB is allocated by PyTorch, and 373.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:23:22,524 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (32, 19), 'features.5': (19, 38), 'features.7': (44, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.00 GiB is allocated by PyTorch, and 373.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:23:22,529 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (22, 16), 'features.5': (25, 44), 'features.7': (44, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 18.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.98 GiB is allocated by PyTorch, and 396.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:23:22,537 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 16), features.5:(19, 32), features.7:(51, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 16:23:22,661 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 19), features.5:(35, 32), features.7:(32, 32), features.10:(38, 64), features.12:(89, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:23:22,662 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(32, 16), features.5:(16, 51), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:23:22,663 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(25, 25), features.5:(22, 70), features.7:(64, 38), features.10:(32, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:23:44,014 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 16), features.5:(19, 32), features.7:(51, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(153, 128)\n",
      "2025-03-30 16:23:44,730 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(32, 16), features.5:(16, 51), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:23:45,113 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(25, 25), features.5:(22, 70), features.7:(64, 38), features.10:(32, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:23:45,133 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 19), features.5:(35, 32), features.7:(32, 32), features.10:(38, 64), features.12:(89, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:23:49,800 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 19), 'features.5': (35, 32), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (89, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 186.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.60 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.75 GiB is allocated by PyTorch, and 465.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:23:49,810 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 16), 'features.5': (19, 32), 'features.7': (51, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 184.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.61 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.67 GiB is allocated by PyTorch, and 544.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:23:49,907 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 51), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(89, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:23:49,910 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 19), features.5:(22, 32), features.7:(32, 51), features.10:(32, 64), features.12:(76, 89), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:24:10,038 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 51), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(89, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:24:10,839 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 19), features.5:(22, 32), features.7:(32, 51), features.10:(32, 64), features.12:(76, 89), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:24:13,426 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (25, 25), 'features.5': (22, 70), 'features.7': (64, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (89, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 170.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.71 GiB is allocated by PyTorch, and 516.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:24:13,437 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 19), 'features.5': (22, 32), 'features.7': (32, 51), 'features.10': (32, 64), 'features.12': (76, 89), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 60.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.73 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.91 GiB is allocated by PyTorch, and 424.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:24:13,455 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 22), features.5:(19, 32), features.7:(38, 44), features.10:(32, 76), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:24:13,498 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 25), features.5:(28, 32), features.7:(32, 44), features.10:(32, 64), features.12:(76, 64), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:24:33,566 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 22), features.5:(19, 32), features.7:(38, 44), features.10:(32, 76), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:24:33,965 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 25), features.5:(28, 32), features.7:(32, 44), features.10:(32, 64), features.12:(76, 64), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:24:38,340 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 22), 'features.5': (19, 32), 'features.7': (38, 44), 'features.10': (32, 76), 'features.12': (64, 102), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 86.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.70 GiB is allocated by PyTorch, and 608.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:24:38,347 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (32, 16), 'features.5': (16, 51), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 36.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.75 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.87 GiB is allocated by PyTorch, and 491.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:24:38,353 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 51), 'features.5': (22, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (89, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 36.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.75 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.89 GiB is allocated by PyTorch, and 466.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:24:38,438 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 25), features.5:(19, 44), features.7:(32, 44), features.10:(44, 64), features.12:(76, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:24:38,441 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 19), features.5:(16, 57), features.7:(51, 32), features.10:(44, 64), features.12:(64, 64), features.14:(102, 64), features.17:(89, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:24:38,442 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(16, 38), features.5:(16, 44), features.7:(32, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:24:57,633 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 25), features.5:(19, 44), features.7:(32, 44), features.10:(44, 64), features.12:(76, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:24:58,010 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(16, 38), features.5:(16, 44), features.7:(32, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:24:59,351 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 19), features.5:(16, 57), features.7:(51, 32), features.10:(44, 64), features.12:(64, 64), features.14:(102, 64), features.17:(89, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:25:31,819 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 25), 'features.5': (19, 44), 'features.7': (32, 44), 'features.10': (44, 64), 'features.12': (76, 64), 'features.14': (89, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 86.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.83 GiB is allocated by PyTorch, and 478.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:25:31,830 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 19), 'features.5': (16, 57), 'features.7': (51, 32), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (102, 64), 'features.17': (89, 153), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 86.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.82 GiB is allocated by PyTorch, and 486.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:25:31,867 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 28), features.5:(16, 32), features.7:(32, 32), features.10:(38, 64), features.12:(64, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:25:31,870 - MainProcess - INFO - Compressing to:features.0:(2, 38), features.2:(22, 38), features.5:(19, 38), features.7:(44, 32), features.10:(44, 89), features.12:(76, 102), features.14:(76, 76), features.17:(89, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:25:51,768 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 28), features.5:(16, 32), features.7:(32, 32), features.10:(38, 64), features.12:(64, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:25:52,307 - MainProcess - INFO - finetuning:features.0:(2, 38), features.2:(22, 38), features.5:(19, 38), features.7:(44, 32), features.10:(44, 89), features.12:(76, 102), features.14:(76, 76), features.17:(89, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:00,144 - MainProcess - ERROR - Error processing config: {'features.0': (2, 38), 'features.2': (22, 38), 'features.5': (19, 38), 'features.7': (44, 32), 'features.10': (44, 89), 'features.12': (76, 102), 'features.14': (76, 76), 'features.17': (89, 128), 'features.19': (128, 153), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 12.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.06 GiB is allocated by PyTorch, and 321.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:26:00,150 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 25), 'features.5': (28, 32), 'features.7': (32, 44), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 12.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.08 GiB is allocated by PyTorch, and 301.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:26:00,156 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 28), 'features.5': (16, 32), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 12.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.02 GiB is allocated by PyTorch, and 358.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:26:00,162 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (16, 38), 'features.5': (16, 44), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 12.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.00 GiB is allocated by PyTorch, and 383.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:26:00,163 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(41, 22), features.5:(19, 32), features.7:(51, 51), features.10:(70, 64), features.12:(76, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:00,226 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(48, 16), features.5:(22, 32), features.7:(38, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:00,229 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 25), features.5:(22, 32), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:26:00,283 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(28, 16), features.5:(16, 38), features.7:(32, 38), features.10:(32, 64), features.12:(76, 76), features.14:(64, 89), features.17:(140, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:21,449 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(41, 22), features.5:(19, 32), features.7:(51, 51), features.10:(70, 64), features.12:(76, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:21,956 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(48, 16), features.5:(22, 32), features.7:(38, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:23,058 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 25), features.5:(22, 32), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:26:24,150 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(28, 16), features.5:(16, 38), features.7:(32, 38), features.10:(32, 64), features.12:(76, 76), features.14:(64, 89), features.17:(140, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:25,179 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 25), 'features.5': (22, 32), 'features.7': (32, 38), 'features.10': (51, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 4.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.78 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.92 GiB is allocated by PyTorch, and 471.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:26:25,189 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (41, 22), 'features.5': (19, 32), 'features.7': (51, 51), 'features.10': (70, 64), 'features.12': (76, 76), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 54.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.73 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.89 GiB is allocated by PyTorch, and 447.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:26:25,207 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(32, 25), features.5:(19, 38), features.7:(38, 32), features.10:(38, 76), features.12:(64, 76), features.14:(64, 64), features.17:(89, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:25,251 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(16, 19), features.5:(16, 44), features.7:(32, 38), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:44,769 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(32, 25), features.5:(19, 38), features.7:(38, 32), features.10:(38, 76), features.12:(64, 76), features.14:(64, 64), features.17:(89, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:45,713 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(16, 19), features.5:(16, 44), features.7:(32, 38), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:26:47,496 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (32, 25), 'features.5': (19, 38), 'features.7': (38, 32), 'features.10': (38, 76), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 298.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.49 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.79 GiB is allocated by PyTorch, and 306.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:26:47,503 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (28, 16), 'features.5': (16, 38), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (76, 76), 'features.14': (64, 89), 'features.17': (140, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 36.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.75 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.08 GiB is allocated by PyTorch, and 278.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:26:47,507 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (48, 16), 'features.5': (22, 32), 'features.7': (38, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 10.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.78 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.11 GiB is allocated by PyTorch, and 269.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:26:47,534 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 22), features.5:(28, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:26:47,607 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 22), features.5:(25, 38), features.7:(32, 32), features.10:(51, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:26:47,609 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 25), features.5:(16, 32), features.7:(44, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:27:07,926 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 22), features.5:(28, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 16:27:08,983 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 25), features.5:(16, 32), features.7:(44, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:27:08,983 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 22), features.5:(25, 38), features.7:(32, 32), features.10:(51, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 16:27:10,510 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (19, 22), 'features.5': (25, 38), 'features.7': (32, 32), 'features.10': (51, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 38.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.75 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.00 GiB is allocated by PyTorch, and 355.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:27:10,514 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 22), 'features.5': (28, 38), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 179), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 12.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.77 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.89 GiB is allocated by PyTorch, and 489.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:27:10,526 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 25), 'features.5': (16, 32), 'features.7': (44, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 90.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.79 GiB is allocated by PyTorch, and 521.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 16:27:10,658 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(35, 25), features.5:(16, 32), features.7:(44, 44), features.10:(38, 89), features.12:(64, 64), features.14:(64, 102), features.17:(89, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:27:10,659 - MainProcess - INFO - Compressing to:features.0:(1, 44), features.2:(32, 25), features.5:(28, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 153), features.19:(128, 128), features.21:(128, 153), features.24:(179, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:27:10,664 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(22, 19), features.5:(28, 51), features.7:(38, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 76), features.17:(76, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=44, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "2025-03-30 16:27:31,783 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(35, 25), features.5:(16, 32), features.7:(44, 44), features.10:(38, 89), features.12:(64, 64), features.14:(64, 102), features.17:(89, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:27:32,454 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(22, 19), features.5:(28, 51), features.7:(38, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 76), features.17:(76, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 16:27:32,594 - MainProcess - INFO - finetuning:features.0:(1, 44), features.2:(32, 25), features.5:(28, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 153), features.19:(128, 128), features.21:(128, 153), features.24:(179, 179), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1882\n",
      "Epoch 1/3, Loss: 0.0688\n",
      "Epoch 1/3, Loss: 0.1427\n",
      "Epoch 1/3, Loss: 0.1710\n",
      "Epoch 2/3, Loss: 0.0348\n",
      "Epoch 2/3, Loss: 0.0260\n",
      "Epoch 2/3, Loss: 0.0327\n",
      "Epoch 3/3, Loss: 0.0275\n",
      "Epoch 2/3, Loss: 0.0332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:50:14,838 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(35, 25), features.5:(16, 32), features.7:(44, 44), features.10:(38, 89), features.12:(64, 64), features.14:(64, 102), features.17:(89, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121519399,\n",
      "    \"flops\": 3975996298,\n",
      "    \"accuracy\": 0.9928,\n",
      "    \"inference_time\": 0.2731896737578568,\n",
      "    \"compression_rate\": 1.1051857983596511,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 16:50:15,078 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(25, 51), features.5:(25, 32), features.7:(44, 44), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:50:32,189 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(25, 51), features.5:(25, 32), features.7:(44, 44), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0276\n",
      "Epoch 3/3, Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:54:29,896 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 22), features.2:(22, 19), features.5:(28, 51), features.7:(38, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 76), features.17:(76, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121494752,\n",
      "    \"flops\": 3664444106,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.2323692462499987,\n",
      "    \"compression_rate\": 1.1054100015776813,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 16:54:30,105 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(35, 25), features.5:(16, 44), features.7:(38, 44), features.10:(32, 64), features.12:(140, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:54:47,393 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(35, 25), features.5:(16, 44), features.7:(38, 44), features.10:(32, 64), features.12:(140, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 16:55:17,450 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 25), features.2:(16, 19), features.5:(16, 44), features.7:(32, 38), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121384889,\n",
      "    \"flops\": 2141495306,\n",
      "    \"accuracy\": 0.9933,\n",
      "    \"inference_time\": 0.2440390677968408,\n",
      "    \"compression_rate\": 1.1064104857401156,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 16:55:17,580 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 16), features.5:(22, 38), features.7:(57, 38), features.10:(32, 64), features.12:(76, 89), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 16:55:35,664 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 16), features.5:(22, 38), features.7:(57, 38), features.10:(32, 64), features.12:(76, 89), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0261\n",
      "Epoch 1/3, Loss: 0.1928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 17:00:10,666 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 44), features.2:(32, 25), features.5:(28, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 153), features.19:(128, 128), features.21:(128, 153), features.24:(179, 179), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121604607,\n",
      "    \"flops\": 5007615630,\n",
      "    \"accuracy\": 0.9921,\n",
      "    \"inference_time\": 0.29172804704896965,\n",
      "    \"compression_rate\": 1.104411397834623,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 17:00:10,859 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(35, 28), features.5:(35, 32), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 17:00:29,899 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(35, 28), features.5:(35, 32), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0604\n",
      "Epoch 2/3, Loss: 0.0354\n",
      "Epoch 1/3, Loss: 0.1457\n",
      "Epoch 3/3, Loss: 0.0264\n",
      "Epoch 1/3, Loss: 0.0630\n",
      "Epoch 2/3, Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 17:14:00,895 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(25, 51), features.5:(25, 32), features.7:(44, 44), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121426993,\n",
      "    \"flops\": 5371118602,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.31366362035147954,\n",
      "    \"compression_rate\": 1.1060268452830748,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 17:14:01,048 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 25), features.5:(22, 32), features.7:(32, 32), features.10:(64, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 153), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 17:14:19,003 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 25), features.5:(22, 32), features.7:(32, 32), features.10:(64, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 153), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0618\n",
      "Epoch 3/3, Loss: 0.0205\n",
      "Epoch 2/3, Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 17:23:15,815 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(35, 25), features.5:(16, 44), features.7:(38, 44), features.10:(32, 64), features.12:(140, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121563556,\n",
      "    \"flops\": 5319788554,\n",
      "    \"accuracy\": 0.992,\n",
      "    \"inference_time\": 0.31464194087212766,\n",
      "    \"compression_rate\": 1.1047843483617739,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 17:23:15,972 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(35, 19), features.5:(19, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(102, 179), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 17:23:30,247 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(35, 19), features.5:(19, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(102, 179), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0261\n",
      "Epoch 2/3, Loss: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 17:27:07,343 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(22, 16), features.5:(22, 38), features.7:(57, 38), features.10:(32, 64), features.12:(76, 89), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121473828,\n",
      "    \"flops\": 4970400522,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.3132716728623505,\n",
      "    \"compression_rate\": 1.1056004096619068,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 17:27:07,492 - MainProcess - INFO - Compressing to:features.0:(2, 41), features.2:(22, 32), features.5:(19, 32), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 17:27:21,728 - MainProcess - INFO - finetuning:features.0:(2, 41), features.2:(22, 32), features.5:(19, 32), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0201\n",
      "Epoch 1/3, Loss: 0.0659\n",
      "Epoch 3/3, Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 17:32:50,002 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 22), features.2:(19, 25), features.5:(22, 32), features.7:(32, 32), features.10:(64, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 153), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121489973,\n",
      "    \"flops\": 4783330478,\n",
      "    \"accuracy\": 0.9877,\n",
      "    \"inference_time\": 0.2691335212399752,\n",
      "    \"compression_rate\": 1.105453484626258,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 17:32:50,140 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 19), features.5:(28, 38), features.7:(51, 32), features.10:(38, 115), features.12:(64, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 17:33:03,728 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 19), features.5:(28, 38), features.7:(51, 32), features.10:(38, 115), features.12:(64, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 17:35:11,816 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(35, 28), features.5:(35, 32), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121374045,\n",
      "    \"flops\": 3817195530,\n",
      "    \"accuracy\": 0.993,\n",
      "    \"inference_time\": 0.2986536780233849,\n",
      "    \"compression_rate\": 1.106509336489527,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 17:35:11,942 - MainProcess - INFO - Compressing to:features.0:(1, 28), features.2:(16, 22), features.5:(16, 32), features.7:(38, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 17:35:11,943 - MainProcess - INFO - Evaluated 50 configurations, found 50 accepted models\n",
      "2025-03-30 17:35:26,363 - MainProcess - INFO - finetuning:features.0:(1, 28), features.2:(16, 22), features.5:(16, 32), features.7:(38, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0651\n",
      "Epoch 1/3, Loss: 0.1332\n",
      "Epoch 2/3, Loss: 0.0263\n",
      "Epoch 2/3, Loss: 0.0326\n",
      "Epoch 2/3, Loss: 0.0262\n",
      "Epoch 1/3, Loss: 0.1246\n",
      "Epoch 3/3, Loss: 0.0259\n",
      "Epoch 3/3, Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 17:51:00,732 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(19, 19), features.5:(28, 38), features.7:(51, 32), features.10:(38, 115), features.12:(64, 64), features.14:(64, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121424265,\n",
      "    \"flops\": 4880130186,\n",
      "    \"accuracy\": 0.9924,\n",
      "    \"inference_time\": 0.22837159689318098,\n",
      "    \"compression_rate\": 1.1060516940333136,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 17:51:00,878 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 44), features.5:(28, 32), features.7:(51, 38), features.10:(32, 76), features.12:(64, 64), features.14:(102, 64), features.17:(64, 153), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 17:51:14,709 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 44), features.5:(28, 32), features.7:(51, 38), features.10:(32, 76), features.12:(64, 64), features.14:(102, 64), features.17:(64, 153), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 17:51:46,698 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(35, 19), features.5:(19, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(102, 179), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121468526,\n",
      "    \"flops\": 4791464490,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.24244474251052628,\n",
      "    \"compression_rate\": 1.1056486681990363,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 17:51:46,826 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 25), features.5:(22, 38), features.7:(32, 51), features.10:(38, 64), features.12:(89, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\n",
      "2025-03-30 17:52:01,075 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 25), features.5:(22, 38), features.7:(32, 51), features.10:(38, 64), features.12:(89, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0214\n",
      "Epoch 1/3, Loss: 0.1474\n",
      "Epoch 2/3, Loss: 0.0319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 17:58:19,557 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 41), features.2:(22, 32), features.5:(19, 32), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121392821,\n",
      "    \"flops\": 4922153162,\n",
      "    \"accuracy\": 0.9935,\n",
      "    \"inference_time\": 0.3216149599435729,\n",
      "    \"compression_rate\": 1.106338191119226,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 17:58:19,696 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 19), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 115), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 17:58:35,258 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 19), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 115), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 17:59:22,954 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (19, 44), 'features.5': (28, 32), 'features.7': (51, 38), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (102, 64), 'features.17': (64, 153), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 254.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.54 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 34.82 GiB is allocated by PyTorch, and 2.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 17:59:23,038 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 32), features.5:(28, 44), features.7:(32, 64), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 17:59:37,191 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 32), features.5:(28, 44), features.7:(32, 64), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:02:29,791 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 32), 'features.5': (28, 44), 'features.7': (32, 64), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 496.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.30 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 32.53 GiB is allocated by PyTorch, and 4.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:02:29,874 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(22, 16), features.5:(16, 32), features.7:(38, 32), features.10:(38, 102), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:02:47,325 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(22, 16), features.5:(16, 32), features.7:(38, 32), features.10:(38, 102), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:03:14,364 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (22, 16), 'features.5': (16, 32), 'features.7': (38, 32), 'features.10': (38, 102), 'features.12': (76, 64), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 162.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.63 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 32.78 GiB is allocated by PyTorch, and 4.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:03:14,465 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(25, 51), features.5:(22, 51), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:03:32,026 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(25, 51), features.5:(22, 51), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:03:41,493 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (25, 51), 'features.5': (22, 51), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.72 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.58 GiB is allocated by PyTorch, and 3.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:03:41,587 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(22, 19), features.5:(25, 38), features.7:(38, 64), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:03:59,186 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(22, 19), features.5:(25, 38), features.7:(38, 64), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:04:18,060 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (22, 19), 'features.5': (25, 38), 'features.7': (38, 64), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 153), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 532.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.27 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 32.70 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:04:18,163 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(25, 54), features.5:(32, 32), features.7:(32, 38), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 153)\n",
      "2025-03-30 18:04:35,751 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(25, 54), features.5:(32, 32), features.7:(32, 38), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 153)\n",
      "2025-03-30 18:05:14,928 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (25, 54), 'features.5': (32, 32), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (153, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 92.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 32.40 GiB is allocated by PyTorch, and 4.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:05:15,113 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 19), features.5:(54, 32), features.7:(38, 32), features.10:(32, 76), features.12:(64, 89), features.14:(76, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:05:32,351 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 19), features.5:(54, 32), features.7:(38, 32), features.10:(32, 76), features.12:(64, 89), features.14:(76, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:06:44,623 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (19, 19), 'features.5': (54, 32), 'features.7': (38, 32), 'features.10': (32, 76), 'features.12': (64, 89), 'features.14': (76, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 460.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.34 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 32.67 GiB is allocated by PyTorch, and 4.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:06:44,760 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 28), features.5:(41, 44), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:07:02,219 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 28), features.5:(41, 44), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1646\n",
      "Epoch 2/3, Loss: 0.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:10:05,373 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 28), features.2:(16, 22), features.5:(16, 32), features.7:(38, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121424526,\n",
      "    \"flops\": 4666973706,\n",
      "    \"accuracy\": 0.9923,\n",
      "    \"inference_time\": 0.2840298836904473,\n",
      "    \"compression_rate\": 1.106049316593585,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 18:10:05,497 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(22, 25), features.5:(16, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:10:23,137 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(22, 25), features.5:(16, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:10:31,936 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 28), 'features.5': (41, 44), 'features.7': (32, 38), 'features.10': (51, 64), 'features.12': (64, 64), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 190.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.60 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.18 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:10:31,946 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 25), 'features.5': (22, 38), 'features.7': (32, 51), 'features.10': (38, 64), 'features.12': (89, 64), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 190.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.60 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.06 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:10:31,950 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 35), features.5:(25, 51), features.7:(38, 38), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(153, 179), features.28:(128, 153)\n",
      "2025-03-30 18:10:31,972 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(22, 25), features.5:(22, 44), features.7:(57, 57), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(204, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:10:52,187 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(22, 25), features.5:(22, 44), features.7:(57, 57), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(204, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:10:52,234 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 35), features.5:(25, 51), features.7:(38, 38), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(153, 179), features.28:(128, 153)\n",
      "2025-03-30 18:11:13,127 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 35), 'features.5': (25, 51), 'features.7': (38, 38), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 179), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 202.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.59 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.55 GiB is allocated by PyTorch, and 646.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:11:13,134 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 19), 'features.5': (22, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 115), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 6.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.78 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.48 GiB is allocated by PyTorch, and 923.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:11:13,145 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (22, 25), 'features.5': (22, 44), 'features.7': (57, 57), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (204, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 204.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.59 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.33 GiB is allocated by PyTorch, and 870.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:11:13,170 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(38, 19), features.5:(16, 32), features.7:(32, 57), features.10:(32, 115), features.12:(115, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:11:13,170 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 32), features.5:(22, 32), features.7:(32, 38), features.10:(44, 64), features.12:(64, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:11:13,263 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 35), features.5:(22, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:11:33,662 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 32), features.5:(22, 32), features.7:(32, 38), features.10:(44, 64), features.12:(64, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:11:34,292 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 35), features.5:(22, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:11:34,418 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(38, 19), features.5:(16, 32), features.7:(32, 57), features.10:(32, 115), features.12:(115, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:11:42,337 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 32), 'features.5': (22, 32), 'features.7': (32, 38), 'features.10': (44, 64), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 158.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.63 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.01 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:11:42,349 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 35), 'features.5': (22, 38), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 354.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.44 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.88 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:11:42,357 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 19), features.5:(25, 32), features.7:(44, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:11:42,404 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 16), features.5:(22, 38), features.7:(44, 51), features.10:(32, 89), features.12:(64, 102), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:12:01,454 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 19), features.5:(25, 32), features.7:(44, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:12:01,970 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 16), features.5:(22, 38), features.7:(44, 51), features.10:(32, 89), features.12:(64, 102), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:12:43,695 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 19), 'features.5': (25, 32), 'features.7': (44, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (179, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 296.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.50 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 34.15 GiB is allocated by PyTorch, and 2.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:12:43,700 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 16), 'features.5': (22, 38), 'features.7': (44, 51), 'features.10': (32, 89), 'features.12': (64, 102), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 296.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.50 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 34.12 GiB is allocated by PyTorch, and 2.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:12:43,748 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 25), features.5:(16, 32), features.7:(32, 38), features.10:(38, 64), features.12:(89, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 204), features.24:(128, 128), features.26:(153, 128), features.28:(128, 153)\n",
      "2025-03-30 18:12:43,749 - MainProcess - INFO - Compressing to:features.0:(1, 32), features.2:(19, 22), features.5:(16, 32), features.7:(38, 57), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:13:02,602 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 25), features.5:(16, 32), features.7:(32, 38), features.10:(38, 64), features.12:(89, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 204), features.24:(128, 128), features.26:(153, 128), features.28:(128, 153)\n",
      "2025-03-30 18:13:02,750 - MainProcess - INFO - finetuning:features.0:(1, 32), features.2:(19, 22), features.5:(16, 32), features.7:(38, 57), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:13:42,160 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 25), 'features.5': (16, 32), 'features.7': (32, 38), 'features.10': (38, 64), 'features.12': (89, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 204), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.78 GiB is allocated by PyTorch, and 588.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:13:42,166 - MainProcess - ERROR - Error processing config: {'features.0': (1, 32), 'features.2': (19, 22), 'features.5': (16, 32), 'features.7': (38, 57), 'features.10': (44, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.67 GiB is allocated by PyTorch, and 711.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:13:42,173 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (38, 19), 'features.5': (16, 32), 'features.7': (32, 57), 'features.10': (32, 115), 'features.12': (115, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 28.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.68 GiB is allocated by PyTorch, and 689.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:13:42,176 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (22, 25), 'features.5': (16, 32), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 82.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.71 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.59 GiB is allocated by PyTorch, and 726.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:13:42,194 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(22, 16), features.5:(54, 32), features.7:(32, 57), features.10:(38, 64), features.12:(128, 64), features.14:(76, 64), features.17:(102, 128), features.19:(128, 179), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:13:42,273 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 19), features.5:(16, 38), features.7:(32, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:13:42,276 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(28, 22), features.5:(19, 32), features.7:(64, 32), features.10:(38, 64), features.12:(76, 102), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:13:42,277 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 22), features.5:(19, 32), features.7:(32, 51), features.10:(51, 64), features.12:(64, 64), features.14:(89, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:14:04,031 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 22), features.5:(19, 32), features.7:(32, 51), features.10:(51, 64), features.12:(64, 64), features.14:(89, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:14:04,059 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(22, 16), features.5:(54, 32), features.7:(32, 57), features.10:(38, 64), features.12:(128, 64), features.14:(76, 64), features.17:(102, 128), features.19:(128, 179), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:14:04,432 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(28, 22), features.5:(19, 32), features.7:(64, 32), features.10:(38, 64), features.12:(76, 102), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:14:05,804 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 19), features.5:(16, 38), features.7:(32, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:14:26,613 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (22, 16), 'features.5': (54, 32), 'features.7': (32, 57), 'features.10': (38, 64), 'features.12': (128, 64), 'features.14': (76, 64), 'features.17': (102, 128), 'features.19': (128, 179), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 218.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.57 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.27 GiB is allocated by PyTorch, and 1.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:14:26,617 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 19), 'features.5': (16, 38), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 218.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.57 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.18 GiB is allocated by PyTorch, and 1.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:14:26,710 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 19), features.5:(19, 38), features.7:(38, 51), features.10:(44, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:14:26,801 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(19, 19), features.5:(19, 38), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:14:46,225 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 19), features.5:(19, 38), features.7:(38, 51), features.10:(44, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:14:46,894 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(19, 19), features.5:(19, 38), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:14:58,944 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 19), 'features.5': (19, 38), 'features.7': (38, 51), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 82.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.71 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 34.81 GiB is allocated by PyTorch, and 2.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:14:59,011 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 16), features.5:(44, 44), features.7:(32, 57), features.10:(64, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 128), features.26:(128, 153), features.28:(204, 153)\n",
      "2025-03-30 18:15:16,384 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 16), features.5:(44, 44), features.7:(32, 57), features.10:(64, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 128), features.26:(128, 153), features.28:(204, 153)\n",
      "2025-03-30 18:15:18,202 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 16), 'features.5': (44, 44), 'features.7': (32, 57), 'features.10': (64, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (153, 128), 'features.26': (128, 153), 'features.28': (204, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 344.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.45 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.60 GiB is allocated by PyTorch, and 455.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:15:18,248 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(44, 22), features.5:(22, 38), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(76, 76), features.17:(76, 128), features.19:(179, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:15:35,719 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(44, 22), features.5:(22, 38), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(76, 76), features.17:(76, 128), features.19:(179, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:15:42,157 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (44, 22), 'features.5': (22, 38), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (76, 76), 'features.17': (76, 128), 'features.19': (179, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 52.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.73 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.96 GiB is allocated by PyTorch, and 379.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:15:42,165 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (19, 19), 'features.5': (19, 38), 'features.7': (32, 32), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 78.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.71 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.87 GiB is allocated by PyTorch, and 445.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:15:42,187 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(28, 19), features.5:(16, 32), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 115), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:15:42,221 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 35), features.5:(25, 44), features.7:(38, 32), features.10:(51, 64), features.12:(64, 76), features.14:(89, 89), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:16:00,997 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(28, 19), features.5:(16, 32), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 115), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:16:02,726 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 35), features.5:(25, 44), features.7:(38, 32), features.10:(51, 64), features.12:(64, 76), features.14:(89, 89), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:16:16,274 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (28, 19), 'features.5': (16, 32), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 115), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 338.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.46 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.78 GiB is allocated by PyTorch, and 284.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:16:16,323 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 19), features.5:(19, 32), features.7:(32, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:16:34,348 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 19), features.5:(19, 32), features.7:(32, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:16:34,718 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 19), 'features.5': (19, 32), 'features.7': (32, 38), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 89), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 130.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.38 GiB is allocated by PyTorch, and 899.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:16:34,749 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 28), features.5:(35, 32), features.7:(44, 32), features.10:(38, 64), features.12:(89, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:16:52,119 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 28), features.5:(35, 32), features.7:(44, 32), features.10:(38, 64), features.12:(89, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:17:29,306 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 28), 'features.5': (35, 32), 'features.7': (44, 32), 'features.10': (38, 64), 'features.12': (89, 64), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 76.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.71 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.58 GiB is allocated by PyTorch, and 743.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:17:29,314 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 35), 'features.5': (25, 44), 'features.7': (38, 32), 'features.10': (51, 64), 'features.12': (64, 76), 'features.14': (89, 89), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 174.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.49 GiB is allocated by PyTorch, and 743.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:17:29,318 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 16), features.5:(19, 32), features.7:(32, 32), features.10:(44, 64), features.12:(115, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:17:29,346 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(54, 16), features.5:(16, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(102, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:17:48,684 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 16), features.5:(19, 32), features.7:(32, 32), features.10:(44, 64), features.12:(115, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:17:48,824 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(54, 16), features.5:(16, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(102, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:17:49,296 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 16), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (44, 64), 'features.12': (115, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 208.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.58 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.91 GiB is allocated by PyTorch, and 272.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:17:49,333 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(22, 19), features.5:(41, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 18:18:05,835 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(22, 19), features.5:(41, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 18:18:12,686 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (22, 19), 'features.5': (41, 38), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 190.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.60 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.85 GiB is allocated by PyTorch, and 356.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:18:12,690 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (54, 16), 'features.5': (16, 32), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (102, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 179), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 92.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.85 GiB is allocated by PyTorch, and 450.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:18:12,699 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (28, 22), 'features.5': (19, 32), 'features.7': (64, 32), 'features.10': (38, 64), 'features.12': (76, 102), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 190.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.60 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.82 GiB is allocated by PyTorch, and 383.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:18:12,790 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(38, 25), features.5:(28, 38), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:18:12,792 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 35), features.5:(22, 32), features.7:(44, 32), features.10:(32, 64), features.12:(76, 64), features.14:(89, 76), features.17:(76, 128), features.19:(128, 204), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:18:12,795 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(25, 22), features.5:(16, 44), features.7:(32, 32), features.10:(57, 76), features.12:(76, 76), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 153)\n",
      "2025-03-30 18:18:30,838 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(38, 25), features.5:(28, 38), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:18:31,210 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(25, 22), features.5:(16, 44), features.7:(32, 32), features.10:(57, 76), features.12:(76, 76), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 153)\n",
      "2025-03-30 18:18:31,211 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 35), features.5:(22, 32), features.7:(44, 32), features.10:(32, 64), features.12:(76, 64), features.14:(89, 76), features.17:(76, 128), features.19:(128, 204), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:19:07,288 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 35), 'features.5': (22, 32), 'features.7': (44, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (89, 76), 'features.17': (76, 128), 'features.19': (128, 204), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 504.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.29 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.23 GiB is allocated by PyTorch, and 3.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:19:07,433 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(16, 19), features.5:(32, 38), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 153), features.19:(128, 128), features.21:(179, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:19:24,224 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(16, 19), features.5:(32, 38), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 153), features.19:(128, 128), features.21:(179, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:19:33,772 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (16, 19), 'features.5': (32, 38), 'features.7': (32, 44), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 76), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (179, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 48.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.74 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 34.09 GiB is allocated by PyTorch, and 3.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:19:33,950 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 25), features.5:(25, 38), features.7:(32, 38), features.10:(44, 76), features.12:(89, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:19:50,886 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 25), features.5:(25, 38), features.7:(32, 38), features.10:(44, 76), features.12:(89, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 18:20:05,180 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (19, 25), 'features.5': (25, 38), 'features.7': (32, 38), 'features.10': (44, 76), 'features.12': (89, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 74.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.71 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.70 GiB is allocated by PyTorch, and 629.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:20:05,190 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (38, 25), 'features.5': (28, 38), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 78.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.71 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.74 GiB is allocated by PyTorch, and 583.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:20:05,197 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(35, 16), features.5:(22, 51), features.7:(32, 38), features.10:(70, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:20:05,234 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 16), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(89, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 179), features.26:(128, 128), features.28:(153, 153)\n",
      "2025-03-30 18:20:23,860 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(35, 16), features.5:(22, 51), features.7:(32, 38), features.10:(70, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:20:24,309 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 16), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(89, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 179), features.26:(128, 128), features.28:(153, 153)\n",
      "2025-03-30 18:20:39,710 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (35, 16), 'features.5': (22, 51), 'features.7': (32, 38), 'features.10': (70, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 50.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.74 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.88 GiB is allocated by PyTorch, and 460.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:20:39,745 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 28), features.5:(19, 44), features.7:(76, 32), features.10:(64, 76), features.12:(64, 64), features.14:(89, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:20:57,012 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 28), features.5:(19, 44), features.7:(76, 32), features.10:(64, 76), features.12:(64, 64), features.14:(89, 64), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:21:14,759 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 28), 'features.5': (19, 44), 'features.7': (76, 32), 'features.10': (64, 76), 'features.12': (64, 64), 'features.14': (89, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 672.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.13 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.35 GiB is allocated by PyTorch, and 3.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:21:14,865 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 19), features.5:(16, 51), features.7:(38, 32), features.10:(57, 102), features.12:(76, 64), features.14:(89, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:21:31,094 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 19), features.5:(16, 51), features.7:(38, 32), features.10:(57, 102), features.12:(76, 64), features.14:(89, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:21:41,645 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 19), 'features.5': (16, 51), 'features.7': (38, 32), 'features.10': (57, 102), 'features.12': (76, 64), 'features.14': (89, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 380.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.41 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.62 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:21:41,690 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 16), 'features.5': (16, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (89, 64), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 179), 'features.26': (128, 128), 'features.28': (153, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 382.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.41 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 34.06 GiB is allocated by PyTorch, and 2.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:21:41,714 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 32), features.5:(28, 38), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 18:21:41,717 - MainProcess - INFO - Compressing to:features.0:(1, 28), features.2:(22, 16), features.5:(16, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 18:22:00,564 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 32), features.5:(28, 38), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 18:22:01,901 - MainProcess - INFO - finetuning:features.0:(1, 28), features.2:(22, 16), features.5:(16, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 18:22:10,695 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 32), 'features.5': (28, 38), 'features.7': (44, 32), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 52.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.73 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.73 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:22:10,703 - MainProcess - ERROR - Error processing config: {'features.0': (1, 28), 'features.2': (22, 16), 'features.5': (16, 32), 'features.7': (44, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 252.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.54 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.61 GiB is allocated by PyTorch, and 1.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:22:10,706 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 28), features.5:(19, 64), features.7:(32, 32), features.10:(51, 64), features.12:(89, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:22:10,746 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(28, 22), features.5:(44, 57), features.7:(57, 32), features.10:(44, 64), features.12:(64, 89), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 18:22:29,335 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 28), features.5:(19, 64), features.7:(32, 32), features.10:(51, 64), features.12:(89, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:22:30,814 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(28, 22), features.5:(44, 57), features.7:(57, 32), features.10:(44, 64), features.12:(64, 89), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 18:22:34,146 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (25, 22), 'features.5': (16, 44), 'features.7': (32, 32), 'features.10': (57, 76), 'features.12': (76, 76), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (153, 153), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 62.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.72 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.10 GiB is allocated by PyTorch, and 222.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:22:34,180 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(28, 28), features.5:(16, 57), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:22:51,037 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(28, 28), features.5:(16, 57), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:22:56,751 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 22), 'features.5': (19, 32), 'features.7': (32, 51), 'features.10': (51, 64), 'features.12': (64, 64), 'features.14': (89, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 32.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.75 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.01 GiB is allocated by PyTorch, and 347.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:22:56,767 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 28), 'features.5': (19, 64), 'features.7': (32, 32), 'features.10': (51, 64), 'features.12': (89, 76), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 60.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.73 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.98 GiB is allocated by PyTorch, and 349.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:22:56,777 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 25), features.5:(22, 44), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:22:56,825 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 22), features.5:(22, 32), features.7:(32, 32), features.10:(38, 64), features.12:(102, 76), features.14:(102, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:23:15,295 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 25), features.5:(22, 44), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:23:16,256 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 22), features.5:(22, 32), features.7:(32, 32), features.10:(38, 64), features.12:(102, 76), features.14:(102, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:23:19,439 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 22), 'features.5': (22, 32), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (102, 76), 'features.14': (102, 76), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 782.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.02 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 34.04 GiB is allocated by PyTorch, and 2.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:23:19,558 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 28), features.5:(25, 32), features.7:(44, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:23:35,930 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 28), features.5:(25, 32), features.7:(44, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:24:30,439 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 28), 'features.5': (25, 32), 'features.7': (44, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 296.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.50 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.74 GiB is allocated by PyTorch, and 357.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:24:30,475 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 32), features.5:(16, 32), features.7:(44, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:24:47,102 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 32), features.5:(16, 32), features.7:(44, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:25:03,903 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 32), 'features.5': (16, 32), 'features.7': (44, 32), 'features.10': (57, 64), 'features.12': (64, 64), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 296.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.50 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 34.18 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:25:04,096 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 19), features.5:(35, 32), features.7:(32, 38), features.10:(51, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:25:20,353 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 19), features.5:(35, 32), features.7:(32, 38), features.10:(51, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:25:34,101 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (28, 22), 'features.5': (44, 57), 'features.7': (57, 32), 'features.10': (44, 64), 'features.12': (64, 89), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (153, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.04 GiB is allocated by PyTorch, and 325.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:25:34,107 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (28, 28), 'features.5': (16, 57), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (102, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.76 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.06 GiB is allocated by PyTorch, and 308.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:25:34,113 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 19), 'features.5': (35, 32), 'features.7': (32, 38), 'features.10': (51, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 48.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.74 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.02 GiB is allocated by PyTorch, and 325.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:25:34,117 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 25), features.5:(51, 32), features.7:(57, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(153, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:25:34,177 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 35), features.5:(25, 38), features.7:(38, 32), features.10:(32, 64), features.12:(76, 64), features.14:(76, 64), features.17:(192, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 18:25:34,180 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(41, 25), features.5:(19, 32), features.7:(44, 32), features.10:(32, 102), features.12:(64, 64), features.14:(76, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:25:53,614 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 25), features.5:(51, 32), features.7:(57, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(153, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:25:54,512 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 35), features.5:(25, 38), features.7:(38, 32), features.10:(32, 64), features.12:(76, 64), features.14:(76, 64), features.17:(192, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 18:25:54,907 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(41, 25), features.5:(19, 32), features.7:(44, 32), features.10:(32, 102), features.12:(64, 64), features.14:(76, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:25:56,882 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 35), 'features.5': (25, 38), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (76, 64), 'features.17': (192, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 248.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.54 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.84 GiB is allocated by PyTorch, and 309.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:25:56,915 - MainProcess - INFO - Compressing to:features.0:(2, 38), features.2:(25, 19), features.5:(22, 38), features.7:(83, 38), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:26:13,593 - MainProcess - INFO - finetuning:features.0:(2, 38), features.2:(25, 19), features.5:(22, 38), features.7:(83, 38), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:26:26,310 - MainProcess - ERROR - Error processing config: {'features.0': (2, 38), 'features.2': (25, 19), 'features.5': (22, 38), 'features.7': (83, 38), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 98.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.69 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.19 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:26:26,327 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 25), 'features.5': (51, 32), 'features.7': (57, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (153, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 296.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.50 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.06 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:26:26,362 - MainProcess - INFO - Compressing to:features.0:(1, 28), features.2:(19, 35), features.5:(19, 51), features.7:(38, 32), features.10:(51, 64), features.12:(64, 76), features.14:(115, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:26:26,365 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(25, 32), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(153, 128), features.21:(153, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:26:45,658 - MainProcess - INFO - finetuning:features.0:(1, 28), features.2:(19, 35), features.5:(19, 51), features.7:(38, 32), features.10:(51, 64), features.12:(64, 76), features.14:(115, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:26:46,112 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(25, 32), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(153, 128), features.21:(153, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:26:57,370 - MainProcess - ERROR - Error processing config: {'features.0': (1, 28), 'features.2': (19, 35), 'features.5': (19, 51), 'features.7': (38, 32), 'features.10': (51, 64), 'features.12': (64, 76), 'features.14': (115, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 298.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.49 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.84 GiB is allocated by PyTorch, and 257.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:26:57,403 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 16), features.5:(35, 38), features.7:(38, 32), features.10:(44, 76), features.12:(102, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:27:13,765 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 16), features.5:(35, 38), features.7:(38, 32), features.10:(44, 76), features.12:(102, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:27:37,528 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 16), 'features.5': (35, 38), 'features.7': (38, 32), 'features.10': (44, 76), 'features.12': (102, 64), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 534.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.26 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.46 GiB is allocated by PyTorch, and 3.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:27:37,618 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(38, 28), features.5:(22, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(89, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(204, 153)\n",
      "2025-03-30 18:27:54,399 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(38, 28), features.5:(22, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(89, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(204, 153)\n",
      "2025-03-30 18:28:07,712 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (38, 28), 'features.5': (22, 38), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (89, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (204, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 314.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.48 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.54 GiB is allocated by PyTorch, and 549.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:28:07,772 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(32, 16), features.5:(32, 44), features.7:(51, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(153, 128), features.21:(128, 128), features.24:(128, 204), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:28:24,448 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(32, 16), features.5:(32, 44), features.7:(51, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(153, 128), features.21:(128, 128), features.24:(128, 204), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:28:25,626 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (32, 16), 'features.5': (32, 44), 'features.7': (51, 38), 'features.10': (51, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 153), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 204), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 380.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.41 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.75 GiB is allocated by PyTorch, and 267.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:28:25,676 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(22, 16), features.5:(16, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:28:42,383 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(22, 16), features.5:(16, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:28:56,945 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (22, 16), 'features.5': (16, 38), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 212.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.58 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 32.70 GiB is allocated by PyTorch, and 4.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:28:57,019 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(25, 19), features.5:(32, 44), features.7:(38, 64), features.10:(44, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:29:13,632 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(25, 19), features.5:(32, 44), features.7:(38, 64), features.10:(44, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:29:16,039 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (25, 19), 'features.5': (32, 44), 'features.7': (38, 64), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (89, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 202.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.59 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.48 GiB is allocated by PyTorch, and 725.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:29:16,065 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(25, 19), features.5:(19, 38), features.7:(32, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(179, 128)\n",
      "2025-03-30 18:29:32,450 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(25, 19), features.5:(19, 38), features.7:(32, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(179, 128)\n",
      "2025-03-30 18:29:53,147 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (25, 19), 'features.5': (19, 38), 'features.7': (32, 38), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (179, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 270.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.52 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.79 GiB is allocated by PyTorch, and 335.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:29:53,153 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (25, 32), 'features.5': (22, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (153, 128), 'features.21': (153, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 270.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.52 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.85 GiB is allocated by PyTorch, and 275.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:29:53,160 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (41, 25), 'features.5': (19, 32), 'features.7': (44, 32), 'features.10': (32, 102), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 272.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.52 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.91 GiB is allocated by PyTorch, and 213.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:29:53,188 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(19, 19), features.5:(16, 57), features.7:(76, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 18:29:53,188 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 25), features.5:(32, 32), features.7:(32, 32), features.10:(57, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:29:53,245 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 16), features.5:(16, 38), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 102), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:30:12,726 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(19, 19), features.5:(16, 57), features.7:(76, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 18:30:12,868 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 25), features.5:(32, 32), features.7:(32, 32), features.10:(57, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:30:14,052 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 16), features.5:(16, 38), features.7:(44, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 102), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:30:55,087 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (19, 25), 'features.5': (32, 32), 'features.7': (32, 32), 'features.10': (57, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 682.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.12 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.33 GiB is allocated by PyTorch, and 3.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:30:55,176 - MainProcess - INFO - Compressing to:features.0:(2, 41), features.2:(19, 22), features.5:(22, 57), features.7:(32, 44), features.10:(38, 64), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:31:11,905 - MainProcess - INFO - finetuning:features.0:(2, 41), features.2:(19, 22), features.5:(22, 57), features.7:(32, 44), features.10:(38, 64), features.12:(64, 102), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:31:37,144 - MainProcess - ERROR - Error processing config: {'features.0': (2, 41), 'features.2': (19, 22), 'features.5': (22, 57), 'features.7': (32, 44), 'features.10': (38, 64), 'features.12': (64, 102), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (179, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 98.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.69 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.03 GiB is allocated by PyTorch, and 2.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:31:37,207 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(22, 32), features.5:(57, 38), features.7:(38, 32), features.10:(44, 64), features.12:(76, 89), features.14:(76, 64), features.17:(89, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:31:53,660 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(22, 32), features.5:(57, 38), features.7:(38, 32), features.10:(44, 64), features.12:(76, 89), features.14:(76, 64), features.17:(89, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:31:56,544 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (22, 32), 'features.5': (57, 38), 'features.7': (38, 32), 'features.10': (44, 64), 'features.12': (76, 89), 'features.14': (76, 64), 'features.17': (89, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 732.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.07 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.61 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:31:56,653 - MainProcess - INFO - Compressing to:features.0:(1, 28), features.2:(19, 19), features.5:(19, 38), features.7:(38, 38), features.10:(38, 64), features.12:(64, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 153)\n",
      "2025-03-30 18:32:13,340 - MainProcess - INFO - finetuning:features.0:(1, 28), features.2:(19, 19), features.5:(19, 38), features.7:(38, 38), features.10:(38, 64), features.12:(64, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 153)\n",
      "2025-03-30 18:32:22,898 - MainProcess - ERROR - Error processing config: {'features.0': (1, 28), 'features.2': (19, 19), 'features.5': (19, 38), 'features.7': (38, 38), 'features.10': (38, 64), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 334.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.46 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.42 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:32:23,039 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 16), features.5:(16, 32), features.7:(44, 57), features.10:(32, 64), features.12:(64, 102), features.14:(64, 76), features.17:(64, 128), features.19:(128, 179), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:32:39,146 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 16), features.5:(16, 32), features.7:(44, 57), features.10:(32, 64), features.12:(64, 102), features.14:(64, 76), features.17:(64, 128), features.19:(128, 179), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:32:40,495 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 16), 'features.5': (16, 32), 'features.7': (44, 57), 'features.10': (32, 64), 'features.12': (64, 102), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 179), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 732.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.07 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.37 GiB is allocated by PyTorch, and 3.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:32:40,601 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(32, 16), features.5:(19, 64), features.7:(57, 32), features.10:(32, 64), features.12:(64, 76), features.14:(89, 64), features.17:(76, 128), features.19:(128, 128), features.21:(179, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:32:57,687 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(32, 16), features.5:(19, 64), features.7:(57, 32), features.10:(32, 64), features.12:(64, 76), features.14:(89, 64), features.17:(76, 128), features.19:(128, 128), features.21:(179, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:33:24,367 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (32, 16), 'features.5': (19, 64), 'features.7': (57, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (89, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (179, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 96.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.69 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.84 GiB is allocated by PyTorch, and 460.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:33:24,408 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(32, 32), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 89), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:33:39,434 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(32, 32), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 89), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:33:53,786 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (32, 32), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 89), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 62.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.72 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.40 GiB is allocated by PyTorch, and 941.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:33:53,828 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(28, 22), features.5:(22, 38), features.7:(32, 57), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:34:09,707 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(28, 22), features.5:(22, 38), features.7:(32, 57), features.10:(44, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:34:38,775 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (28, 22), 'features.5': (22, 38), 'features.7': (32, 57), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 580.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.22 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.81 GiB is allocated by PyTorch, and 3.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:34:38,985 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(22, 16), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 115), features.14:(64, 89), features.17:(89, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:34:56,629 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(22, 16), features.5:(19, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 115), features.14:(64, 89), features.17:(89, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:35:12,993 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (22, 16), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (76, 115), 'features.14': (64, 89), 'features.17': (89, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 184.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.61 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 34.59 GiB is allocated by PyTorch, and 2.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:35:13,055 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 22), features.5:(32, 32), features.7:(32, 32), features.10:(32, 76), features.12:(64, 76), features.14:(76, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:35:30,186 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 22), features.5:(32, 32), features.7:(32, 32), features.10:(32, 76), features.12:(64, 76), features.14:(76, 76), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:36:02,421 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 22), 'features.5': (32, 32), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 76), 'features.14': (76, 76), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 592.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.21 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 32.92 GiB is allocated by PyTorch, and 3.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:36:02,538 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(41, 22), features.5:(19, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:36:19,509 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(41, 22), features.5:(19, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:36:21,505 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (41, 22), 'features.5': (19, 32), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 738.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.06 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.59 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:36:21,628 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 16), features.5:(19, 51), features.7:(32, 38), features.10:(32, 64), features.12:(102, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:36:38,489 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 16), features.5:(19, 51), features.7:(32, 38), features.10:(32, 64), features.12:(102, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:36:49,089 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 16), 'features.5': (19, 51), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (102, 89), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 590.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.21 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.29 GiB is allocated by PyTorch, and 3.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:36:49,229 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 19), features.5:(25, 32), features.7:(32, 32), features.10:(44, 76), features.12:(64, 89), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:37:06,130 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 19), features.5:(25, 32), features.7:(32, 32), features.10:(44, 76), features.12:(64, 89), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:37:30,661 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 19), 'features.5': (25, 32), 'features.7': (32, 32), 'features.10': (44, 76), 'features.12': (64, 89), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 518.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.28 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.29 GiB is allocated by PyTorch, and 3.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:37:30,781 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(28, 32), features.5:(16, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:37:47,344 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(28, 32), features.5:(16, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:38:03,404 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (28, 32), 'features.5': (16, 38), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 320.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.47 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.08 GiB is allocated by PyTorch, and 1.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:38:03,537 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(28, 28), features.5:(28, 32), features.7:(64, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:38:20,329 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(28, 28), features.5:(28, 32), features.7:(64, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:38:27,167 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (28, 28), 'features.5': (28, 32), 'features.7': (64, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 264.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.53 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.65 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:38:27,268 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 22), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:38:44,048 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 22), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 18:39:07,199 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (19, 22), 'features.5': (19, 32), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 54.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.73 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.90 GiB is allocated by PyTorch, and 438.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:39:07,203 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (19, 19), 'features.5': (16, 57), 'features.7': (76, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 54.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.73 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.78 GiB is allocated by PyTorch, and 567.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:39:07,231 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 16), 'features.5': (16, 38), 'features.7': (44, 32), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (64, 102), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 152.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.64 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.34 GiB is allocated by PyTorch, and 911.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:39:07,258 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 25), features.5:(16, 32), features.7:(38, 32), features.10:(32, 64), features.12:(89, 89), features.14:(102, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:39:07,258 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(22, 28), features.5:(22, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 179), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:39:07,300 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(19, 16), features.5:(19, 32), features.7:(44, 32), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:39:27,178 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 25), features.5:(16, 32), features.7:(38, 32), features.10:(32, 64), features.12:(89, 89), features.14:(102, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:39:27,178 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(19, 16), features.5:(19, 32), features.7:(44, 32), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:39:28,664 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(22, 28), features.5:(22, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 179), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:39:47,835 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (22, 28), 'features.5': (22, 32), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 179), 'features.21': (128, 153), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 540.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.26 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.61 GiB is allocated by PyTorch, and 3.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:39:47,962 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(41, 22), features.5:(16, 32), features.7:(38, 32), features.10:(64, 76), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:40:05,100 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(41, 22), features.5:(16, 32), features.7:(38, 32), features.10:(64, 76), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:40:13,767 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (41, 22), 'features.5': (16, 32), 'features.7': (38, 32), 'features.10': (64, 76), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 338.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.46 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.44 GiB is allocated by PyTorch, and 622.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:40:13,836 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(25, 32), features.5:(25, 44), features.7:(70, 44), features.10:(32, 76), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:40:30,777 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(25, 32), features.5:(25, 44), features.7:(70, 44), features.10:(32, 76), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:40:37,310 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (25, 32), 'features.5': (25, 44), 'features.7': (70, 44), 'features.10': (32, 76), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 38.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.75 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 33.01 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:40:37,501 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(35, 22), features.5:(16, 32), features.7:(38, 44), features.10:(51, 89), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:40:55,020 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(35, 22), features.5:(16, 32), features.7:(38, 44), features.10:(51, 89), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:41:10,257 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (35, 22), 'features.5': (16, 32), 'features.7': (38, 44), 'features.10': (51, 89), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 374.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.42 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 34.73 GiB is allocated by PyTorch, and 2.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:41:10,300 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 16), features.5:(22, 32), features.7:(38, 57), features.10:(38, 64), features.12:(64, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:41:26,489 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 16), features.5:(22, 32), features.7:(38, 57), features.10:(38, 64), features.12:(64, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:42:18,204 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 16), 'features.5': (22, 32), 'features.7': (38, 57), 'features.10': (38, 64), 'features.12': (64, 76), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 179), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 464.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.33 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 32.13 GiB is allocated by PyTorch, and 4.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:42:18,274 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(25, 16), features.5:(28, 44), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:42:35,033 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(25, 16), features.5:(28, 44), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 18:42:37,934 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (25, 16), 'features.5': (28, 44), 'features.7': (32, 44), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 124.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.09 GiB is allocated by PyTorch, and 2.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:42:37,995 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(22, 16), features.5:(19, 38), features.7:(44, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:42:54,824 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(22, 16), features.5:(19, 38), features.7:(44, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:43:26,208 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (22, 16), 'features.5': (19, 38), 'features.7': (44, 44), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 86.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.70 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.74 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 36.07 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:43:26,247 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(19, 22), features.5:(35, 32), features.7:(32, 51), features.10:(32, 64), features.12:(64, 76), features.14:(76, 64), features.17:(89, 128), features.19:(128, 128), features.21:(153, 204), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:43:42,449 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(19, 22), features.5:(35, 32), features.7:(32, 51), features.10:(32, 64), features.12:(64, 76), features.14:(76, 64), features.17:(89, 128), features.19:(128, 128), features.21:(153, 204), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:44:33,021 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (19, 22), 'features.5': (35, 32), 'features.7': (32, 51), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (76, 64), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (153, 204), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 562.31 MiB is free. Process 3928929 has 3.16 GiB memory in use. Process 3930001 has 764.00 MiB memory in use. Including non-PyTorch memory, this process has 37.23 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.75 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 32.20 GiB is allocated by PyTorch, and 4.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 18:44:33,109 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(16, 16), features.5:(19, 38), features.7:(32, 38), features.10:(38, 64), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:44:49,990 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(16, 16), features.5:(19, 38), features.7:(32, 38), features.10:(38, 64), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0611\n",
      "Epoch 1/3, Loss: 0.0649\n",
      "Epoch 3/3, Loss: 0.0207\n",
      "Epoch 1/3, Loss: 0.0694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:52:50,107 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(16, 25), features.5:(22, 44), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121436289,\n",
      "    \"flops\": 4841435658,\n",
      "    \"accuracy\": 0.9926,\n",
      "    \"inference_time\": 0.3656270600175149,\n",
      "    \"compression_rate\": 1.1059421784537569,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 18:52:50,240 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 16), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 18:53:06,185 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 16), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0256\n",
      "Epoch 2/3, Loss: 0.0271\n",
      "Epoch 2/3, Loss: 0.0270\n",
      "Epoch 1/3, Loss: 0.0664\n",
      "Epoch 3/3, Loss: 0.0202\n",
      "Epoch 3/3, Loss: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:06:29,899 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 32), features.2:(16, 16), features.5:(19, 38), features.7:(32, 38), features.10:(38, 64), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121367787,\n",
      "    \"flops\": 4632803850,\n",
      "    \"accuracy\": 0.9934,\n",
      "    \"inference_time\": 0.21565767964486612,\n",
      "    \"compression_rate\": 1.1065663906354328,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 19:06:30,077 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 16), features.5:(16, 32), features.7:(44, 32), features.10:(32, 64), features.12:(64, 64), features.14:(89, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 179)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:06:42,745 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 16), features.5:(16, 32), features.7:(44, 32), features.10:(32, 64), features.12:(64, 64), features.14:(89, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 179)\n",
      "2025-03-30 19:07:13,209 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(16, 25), features.5:(16, 32), features.7:(38, 32), features.10:(32, 64), features.12:(89, 89), features.14:(102, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121430866,\n",
      "    \"flops\": 4893672010,\n",
      "    \"accuracy\": 0.993,\n",
      "    \"inference_time\": 0.21333728828754142,\n",
      "    \"compression_rate\": 1.1059915688981417,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 19:07:13,296 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(44, 19), features.5:(19, 32), features.7:(32, 32), features.10:(32, 76), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(204, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 19:07:26,682 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(44, 19), features.5:(19, 32), features.7:(32, 32), features.10:(32, 76), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(204, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 19:09:36,880 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 25), features.2:(19, 16), features.5:(19, 32), features.7:(44, 32), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121391961,\n",
      "    \"flops\": 3307008522,\n",
      "    \"accuracy\": 0.9945,\n",
      "    \"inference_time\": 0.29190707763542284,\n",
      "    \"compression_rate\": 1.1063460289598583,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 19:09:36,988 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(16, 22), features.5:(51, 44), features.7:(32, 44), features.10:(51, 76), features.12:(102, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 153)\n",
      "2025-03-30 19:09:50,553 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(16, 22), features.5:(51, 44), features.7:(32, 44), features.10:(51, 76), features.12:(102, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1695\n",
      "Epoch 2/3, Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:14:17,731 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 16), 'features.5': (16, 32), 'features.7': (44, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (89, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 179)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 356.19 MiB is free. Including non-PyTorch memory, this process has 41.34 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 38.82 GiB is allocated by PyTorch, and 2.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 19:14:17,804 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(28, 44), features.5:(16, 32), features.7:(44, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(89, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 19:14:31,613 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(28, 44), features.5:(16, 32), features.7:(44, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(89, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 19:15:15,547 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (28, 44), 'features.5': (16, 32), 'features.7': (44, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (89, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.42 GiB is allocated by PyTorch, and 3.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 19:15:15,707 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(38, 16), features.5:(16, 44), features.7:(38, 32), features.10:(38, 76), features.12:(64, 76), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 179), features.28:(128, 128)\n",
      "2025-03-30 19:15:29,739 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(38, 16), features.5:(16, 44), features.7:(38, 32), features.10:(38, 76), features.12:(64, 76), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 179), features.28:(128, 128)\n",
      "2025-03-30 19:16:22,383 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (38, 16), 'features.5': (16, 44), 'features.7': (38, 32), 'features.10': (38, 76), 'features.12': (64, 76), 'features.14': (76, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 179), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 688.19 MiB is free. Including non-PyTorch memory, this process has 41.01 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.20 GiB is allocated by PyTorch, and 3.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 19:16:22,500 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(25, 22), features.5:(22, 32), features.7:(38, 38), features.10:(32, 76), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:16:36,568 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(25, 22), features.5:(22, 32), features.7:(38, 38), features.10:(32, 76), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1294\n",
      "Epoch 1/3, Loss: 0.0669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:22:32,186 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (25, 22), 'features.5': (22, 32), 'features.7': (38, 38), 'features.10': (32, 76), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 380.19 MiB is free. Including non-PyTorch memory, this process has 41.31 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.22 GiB is allocated by PyTorch, and 5.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 19:22:32,351 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 22), features.5:(16, 38), features.7:(57, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(204, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 19:22:48,594 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 22), features.5:(16, 38), features.7:(57, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(204, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0216\n",
      "Epoch 2/3, Loss: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:27:34,688 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(16, 16), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121371785,\n",
      "    \"flops\": 4544995850,\n",
      "    \"accuracy\": 0.9925,\n",
      "    \"inference_time\": 0.3119249156579344,\n",
      "    \"compression_rate\": 1.1065299402163362,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 19:27:34,933 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(28, 25), features.5:(19, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 89), features.14:(76, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 19:27:51,848 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(28, 25), features.5:(19, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 89), features.14:(76, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0650\n",
      "Epoch 2/3, Loss: 0.0325\n",
      "Epoch 3/3, Loss: 0.0203\n",
      "Epoch 2/3, Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:37:30,849 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 22), features.2:(44, 19), features.5:(19, 32), features.7:(32, 32), features.10:(32, 76), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(204, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121497549,\n",
      "    \"flops\": 2522531850,\n",
      "    \"accuracy\": 0.9929,\n",
      "    \"inference_time\": 0.30376364521666444,\n",
      "    \"compression_rate\": 1.105384553889231,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 19:37:31,010 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(22, 25), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 19:37:31,011 - MainProcess - INFO - Evaluated 60 configurations, found 60 accepted models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:37:47,442 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(22, 25), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0634\n",
      "Epoch 3/3, Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:40:46,012 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 22), features.2:(16, 22), features.5:(51, 44), features.7:(32, 44), features.10:(51, 76), features.12:(102, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 153)\",\n",
      "    \"params\": 121502326,\n",
      "    \"flops\": 5106001162,\n",
      "    \"accuracy\": 0.9921,\n",
      "    \"inference_time\": 0.2755182219665268,\n",
      "    \"compression_rate\": 1.1053410944577309,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 19:40:46,127 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(25, 16), features.5:(16, 32), features.7:(32, 51), features.10:(32, 76), features.12:(89, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 19:41:00,860 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(25, 16), features.5:(16, 32), features.7:(32, 51), features.10:(32, 76), features.12:(89, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 19:43:21,149 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(19, 22), features.5:(16, 38), features.7:(57, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(153, 128), features.21:(204, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121527111,\n",
      "    \"flops\": 2491372554,\n",
      "    \"accuracy\": 0.9934,\n",
      "    \"inference_time\": 0.30524987931464126,\n",
      "    \"compression_rate\": 1.105115664273464,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 19:43:21,244 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(41, 38), features.5:(16, 32), features.7:(38, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 19:43:39,323 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(41, 38), features.5:(16, 32), features.7:(38, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0675\n",
      "Epoch 2/3, Loss: 0.0257\n",
      "Epoch 1/3, Loss: 0.1644\n",
      "Epoch 1/3, Loss: 0.1691\n",
      "Epoch 2/3, Loss: 0.0270\n",
      "Epoch 2/3, Loss: 0.0349\n",
      "Epoch 2/3, Loss: 0.0348\n",
      "Epoch 3/3, Loss: 0.0202\n",
      "Epoch 3/3, Loss: 0.0279\n",
      "Epoch 3/3, Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:02:46,219 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 22), features.2:(28, 25), features.5:(19, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 89), features.14:(76, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121513735,\n",
      "    \"flops\": 3762754570,\n",
      "    \"accuracy\": 0.9931,\n",
      "    \"inference_time\": 0.21405284521179846,\n",
      "    \"compression_rate\": 1.1052373132963118,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 20:02:46,385 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(38, 19), features.5:(22, 32), features.7:(57, 32), features.10:(38, 89), features.12:(64, 89), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 20:03:02,075 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(38, 19), features.5:(22, 32), features.7:(57, 32), features.10:(38, 89), features.12:(64, 89), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 20:03:29,680 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(41, 38), features.5:(16, 32), features.7:(38, 38), features.10:(38, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121404216,\n",
      "    \"flops\": 3456332298,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.21280440403397674,\n",
      "    \"compression_rate\": 1.106234350213999,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 20:03:29,751 - MainProcess - INFO - Compressing to:features.0:(1, 32), features.2:(32, 22), features.5:(19, 44), features.7:(44, 57), features.10:(32, 64), features.12:(89, 76), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 20:03:46,787 - MainProcess - INFO - finetuning:features.0:(1, 32), features.2:(32, 22), features.5:(19, 44), features.7:(44, 57), features.10:(32, 64), features.12:(89, 76), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 20:05:06,572 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 22), features.2:(22, 25), features.5:(16, 32), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121416363,\n",
      "    \"flops\": 3439410442,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.2682851661795517,\n",
      "    \"compression_rate\": 1.106123677909871,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 20:05:06,705 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(28, 25), features.5:(19, 32), features.7:(32, 57), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 20:05:23,228 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(28, 25), features.5:(19, 32), features.7:(32, 57), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0272\n",
      "Epoch 1/3, Loss: 0.1486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:11:24,208 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(25, 16), features.5:(16, 32), features.7:(32, 51), features.10:(32, 76), features.12:(89, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\",\n",
      "    \"params\": 121446366,\n",
      "    \"flops\": 4815695370,\n",
      "    \"accuracy\": 0.9924,\n",
      "    \"inference_time\": 0.31868472524509306,\n",
      "    \"compression_rate\": 1.1058504130127698,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 20:11:24,370 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 16), features.5:(38, 38), features.7:(32, 32), features.10:(32, 64), features.12:(89, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 20:11:41,045 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 16), features.5:(38, 38), features.7:(32, 32), features.10:(32, 64), features.12:(89, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0616\n",
      "Epoch 1/3, Loss: 0.0670\n",
      "Epoch 2/3, Loss: 0.0332\n",
      "Epoch 1/3, Loss: 0.0644\n",
      "Epoch 3/3, Loss: 0.0263\n",
      "Epoch 2/3, Loss: 0.0259\n",
      "Epoch 2/3, Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:25:16,679 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 32), features.2:(32, 22), features.5:(19, 44), features.7:(44, 57), features.10:(32, 64), features.12:(89, 76), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121463766,\n",
      "    \"flops\": 5270064138,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.31938371891175615,\n",
      "    \"compression_rate\": 1.105691997068492,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 20:25:16,834 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 19), features.5:(16, 32), features.7:(51, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 20:25:32,057 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 19), features.5:(16, 32), features.7:(51, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0207\n",
      "Epoch 2/3, Loss: 0.0271\n",
      "Epoch 1/3, Loss: 0.0693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:32:34,116 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(28, 25), features.5:(19, 32), features.7:(32, 57), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121459493,\n",
      "    \"flops\": 5008622090,\n",
      "    \"accuracy\": 0.9931,\n",
      "    \"inference_time\": 0.2979643031037284,\n",
      "    \"compression_rate\": 1.1057308958139649,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 20:32:34,258 - MainProcess - INFO - Compressing to:features.0:(2, 44), features.2:(16, 16), features.5:(19, 64), features.7:(44, 44), features.10:(38, 64), features.12:(76, 76), features.14:(76, 76), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 20:32:50,800 - MainProcess - INFO - finetuning:features.0:(2, 44), features.2:(16, 16), features.5:(19, 64), features.7:(44, 44), features.10:(38, 64), features.12:(76, 76), features.14:(76, 76), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:36:24,817 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 22), features.2:(38, 19), features.5:(22, 32), features.7:(57, 32), features.10:(38, 89), features.12:(64, 89), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121393905,\n",
      "    \"flops\": 3925315978,\n",
      "    \"accuracy\": 0.992,\n",
      "    \"inference_time\": 0.29558451312362766,\n",
      "    \"compression_rate\": 1.1063283119527294,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 20:36:24,970 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(28, 19), features.5:(19, 32), features.7:(38, 38), features.10:(32, 89), features.12:(76, 76), features.14:(64, 64), features.17:(64, 128), features.19:(153, 179), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:36:42,300 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(28, 19), features.5:(19, 32), features.7:(38, 38), features.10:(32, 89), features.12:(76, 76), features.14:(64, 64), features.17:(64, 128), features.19:(153, 179), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0206\n",
      "Epoch 1/3, Loss: 0.0603\n",
      "Epoch 3/3, Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:42:17,873 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(16, 16), features.5:(38, 38), features.7:(32, 32), features.10:(32, 64), features.12:(89, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121414361,\n",
      "    \"flops\": 3527567114,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.2914121965946918,\n",
      "    \"compression_rate\": 1.1061419167704551,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 20:42:18,077 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(16, 51), features.5:(16, 51), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 20:42:18,078 - MainProcess - INFO - Evaluated 70 configurations, found 70 accepted models\n",
      "2025-03-30 20:42:34,106 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(16, 51), features.5:(16, 51), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 20:45:20,001 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(16, 19), features.5:(16, 32), features.7:(51, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121357017,\n",
      "    \"flops\": 3391351818,\n",
      "    \"accuracy\": 0.9939,\n",
      "    \"inference_time\": 0.3012090620215025,\n",
      "    \"compression_rate\": 1.1066645944337936,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 20:45:20,056 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(51, 16), features.5:(19, 38), features.7:(38, 38), features.10:(64, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 20:45:36,765 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(51, 16), features.5:(19, 38), features.7:(38, 38), features.10:(64, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0664\n",
      "Epoch 2/3, Loss: 0.0255\n",
      "Epoch 1/3, Loss: 0.0689\n",
      "Epoch 1/3, Loss: 0.0652\n",
      "Epoch 2/3, Loss: 0.0270\n",
      "Epoch 3/3, Loss: 0.0207\n",
      "Epoch 2/3, Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 21:00:12,168 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 44), features.2:(16, 16), features.5:(19, 64), features.7:(44, 44), features.10:(38, 64), features.12:(76, 76), features.14:(76, 76), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\",\n",
      "    \"params\": 121540025,\n",
      "    \"flops\": 4970613770,\n",
      "    \"accuracy\": 0.994,\n",
      "    \"inference_time\": 0.3137500827732613,\n",
      "    \"compression_rate\": 1.1049982423485596,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 21:00:12,342 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(28, 16), features.5:(19, 38), features.7:(70, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 153), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:00:28,439 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(28, 16), features.5:(19, 38), features.7:(70, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 153), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0266\n",
      "Epoch 3/3, Loss: 0.0206\n",
      "Epoch 3/3, Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 21:06:55,530 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(51, 16), features.5:(19, 38), features.7:(38, 38), features.10:(64, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 179), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121496031,\n",
      "    \"flops\": 5079119370,\n",
      "    \"accuracy\": 0.9921,\n",
      "    \"inference_time\": 0.2806504967359474,\n",
      "    \"compression_rate\": 1.1053983648239505,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 21:06:55,667 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(44, 22), features.5:(19, 44), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 179)\n",
      "2025-03-30 21:07:11,760 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(44, 22), features.5:(19, 44), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 179)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0610\n",
      "Epoch 3/3, Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 21:09:40,519 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(28, 19), features.5:(19, 32), features.7:(38, 38), features.10:(32, 89), features.12:(76, 76), features.14:(64, 64), features.17:(64, 128), features.19:(153, 179), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121507300,\n",
      "    \"flops\": 4968119866,\n",
      "    \"accuracy\": 0.9939,\n",
      "    \"inference_time\": 0.3045304206273105,\n",
      "    \"compression_rate\": 1.105295846422396,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 21:09:40,620 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 19), features.5:(25, 32), features.7:(38, 32), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:09:56,999 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 19), features.5:(25, 32), features.7:(38, 32), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:12:45,659 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 28), features.2:(16, 51), features.5:(16, 51), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121348905,\n",
      "    \"flops\": 4951697418,\n",
      "    \"accuracy\": 0.9933,\n",
      "    \"inference_time\": 0.29631436554489615,\n",
      "    \"compression_rate\": 1.106738573372376,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 21:12:45,783 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 22), features.5:(16, 32), features.7:(44, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 21:13:02,675 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 22), features.5:(16, 32), features.7:(44, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 21:17:37,766 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (44, 22), 'features.5': (19, 44), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 179)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 766.19 MiB is free. Including non-PyTorch memory, this process has 40.94 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 35.92 GiB is allocated by PyTorch, and 4.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:17:37,878 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(25, 28), features.5:(16, 38), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:17:54,250 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(25, 28), features.5:(16, 38), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0613\n",
      "Epoch 1/3, Loss: 0.0671\n",
      "Epoch 1/3, Loss: 0.1310\n",
      "Epoch 3/3, Loss: 0.0209\n",
      "Epoch 2/3, Loss: 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 21:28:40,260 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(28, 16), features.5:(19, 38), features.7:(70, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 153), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121472619,\n",
      "    \"flops\": 5008521738,\n",
      "    \"accuracy\": 0.9936,\n",
      "    \"inference_time\": 0.30875985030156033,\n",
      "    \"compression_rate\": 1.1056114135482664,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 21:28:40,397 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 16), features.5:(35, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:28:54,615 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 16), features.5:(35, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0269\n",
      "Epoch 2/3, Loss: 0.0267\n",
      "Epoch 3/3, Loss: 0.0265\n",
      "Epoch 1/3, Loss: 0.1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 21:36:17,102 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(25, 28), features.5:(16, 38), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121377654,\n",
      "    \"flops\": 4920876810,\n",
      "    \"accuracy\": 0.9919,\n",
      "    \"inference_time\": 0.30659346064184884,\n",
      "    \"compression_rate\": 1.1064764359344101,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 21:36:17,234 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(22, 38), features.5:(19, 32), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 21:36:31,457 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(22, 38), features.5:(19, 32), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 21:38:51,967 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (22, 38), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 614.19 MiB is free. Including non-PyTorch memory, this process has 41.08 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 37.51 GiB is allocated by PyTorch, and 3.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:38:52,134 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 19), features.5:(28, 32), features.7:(38, 32), features.10:(44, 64), features.12:(64, 89), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:39:06,863 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 19), features.5:(28, 32), features.7:(38, 32), features.10:(44, 64), features.12:(64, 89), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0211\n",
      "Epoch 3/3, Loss: 0.0214\n",
      "Epoch 2/3, Loss: 0.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 21:43:44,145 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 22), features.2:(19, 22), features.5:(16, 32), features.7:(44, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121354683,\n",
      "    \"flops\": 2163974154,\n",
      "    \"accuracy\": 0.9937,\n",
      "    \"inference_time\": 0.2200319119066696,\n",
      "    \"compression_rate\": 1.1066858787806317,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 21:43:44,275 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 16), features.5:(35, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:43:59,556 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 16), features.5:(35, 38), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:44:12,941 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(22, 19), features.5:(25, 32), features.7:(38, 32), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121436839,\n",
      "    \"flops\": 4777671370,\n",
      "    \"accuracy\": 0.9936,\n",
      "    \"inference_time\": 0.22378343229840514,\n",
      "    \"compression_rate\": 1.10593716952728,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 21:44:13,050 - MainProcess - INFO - Compressing to:features.0:(2, 44), features.2:(19, 16), features.5:(19, 51), features.7:(32, 32), features.10:(51, 64), features.12:(89, 64), features.14:(115, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 179)\n",
      "2025-03-30 21:44:27,420 - MainProcess - INFO - finetuning:features.0:(2, 44), features.2:(19, 16), features.5:(19, 51), features.7:(32, 32), features.10:(51, 64), features.12:(89, 64), features.14:(115, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 179)\n",
      "2025-03-30 21:44:30,352 - MainProcess - ERROR - Error processing config: {'features.0': (2, 44), 'features.2': (19, 16), 'features.5': (19, 51), 'features.7': (32, 32), 'features.10': (51, 64), 'features.12': (89, 64), 'features.14': (115, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 179)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.70 GiB is allocated by PyTorch, and 564.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:44:30,352 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 16), 'features.5': (35, 38), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.70 GiB is allocated by PyTorch, and 570.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:44:30,359 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 19), 'features.5': (28, 32), 'features.7': (38, 32), 'features.10': (44, 64), 'features.12': (64, 89), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.70 GiB is allocated by PyTorch, and 570.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:44:30,365 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 16), 'features.5': (35, 38), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.61 GiB is allocated by PyTorch, and 657.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:44:30,395 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(25, 19), features.5:(25, 51), features.7:(38, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 21:44:30,395 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(25, 19), features.5:(16, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:44:30,457 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(19, 16), features.5:(16, 44), features.7:(38, 32), features.10:(32, 64), features.12:(89, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 204), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:44:30,459 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(25, 22), features.5:(16, 32), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:44:47,710 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(25, 19), features.5:(25, 51), features.7:(38, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 21:44:48,232 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(25, 19), features.5:(16, 32), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:44:49,149 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(19, 16), features.5:(16, 44), features.7:(38, 32), features.10:(32, 64), features.12:(89, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 204), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:44:49,786 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(25, 22), features.5:(16, 32), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:44:55,029 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (25, 22), 'features.5': (16, 32), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 136.19 MiB is free. Including non-PyTorch memory, this process has 41.55 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.39 GiB is allocated by PyTorch, and 777.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:44:55,040 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (25, 19), 'features.5': (16, 32), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 30.19 MiB is free. Including non-PyTorch memory, this process has 41.65 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.76 GiB is allocated by PyTorch, and 501.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:44:55,055 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 22), features.5:(35, 32), features.7:(38, 44), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:44:55,082 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 38), features.5:(38, 44), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:45:11,941 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 22), features.5:(35, 32), features.7:(38, 44), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:45:12,599 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 38), features.5:(38, 44), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:45:21,145 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (25, 19), 'features.5': (25, 51), 'features.7': (38, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 4.19 MiB is free. Including non-PyTorch memory, this process has 41.68 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.73 GiB is allocated by PyTorch, and 563.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:45:21,151 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 38), 'features.5': (38, 44), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (89, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 4.19 MiB is free. Including non-PyTorch memory, this process has 41.68 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.76 GiB is allocated by PyTorch, and 526.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:45:21,166 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 22), 'features.5': (35, 32), 'features.7': (38, 44), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 30.19 MiB is free. Including non-PyTorch memory, this process has 41.65 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.70 GiB is allocated by PyTorch, and 567.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:45:21,198 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 16), features.5:(16, 64), features.7:(38, 32), features.10:(32, 64), features.12:(89, 64), features.14:(64, 102), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:45:21,241 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 25), features.5:(28, 32), features.7:(57, 44), features.10:(32, 64), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 21:45:21,244 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 22), features.5:(38, 44), features.7:(51, 32), features.10:(32, 64), features.12:(76, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\n",
      "2025-03-30 21:45:38,649 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 22), features.5:(38, 44), features.7:(51, 32), features.10:(32, 64), features.12:(76, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\n",
      "2025-03-30 21:45:38,722 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 16), features.5:(16, 64), features.7:(38, 32), features.10:(32, 64), features.12:(89, 64), features.14:(64, 102), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:45:40,231 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 25), features.5:(28, 32), features.7:(57, 44), features.10:(32, 64), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 21:45:50,127 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 22), 'features.5': (38, 44), 'features.7': (51, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 282.19 MiB is free. Including non-PyTorch memory, this process has 41.41 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.68 GiB is allocated by PyTorch, and 329.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:45:50,133 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (19, 16), 'features.5': (16, 44), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (89, 64), 'features.14': (89, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 204), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 30.19 MiB is free. Including non-PyTorch memory, this process has 41.65 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.92 GiB is allocated by PyTorch, and 338.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:45:50,144 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 16), 'features.5': (16, 64), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (89, 64), 'features.14': (64, 102), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 30.19 MiB is free. Including non-PyTorch memory, this process has 41.65 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.92 GiB is allocated by PyTorch, and 335.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:45:50,149 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 25), 'features.5': (28, 32), 'features.7': (57, 44), 'features.10': (32, 64), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 30.19 MiB is free. Including non-PyTorch memory, this process has 41.65 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.92 GiB is allocated by PyTorch, and 335.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:45:50,170 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(25, 22), features.5:(22, 32), features.7:(32, 38), features.10:(38, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:45:50,225 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 16), features.5:(19, 38), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:45:50,276 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(19, 19), features.5:(16, 38), features.7:(32, 32), features.10:(32, 64), features.12:(76, 76), features.14:(76, 89), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:45:50,277 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 22), features.5:(25, 32), features.7:(51, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:46:07,035 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(25, 22), features.5:(22, 32), features.7:(32, 38), features.10:(38, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:46:07,929 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(19, 19), features.5:(16, 38), features.7:(32, 32), features.10:(32, 64), features.12:(76, 76), features.14:(76, 89), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:46:07,955 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 22), features.5:(25, 32), features.7:(51, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:46:09,341 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 16), features.5:(19, 38), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:46:29,517 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (19, 19), 'features.5': (16, 38), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (76, 76), 'features.14': (76, 89), 'features.17': (76, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 54.19 MiB is free. Including non-PyTorch memory, this process has 41.63 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.85 GiB is allocated by PyTorch, and 389.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:46:29,523 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 16), 'features.5': (19, 38), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 28.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.88 GiB is allocated by PyTorch, and 383.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:46:29,529 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 22), 'features.5': (25, 32), 'features.7': (51, 32), 'features.10': (38, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (179, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 28.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.89 GiB is allocated by PyTorch, and 371.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:46:29,536 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(16, 25), features.5:(16, 76), features.7:(32, 38), features.10:(44, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 153), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:46:29,601 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(16, 25), features.5:(28, 32), features.7:(44, 38), features.10:(38, 64), features.12:(76, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:46:29,601 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 41), features.5:(28, 32), features.7:(32, 32), features.10:(32, 76), features.12:(89, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 153), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 21:46:46,849 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(16, 25), features.5:(16, 76), features.7:(32, 38), features.10:(44, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 153), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:46:48,012 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 41), features.5:(28, 32), features.7:(32, 32), features.10:(32, 76), features.12:(89, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 153), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 21:46:48,015 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(16, 25), features.5:(28, 32), features.7:(44, 38), features.10:(38, 64), features.12:(76, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:47:00,454 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (16, 25), 'features.5': (28, 32), 'features.7': (44, 38), 'features.10': (38, 64), 'features.12': (76, 76), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 48.19 MiB is free. Including non-PyTorch memory, this process has 41.64 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.65 GiB is allocated by PyTorch, and 598.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:47:00,461 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (25, 22), 'features.5': (22, 32), 'features.7': (32, 38), 'features.10': (38, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 48.19 MiB is free. Including non-PyTorch memory, this process has 41.64 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.76 GiB is allocated by PyTorch, and 486.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:47:00,477 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 28), features.5:(19, 32), features.7:(32, 44), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(153, 179), features.28:(128, 128)\n",
      "2025-03-30 21:47:00,510 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 19), features.5:(16, 44), features.7:(38, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 179), features.19:(128, 153), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:18,201 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 28), features.5:(19, 32), features.7:(32, 44), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(153, 179), features.28:(128, 128)\n",
      "2025-03-30 21:47:18,604 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 19), features.5:(16, 44), features.7:(38, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 179), features.19:(128, 153), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:23,065 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 28), 'features.5': (19, 32), 'features.7': (32, 44), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 179), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.55 GiB is allocated by PyTorch, and 674.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:47:23,071 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (16, 25), 'features.5': (16, 76), 'features.7': (32, 38), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 20.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.63 GiB is allocated by PyTorch, and 649.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:47:23,076 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 41), 'features.5': (28, 32), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (89, 64), 'features.14': (89, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 153), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 80.19 MiB is free. Including non-PyTorch memory, this process has 41.61 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.60 GiB is allocated by PyTorch, and 617.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:47:23,120 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 19), features.5:(16, 44), features.7:(32, 44), features.10:(32, 64), features.12:(102, 76), features.14:(64, 76), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:23,169 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 16), features.5:(19, 44), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 89), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:23,171 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 16), features.5:(22, 44), features.7:(57, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(89, 128), features.19:(153, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:40,583 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 19), features.5:(16, 44), features.7:(32, 44), features.10:(32, 64), features.12:(102, 76), features.14:(64, 76), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:40,681 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 16), features.5:(19, 44), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 89), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:42,123 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 16), features.5:(22, 44), features.7:(57, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(89, 128), features.19:(153, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:59,692 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 19), 'features.5': (16, 44), 'features.7': (38, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 179), 'features.19': (128, 153), 'features.21': (128, 153), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 22.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.89 GiB is allocated by PyTorch, and 374.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:47:59,698 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 16), 'features.5': (19, 44), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 89), 'features.17': (76, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 20.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.91 GiB is allocated by PyTorch, and 363.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:47:59,704 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 19), 'features.5': (16, 44), 'features.7': (32, 44), 'features.10': (32, 64), 'features.12': (102, 76), 'features.14': (64, 76), 'features.17': (76, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 20.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.91 GiB is allocated by PyTorch, and 363.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:47:59,710 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 16), 'features.5': (22, 44), 'features.7': (57, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (89, 128), 'features.19': (153, 128), 'features.21': (128, 153), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 20.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.91 GiB is allocated by PyTorch, and 362.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:47:59,712 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 16), features.5:(16, 38), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:59,838 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 16), features.5:(19, 32), features.7:(70, 70), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:59,838 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(41, 19), features.5:(16, 38), features.7:(32, 44), features.10:(51, 64), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(179, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:47:59,843 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 22), features.5:(19, 44), features.7:(44, 32), features.10:(38, 64), features.12:(64, 89), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 21:48:16,653 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 16), features.5:(16, 38), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:48:17,513 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 22), features.5:(19, 44), features.7:(44, 32), features.10:(38, 64), features.12:(64, 89), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 21:48:17,877 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 16), features.5:(19, 32), features.7:(70, 70), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:48:17,877 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(41, 19), features.5:(16, 38), features.7:(32, 44), features.10:(51, 64), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(179, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:48:57,642 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (41, 19), 'features.5': (16, 38), 'features.7': (32, 44), 'features.10': (51, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (179, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 108.19 MiB is free. Including non-PyTorch memory, this process has 41.58 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 39.77 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:48:57,651 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 16), 'features.5': (16, 38), 'features.7': (32, 44), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 114.19 MiB is free. Including non-PyTorch memory, this process has 41.57 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.50 GiB is allocated by PyTorch, and 688.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:48:57,669 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 16), features.5:(16, 38), features.7:(38, 51), features.10:(38, 64), features.12:(89, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:48:57,714 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 19), features.5:(38, 51), features.7:(38, 44), features.10:(44, 64), features.12:(76, 76), features.14:(89, 102), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:49:14,251 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 16), features.5:(16, 38), features.7:(38, 51), features.10:(38, 64), features.12:(89, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:49:15,722 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 19), features.5:(38, 51), features.7:(38, 44), features.10:(44, 64), features.12:(76, 76), features.14:(89, 102), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:51:16,919 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 16), 'features.5': (16, 38), 'features.7': (38, 51), 'features.10': (38, 64), 'features.12': (89, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 164.19 MiB is free. Including non-PyTorch memory, this process has 41.52 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.12 GiB is allocated by PyTorch, and 1023.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:51:17,046 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(16, 35), features.5:(16, 32), features.7:(44, 38), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:51:31,475 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(16, 35), features.5:(16, 32), features.7:(44, 38), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:53:06,086 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 22), 'features.5': (19, 44), 'features.7': (44, 32), 'features.10': (38, 64), 'features.12': (64, 89), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.79 GiB is allocated by PyTorch, and 478.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:53:06,094 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (16, 35), 'features.5': (16, 32), 'features.7': (44, 38), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.74 GiB is allocated by PyTorch, and 528.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:53:06,100 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 19), 'features.5': (38, 51), 'features.7': (38, 44), 'features.10': (44, 64), 'features.12': (76, 76), 'features.14': (89, 102), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (179, 153), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 28.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.81 GiB is allocated by PyTorch, and 455.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:53:06,121 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(28, 28), features.5:(38, 32), features.7:(32, 38), features.10:(32, 76), features.12:(64, 64), features.14:(89, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:53:06,124 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 16), features.5:(19, 32), features.7:(32, 44), features.10:(70, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 256), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 21:53:06,151 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 19), features.5:(16, 32), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:53:23,426 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(28, 28), features.5:(38, 32), features.7:(32, 38), features.10:(32, 76), features.12:(64, 64), features.14:(89, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:53:23,427 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 16), features.5:(19, 32), features.7:(32, 44), features.10:(70, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 256), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 21:53:25,053 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 19), features.5:(16, 32), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 153), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:53:26,197 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 16), 'features.5': (19, 32), 'features.7': (32, 44), 'features.10': (70, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 256), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 218.19 MiB is free. Including non-PyTorch memory, this process has 41.47 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.62 GiB is allocated by PyTorch, and 455.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:53:26,202 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 16), 'features.5': (19, 32), 'features.7': (70, 70), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.75 GiB is allocated by PyTorch, and 469.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:53:26,211 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (28, 28), 'features.5': (38, 32), 'features.7': (32, 38), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (89, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 98.19 MiB is free. Including non-PyTorch memory, this process has 41.59 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.76 GiB is allocated by PyTorch, and 438.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:53:26,263 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(28, 16), features.5:(16, 44), features.7:(38, 44), features.10:(32, 76), features.12:(76, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:53:26,271 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(38, 16), features.5:(28, 83), features.7:(32, 32), features.10:(38, 76), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:53:26,273 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(19, 16), features.5:(22, 57), features.7:(32, 32), features.10:(44, 76), features.12:(64, 64), features.14:(115, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:53:43,853 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(38, 16), features.5:(28, 83), features.7:(32, 32), features.10:(38, 76), features.12:(76, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:53:43,854 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(19, 16), features.5:(22, 57), features.7:(32, 32), features.10:(44, 76), features.12:(64, 64), features.14:(115, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:53:45,390 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(28, 16), features.5:(16, 44), features.7:(38, 44), features.10:(32, 76), features.12:(76, 64), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:54:37,065 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (28, 16), 'features.5': (16, 44), 'features.7': (38, 44), 'features.10': (32, 76), 'features.12': (76, 64), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 38.19 MiB is free. Including non-PyTorch memory, this process has 41.65 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.69 GiB is allocated by PyTorch, and 568.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:54:37,072 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (38, 16), 'features.5': (28, 83), 'features.7': (32, 32), 'features.10': (38, 76), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 38.19 MiB is free. Including non-PyTorch memory, this process has 41.65 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.59 GiB is allocated by PyTorch, and 666.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:54:37,119 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(16, 16), features.5:(16, 38), features.7:(38, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(89, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:54:37,121 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(19, 32), features.5:(16, 51), features.7:(44, 32), features.10:(51, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 153), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 21:54:54,878 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(16, 16), features.5:(16, 38), features.7:(38, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(89, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:54:55,015 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(19, 32), features.5:(16, 51), features.7:(44, 32), features.10:(51, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 153), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 21:54:59,017 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (19, 32), 'features.5': (16, 51), 'features.7': (44, 32), 'features.10': (51, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (153, 153), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 98.19 MiB is free. Including non-PyTorch memory, this process has 41.59 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.67 GiB is allocated by PyTorch, and 523.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:54:59,023 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (16, 16), 'features.5': (16, 38), 'features.7': (38, 32), 'features.10': (57, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (89, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 98.19 MiB is free. Including non-PyTorch memory, this process has 41.59 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.69 GiB is allocated by PyTorch, and 508.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:54:59,044 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(44, 19), features.5:(35, 32), features.7:(32, 32), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:54:59,077 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 19), features.5:(25, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(204, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:55:15,640 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 19), features.5:(25, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(204, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:55:16,802 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(44, 19), features.5:(35, 32), features.7:(32, 32), features.10:(44, 64), features.12:(64, 76), features.14:(64, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 153), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:55:21,654 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (19, 16), 'features.5': (22, 57), 'features.7': (32, 32), 'features.10': (44, 76), 'features.12': (64, 64), 'features.14': (115, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 52.19 MiB is free. Including non-PyTorch memory, this process has 41.63 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.75 GiB is allocated by PyTorch, and 493.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:55:21,661 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 19), 'features.5': (25, 38), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (204, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 52.19 MiB is free. Including non-PyTorch memory, this process has 41.63 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.75 GiB is allocated by PyTorch, and 493.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:55:21,667 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (44, 19), 'features.5': (35, 32), 'features.7': (32, 32), 'features.10': (44, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (153, 128), 'features.21': (128, 153), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 78.19 MiB is free. Including non-PyTorch memory, this process has 41.61 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.65 GiB is allocated by PyTorch, and 572.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:55:21,675 - MainProcess - INFO - Compressing to:features.0:(1, 32), features.2:(19, 16), features.5:(22, 32), features.7:(38, 32), features.10:(51, 64), features.12:(64, 76), features.14:(64, 64), features.17:(115, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:55:21,740 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 22), features.5:(16, 44), features.7:(44, 44), features.10:(32, 64), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:55:21,743 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(41, 25), features.5:(41, 32), features.7:(44, 64), features.10:(44, 102), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:55:39,615 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 22), features.5:(16, 44), features.7:(44, 44), features.10:(32, 64), features.12:(76, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 179), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:55:40,338 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(41, 25), features.5:(41, 32), features.7:(44, 64), features.10:(44, 102), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:55:41,302 - MainProcess - INFO - finetuning:features.0:(1, 32), features.2:(19, 16), features.5:(22, 32), features.7:(38, 32), features.10:(51, 64), features.12:(64, 76), features.14:(64, 64), features.17:(115, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:56:08,169 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (41, 25), 'features.5': (41, 32), 'features.7': (44, 64), 'features.10': (44, 102), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 60.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.82 GiB is allocated by PyTorch, and 409.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:56:08,175 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (19, 19), 'features.5': (16, 32), 'features.7': (32, 38), 'features.10': (51, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 153), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 60.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.85 GiB is allocated by PyTorch, and 385.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:56:08,186 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 16), features.5:(16, 44), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:56:08,209 - MainProcess - INFO - Compressing to:features.0:(1, 54), features.2:(22, 19), features.5:(16, 32), features.7:(38, 32), features.10:(51, 89), features.12:(64, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=54, which is larger than max(matrix.shape)=9. Setting n_eigenvecs to 9.\n",
      "  warnings.warn(\n",
      "2025-03-30 21:56:25,102 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 16), features.5:(16, 44), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:56:25,415 - MainProcess - INFO - finetuning:features.0:(1, 54), features.2:(22, 19), features.5:(16, 32), features.7:(38, 32), features.10:(51, 89), features.12:(64, 64), features.14:(64, 64), features.17:(89, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:56:59,037 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 22), 'features.5': (16, 44), 'features.7': (44, 44), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 179), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 44.19 MiB is free. Including non-PyTorch memory, this process has 41.64 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.62 GiB is allocated by PyTorch, and 632.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:56:59,050 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(22, 28), features.5:(19, 44), features.7:(57, 38), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 21:57:15,795 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(22, 28), features.5:(19, 44), features.7:(57, 38), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 21:57:24,431 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (22, 28), 'features.5': (19, 44), 'features.7': (57, 38), 'features.10': (57, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 46.19 MiB is free. Including non-PyTorch memory, this process has 41.64 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.89 GiB is allocated by PyTorch, and 349.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:57:24,436 - MainProcess - ERROR - Error processing config: {'features.0': (1, 32), 'features.2': (19, 16), 'features.5': (22, 32), 'features.7': (38, 32), 'features.10': (51, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (115, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 46.19 MiB is free. Including non-PyTorch memory, this process has 41.64 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.92 GiB is allocated by PyTorch, and 320.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:57:24,463 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(35, 25), features.5:(22, 32), features.7:(44, 44), features.10:(38, 64), features.12:(64, 64), features.14:(64, 102), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:57:24,518 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 19), features.5:(28, 32), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:57:41,680 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(35, 25), features.5:(22, 32), features.7:(44, 44), features.10:(38, 64), features.12:(64, 64), features.14:(64, 102), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:57:42,867 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 19), features.5:(28, 32), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:58:29,145 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 16), 'features.5': (16, 44), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.78 GiB is allocated by PyTorch, and 452.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:58:29,151 - MainProcess - ERROR - Error processing config: {'features.0': (1, 54), 'features.2': (22, 19), 'features.5': (16, 32), 'features.7': (38, 32), 'features.10': (51, 89), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.80 GiB is allocated by PyTorch, and 432.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:58:29,164 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(16, 19), features.5:(22, 32), features.7:(38, 102), features.10:(32, 76), features.12:(64, 76), features.14:(64, 89), features.17:(89, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:58:29,199 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 16), features.5:(19, 38), features.7:(51, 32), features.10:(32, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 21:58:47,376 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(16, 19), features.5:(22, 32), features.7:(38, 102), features.10:(32, 76), features.12:(64, 76), features.14:(64, 89), features.17:(89, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:58:47,516 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 16), features.5:(19, 38), features.7:(51, 32), features.10:(32, 76), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 21:59:20,347 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 19), 'features.5': (28, 32), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 50.19 MiB is free. Including non-PyTorch memory, this process has 41.63 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.99 GiB is allocated by PyTorch, and 249.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:59:20,353 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (35, 25), 'features.5': (22, 32), 'features.7': (44, 44), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 102), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 41.03 GiB is allocated by PyTorch, and 236.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:59:20,359 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 16), 'features.5': (19, 38), 'features.7': (51, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 24.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 41.03 GiB is allocated by PyTorch, and 235.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:59:20,364 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (16, 19), 'features.5': (22, 32), 'features.7': (38, 102), 'features.10': (32, 76), 'features.12': (64, 76), 'features.14': (64, 89), 'features.17': (89, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 26.19 MiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 41.02 GiB is allocated by PyTorch, and 241.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:59:20,369 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 22), features.5:(35, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(89, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:59:20,488 - MainProcess - INFO - Compressing to:features.0:(1, 32), features.2:(22, 22), features.5:(32, 38), features.7:(38, 32), features.10:(38, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:59:20,489 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 35), features.5:(22, 32), features.7:(38, 32), features.10:(38, 64), features.12:(89, 64), features.14:(64, 76), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(153, 128), features.28:(153, 153)\n",
      "2025-03-30 21:59:20,493 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(22, 22), features.5:(19, 38), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:59:38,610 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 22), features.5:(35, 38), features.7:(32, 32), features.10:(32, 64), features.12:(64, 76), features.14:(89, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 21:59:39,058 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(22, 22), features.5:(19, 38), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:59:39,059 - MainProcess - INFO - finetuning:features.0:(1, 32), features.2:(22, 22), features.5:(32, 38), features.7:(38, 32), features.10:(38, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 21:59:40,903 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 35), features.5:(22, 32), features.7:(38, 32), features.10:(38, 64), features.12:(89, 64), features.14:(64, 76), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(153, 128), features.28:(153, 153)\n",
      "2025-03-30 21:59:45,450 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 22), 'features.5': (35, 38), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (89, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 8.19 MiB is free. Including non-PyTorch memory, this process has 41.68 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.81 GiB is allocated by PyTorch, and 479.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:59:45,461 - MainProcess - ERROR - Error processing config: {'features.0': (1, 32), 'features.2': (22, 22), 'features.5': (32, 38), 'features.7': (38, 32), 'features.10': (38, 64), 'features.12': (64, 76), 'features.14': (64, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 36.19 MiB is free. Including non-PyTorch memory, this process has 41.65 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.75 GiB is allocated by PyTorch, and 505.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 21:59:45,467 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 25), features.5:(19, 70), features.7:(32, 32), features.10:(44, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 204), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 21:59:45,490 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 19), features.5:(19, 38), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 22:00:03,394 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 25), features.5:(19, 70), features.7:(32, 32), features.10:(44, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 204), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:00:04,741 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 19), features.5:(19, 38), features.7:(32, 51), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 22:00:08,765 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (19, 35), 'features.5': (22, 32), 'features.7': (38, 32), 'features.10': (38, 64), 'features.12': (89, 64), 'features.14': (64, 76), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (153, 128), 'features.28': (153, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 18.19 MiB is free. Including non-PyTorch memory, this process has 41.67 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.78 GiB is allocated by PyTorch, and 495.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:00:08,794 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 22), features.5:(19, 38), features.7:(32, 38), features.10:(51, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 22:00:27,414 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 22), features.5:(19, 38), features.7:(32, 38), features.10:(51, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 22:01:06,442 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 25), 'features.5': (19, 70), 'features.7': (32, 32), 'features.10': (44, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 204), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 3.25 MiB is free. Including non-PyTorch memory, this process has 40.15 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Process 1450665 has 1.53 GiB memory in use. Of the allocated memory 39.31 GiB is allocated by PyTorch, and 443.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:01:06,447 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 22), 'features.5': (19, 38), 'features.7': (32, 38), 'features.10': (51, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 3.25 MiB is free. Including non-PyTorch memory, this process has 40.15 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Process 1450665 has 1.53 GiB memory in use. Of the allocated memory 39.33 GiB is allocated by PyTorch, and 427.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:01:06,455 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (22, 22), 'features.5': (19, 38), 'features.7': (32, 32), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 29.25 MiB is free. Including non-PyTorch memory, this process has 40.12 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Process 1450665 has 1.53 GiB memory in use. Of the allocated memory 39.21 GiB is allocated by PyTorch, and 523.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:01:06,481 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(16, 19), features.5:(28, 38), features.7:(32, 44), features.10:(38, 89), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:01:06,533 - MainProcess - INFO - Compressing to:features.0:(2, 35), features.2:(19, 16), features.5:(35, 38), features.7:(32, 32), features.10:(44, 64), features.12:(102, 64), features.14:(102, 64), features.17:(89, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 153), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 22:01:06,536 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 22), features.5:(19, 38), features.7:(38, 51), features.10:(38, 64), features.12:(64, 102), features.14:(102, 76), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 179), features.28:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=35, which is larger than max(matrix.shape)=18. Setting n_eigenvecs to 18.\n",
      "  warnings.warn(\n",
      "2025-03-30 22:01:26,884 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(16, 19), features.5:(28, 38), features.7:(32, 44), features.10:(38, 89), features.12:(64, 64), features.14:(76, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:01:28,394 - MainProcess - INFO - finetuning:features.0:(2, 35), features.2:(19, 16), features.5:(35, 38), features.7:(32, 32), features.10:(44, 64), features.12:(102, 64), features.14:(102, 64), features.17:(89, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 153), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 22:01:28,440 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 22), features.5:(19, 38), features.7:(38, 51), features.10:(38, 64), features.12:(64, 102), features.14:(102, 76), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 179), features.28:(128, 128)\n",
      "2025-03-30 22:01:32,701 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (16, 19), 'features.5': (28, 38), 'features.7': (32, 44), 'features.10': (38, 89), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 45.25 MiB is free. Including non-PyTorch memory, this process has 40.88 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Process 1465349 has 778.00 MiB memory in use. Of the allocated memory 40.07 GiB is allocated by PyTorch, and 417.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:01:32,707 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (19, 22), 'features.5': (19, 38), 'features.7': (38, 51), 'features.10': (38, 64), 'features.12': (64, 102), 'features.14': (102, 76), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 179), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 45.25 MiB is free. Including non-PyTorch memory, this process has 40.88 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Process 1465349 has 778.00 MiB memory in use. Of the allocated memory 40.07 GiB is allocated by PyTorch, and 417.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:01:32,714 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 19), 'features.5': (19, 38), 'features.7': (32, 51), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 45.25 MiB is free. Including non-PyTorch memory, this process has 40.88 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Process 1465349 has 778.00 MiB memory in use. Of the allocated memory 40.06 GiB is allocated by PyTorch, and 425.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:01:32,726 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(48, 19), features.5:(25, 32), features.7:(38, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 76), features.17:(76, 153), features.19:(153, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:01:32,803 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 16), features.5:(22, 38), features.7:(64, 32), features.10:(32, 64), features.12:(76, 64), features.14:(76, 76), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:01:32,804 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(28, 22), features.5:(57, 32), features.7:(32, 32), features.10:(38, 76), features.12:(64, 64), features.14:(102, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 22:01:52,657 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(28, 22), features.5:(57, 32), features.7:(32, 32), features.10:(38, 76), features.12:(64, 64), features.14:(102, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 22:01:52,657 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(48, 19), features.5:(25, 32), features.7:(38, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 76), features.17:(76, 153), features.19:(153, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:01:52,770 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 16), features.5:(22, 38), features.7:(64, 32), features.10:(32, 64), features.12:(76, 64), features.14:(76, 76), features.17:(76, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:01:53,022 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 16), 'features.5': (22, 38), 'features.7': (64, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (76, 76), 'features.17': (76, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 41.67 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.91 GiB is allocated by PyTorch, and 360.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:01:53,030 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (28, 22), 'features.5': (57, 32), 'features.7': (32, 32), 'features.10': (38, 76), 'features.12': (64, 64), 'features.14': (102, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.83 GiB is allocated by PyTorch, and 394.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:01:53,059 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(25, 16), features.5:(25, 51), features.7:(32, 38), features.10:(32, 64), features.12:(64, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:01:53,092 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 19), features.5:(28, 44), features.7:(44, 32), features.10:(44, 64), features.12:(89, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:02:11,116 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(25, 16), features.5:(25, 51), features.7:(32, 38), features.10:(32, 64), features.12:(64, 89), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:02:12,609 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 19), features.5:(28, 44), features.7:(44, 32), features.10:(44, 64), features.12:(89, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:02:48,274 - MainProcess - ERROR - Error processing config: {'features.0': (2, 35), 'features.2': (19, 16), 'features.5': (35, 38), 'features.7': (32, 32), 'features.10': (44, 64), 'features.12': (102, 64), 'features.14': (102, 64), 'features.17': (89, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 153), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 46.19 MiB is free. Including non-PyTorch memory, this process has 41.64 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.71 GiB is allocated by PyTorch, and 542.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:02:48,280 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (25, 16), 'features.5': (25, 51), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 46.19 MiB is free. Including non-PyTorch memory, this process has 41.64 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.73 GiB is allocated by PyTorch, and 518.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:02:48,302 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(41, 25), features.5:(19, 32), features.7:(32, 32), features.10:(38, 76), features.12:(76, 64), features.14:(89, 76), features.17:(115, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:02:48,304 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(16, 16), features.5:(22, 32), features.7:(38, 44), features.10:(44, 64), features.12:(64, 102), features.14:(64, 64), features.17:(64, 179), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 22:03:07,109 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(41, 25), features.5:(19, 32), features.7:(32, 32), features.10:(38, 76), features.12:(76, 64), features.14:(89, 76), features.17:(115, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:03:08,065 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(16, 16), features.5:(22, 32), features.7:(38, 44), features.10:(44, 64), features.12:(64, 102), features.14:(64, 64), features.17:(64, 179), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 22:03:19,561 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (48, 19), 'features.5': (25, 32), 'features.7': (38, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (76, 153), 'features.19': (153, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 120.19 MiB is free. Including non-PyTorch memory, this process has 41.57 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.59 GiB is allocated by PyTorch, and 584.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:03:19,585 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 32), features.5:(22, 51), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 22:03:35,687 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 32), features.5:(22, 51), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(76, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 153), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 22:03:57,186 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 19), 'features.5': (28, 44), 'features.7': (44, 32), 'features.10': (44, 64), 'features.12': (89, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 41.67 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.88 GiB is allocated by PyTorch, and 398.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:03:57,193 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 32), 'features.5': (22, 51), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (153, 153), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 41.67 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.88 GiB is allocated by PyTorch, and 398.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:03:57,197 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (41, 25), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (38, 76), 'features.12': (76, 64), 'features.14': (89, 76), 'features.17': (115, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 41.67 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.87 GiB is allocated by PyTorch, and 404.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:03:57,201 - MainProcess - ERROR - Error processing config: {'features.0': (2, 32), 'features.2': (16, 16), 'features.5': (22, 32), 'features.7': (38, 44), 'features.10': (44, 64), 'features.12': (64, 102), 'features.14': (64, 64), 'features.17': (64, 179), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 41.67 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.86 GiB is allocated by PyTorch, and 410.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:03:57,209 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(22, 19), features.5:(16, 38), features.7:(32, 44), features.10:(57, 64), features.12:(89, 102), features.14:(76, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 22:03:57,284 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 22), features.5:(44, 70), features.7:(38, 38), features.10:(32, 64), features.12:(89, 64), features.14:(64, 89), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:03:57,286 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 16), features.5:(35, 51), features.7:(32, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:03:57,287 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 38), features.5:(16, 38), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:04:17,196 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(22, 19), features.5:(16, 38), features.7:(32, 44), features.10:(57, 64), features.12:(89, 102), features.14:(76, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 22:04:17,431 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 16), features.5:(35, 51), features.7:(32, 32), features.10:(57, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:04:18,378 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 22), features.5:(44, 70), features.7:(38, 38), features.10:(32, 64), features.12:(89, 64), features.14:(64, 89), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:04:19,053 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 38), features.5:(16, 38), features.7:(32, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:04:23,267 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (22, 19), 'features.5': (16, 38), 'features.7': (32, 44), 'features.10': (57, 64), 'features.12': (89, 102), 'features.14': (76, 76), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 40.19 MiB is free. Including non-PyTorch memory, this process has 41.64 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.97 GiB is allocated by PyTorch, and 277.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:04:23,267 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (19, 16), 'features.5': (35, 51), 'features.7': (32, 32), 'features.10': (57, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 40.19 MiB is free. Including non-PyTorch memory, this process has 41.64 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.98 GiB is allocated by PyTorch, and 266.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:04:23,273 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 38), 'features.5': (16, 38), 'features.7': (32, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 41.67 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 41.03 GiB is allocated by PyTorch, and 241.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:04:23,315 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(16, 19), features.5:(16, 32), features.7:(38, 38), features.10:(32, 64), features.12:(76, 89), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 22:04:23,317 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(28, 16), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 76), features.14:(64, 89), features.17:(115, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 22:04:23,363 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(28, 25), features.5:(35, 32), features.7:(51, 51), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(102, 153), features.19:(128, 179), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:04:43,144 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(28, 25), features.5:(35, 32), features.7:(51, 51), features.10:(32, 64), features.12:(64, 76), features.14:(64, 64), features.17:(102, 153), features.19:(128, 179), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:04:43,853 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(28, 16), features.5:(22, 32), features.7:(32, 32), features.10:(32, 64), features.12:(76, 76), features.14:(64, 89), features.17:(115, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-30 22:04:43,997 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(16, 19), features.5:(16, 32), features.7:(38, 38), features.10:(32, 64), features.12:(76, 89), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-30 22:04:47,568 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (28, 25), 'features.5': (35, 32), 'features.7': (51, 51), 'features.10': (32, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (102, 153), 'features.19': (128, 179), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.77 GiB is allocated by PyTorch, and 461.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:04:47,568 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (19, 22), 'features.5': (44, 70), 'features.7': (38, 38), 'features.10': (32, 64), 'features.12': (89, 64), 'features.14': (64, 89), 'features.17': (76, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 64.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.79 GiB is allocated by PyTorch, and 437.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:04:47,573 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (16, 19), 'features.5': (16, 32), 'features.7': (38, 38), 'features.10': (32, 64), 'features.12': (76, 89), 'features.14': (76, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 68.19 MiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.80 GiB is allocated by PyTorch, and 424.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:04:47,612 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(22, 25), features.5:(16, 38), features.7:(32, 32), features.10:(32, 76), features.12:(76, 76), features.14:(89, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:04:47,615 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(38, 19), features.5:(25, 51), features.7:(32, 32), features.10:(44, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:04:47,666 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 16), features.5:(22, 32), features.7:(57, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 179), features.28:(128, 128)\n",
      "2025-03-30 22:05:06,520 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(38, 19), features.5:(25, 51), features.7:(32, 32), features.10:(44, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:05:06,912 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(22, 25), features.5:(16, 38), features.7:(32, 32), features.10:(32, 76), features.12:(76, 76), features.14:(89, 64), features.17:(76, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-30 22:05:08,534 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 16), features.5:(22, 32), features.7:(57, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 179), features.28:(128, 128)\n",
      "2025-03-30 22:05:27,876 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (28, 16), 'features.5': (22, 32), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (76, 76), 'features.14': (64, 89), 'features.17': (115, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 41.67 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.77 GiB is allocated by PyTorch, and 503.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:05:27,881 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (22, 25), 'features.5': (16, 38), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (76, 76), 'features.14': (89, 64), 'features.17': (76, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 41.67 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.79 GiB is allocated by PyTorch, and 489.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:05:27,898 - MainProcess - INFO - Compressing to:features.0:(1, 32), features.2:(22, 44), features.5:(16, 38), features.7:(44, 38), features.10:(38, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:05:27,930 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(25, 22), features.5:(25, 38), features.7:(32, 44), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 22:05:46,493 - MainProcess - INFO - finetuning:features.0:(1, 32), features.2:(22, 44), features.5:(16, 38), features.7:(44, 38), features.10:(38, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:05:47,728 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(25, 22), features.5:(25, 38), features.7:(32, 44), features.10:(44, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-30 22:05:48,068 - MainProcess - ERROR - Error processing config: {'features.0': (1, 32), 'features.2': (22, 44), 'features.5': (16, 38), 'features.7': (44, 38), 'features.10': (38, 76), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 194.19 MiB is free. Including non-PyTorch memory, this process has 41.49 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.60 GiB is allocated by PyTorch, and 503.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:05:48,076 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (25, 22), 'features.5': (25, 38), 'features.7': (32, 44), 'features.10': (44, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (153, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 96.19 MiB is free. Including non-PyTorch memory, this process has 41.59 GiB memory in use. Process 3634912 has 2.89 GiB memory in use. Process 3734524 has 1.76 GiB memory in use. Process 3734566 has 1.18 GiB memory in use. Of the allocated memory 40.71 GiB is allocated by PyTorch, and 489.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 22:05:48,138 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 28), features.5:(32, 32), features.7:(32, 44), features.10:(51, 76), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:05:48,140 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(19, 16), features.5:(35, 32), features.7:(32, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:06:06,724 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 28), features.5:(32, 32), features.7:(32, 44), features.10:(51, 76), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:06:07,400 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(19, 16), features.5:(35, 32), features.7:(32, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1451\n",
      "Epoch 1/3, Loss: 0.1893\n",
      "Epoch 1/3, Loss: 0.0647\n",
      "Epoch 2/3, Loss: 0.0334\n",
      "Epoch 1/3, Loss: 0.1395\n",
      "Epoch 2/3, Loss: 0.0328\n",
      "Epoch 3/3, Loss: 0.0271\n",
      "Epoch 2/3, Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 22:26:13,050 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 22), features.2:(38, 19), features.5:(25, 51), features.7:(32, 32), features.10:(44, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 128), features.26:(128, 128), features.28:(153, 128)\",\n",
      "    \"params\": 121483699,\n",
      "    \"flops\": 5007480586,\n",
      "    \"accuracy\": 0.9923,\n",
      "    \"inference_time\": 0.2903299620197078,\n",
      "    \"compression_rate\": 1.1055105755382044,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 22:26:13,328 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(25, 16), features.5:(35, 44), features.7:(32, 51), features.10:(38, 64), features.12:(64, 76), features.14:(64, 76), features.17:(64, 153), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:26:13,328 - MainProcess - INFO - Evaluated 80 configurations, found 80 accepted models\n",
      "2025-03-30 22:26:29,323 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(25, 16), features.5:(35, 44), features.7:(32, 51), features.10:(38, 64), features.12:(64, 76), features.14:(64, 76), features.17:(64, 153), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0330\n",
      "Epoch 3/3, Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 22:31:55,162 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(19, 16), features.5:(22, 32), features.7:(57, 32), features.10:(32, 64), features.12:(64, 76), features.14:(64, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 179), features.28:(128, 128)\",\n",
      "    \"params\": 121498366,\n",
      "    \"flops\": 2293478410,\n",
      "    \"accuracy\": 0.9918,\n",
      "    \"inference_time\": 0.2954936513475552,\n",
      "    \"compression_rate\": 1.1053771208742018,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 22:31:55,316 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 32), features.5:(19, 32), features.7:(38, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 115), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:32:11,920 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 32), features.5:(19, 32), features.7:(38, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 115), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0670\n",
      "Epoch 3/3, Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 22:36:27,664 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 25), features.2:(19, 16), features.5:(35, 32), features.7:(32, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121351193,\n",
      "    \"flops\": 4682954762,\n",
      "    \"accuracy\": 0.9931,\n",
      "    \"inference_time\": 0.29791807774019347,\n",
      "    \"compression_rate\": 1.1067177065164906,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 22:36:27,809 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(16, 44), features.5:(19, 32), features.7:(51, 44), features.10:(38, 89), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 22:36:43,397 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(16, 44), features.5:(19, 32), features.7:(51, 44), features.10:(38, 89), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 22:39:58,750 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(19, 28), features.5:(32, 32), features.7:(32, 44), features.10:(51, 76), features.12:(64, 76), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121385510,\n",
      "    \"flops\": 4954168586,\n",
      "    \"accuracy\": 0.9934,\n",
      "    \"inference_time\": 0.3078965351080439,\n",
      "    \"compression_rate\": 1.1064048254194425,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 22:39:58,881 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 35), features.5:(25, 38), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(102, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 22:40:15,641 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 35), features.5:(25, 38), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(102, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1607\n",
      "Epoch 3/3, Loss: 0.0207\n",
      "Epoch 1/3, Loss: 0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 22:47:18,376 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(25, 16), features.5:(35, 44), features.7:(32, 51), features.10:(38, 64), features.12:(64, 76), features.14:(64, 76), features.17:(64, 153), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121478877,\n",
      "    \"flops\": 5014618122,\n",
      "    \"accuracy\": 0.9923,\n",
      "    \"inference_time\": 0.30924441758740984,\n",
      "    \"compression_rate\": 1.1055544578338503,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 22:47:18,549 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 35), features.5:(28, 32), features.7:(51, 38), features.10:(32, 64), features.12:(64, 76), features.14:(89, 76), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 22:47:35,079 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 35), features.5:(28, 32), features.7:(51, 38), features.10:(32, 64), features.12:(64, 76), features.14:(89, 76), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0341\n",
      "Epoch 1/3, Loss: 0.1769\n",
      "Epoch 1/3, Loss: 0.0595\n",
      "Epoch 2/3, Loss: 0.0267\n",
      "Epoch 3/3, Loss: 0.0256\n",
      "Epoch 2/3, Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 22:59:58,218 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(19, 32), features.5:(19, 32), features.7:(38, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 115), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121434734,\n",
      "    \"flops\": 3719603210,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.3112883355207504,\n",
      "    \"compression_rate\": 1.1059563403004613,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 22:59:58,383 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(28, 16), features.5:(16, 38), features.7:(38, 51), features.10:(44, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 23:00:14,623 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(28, 16), features.5:(16, 38), features.7:(38, 51), features.10:(44, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0330\n",
      "Epoch 3/3, Loss: 0.0209\n",
      "Epoch 3/3, Loss: 0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:07:38,216 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 25), features.2:(16, 44), features.5:(19, 32), features.7:(51, 44), features.10:(38, 89), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121418035,\n",
      "    \"flops\": 5092886410,\n",
      "    \"accuracy\": 0.9931,\n",
      "    \"inference_time\": 0.23265451382679547,\n",
      "    \"compression_rate\": 1.1061084459157982,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 23:07:38,400 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 41), features.5:(22, 32), features.7:(44, 57), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 23:07:55,119 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 41), features.5:(22, 32), features.7:(44, 57), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 23:08:09,195 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(16, 35), features.5:(28, 32), features.7:(51, 38), features.10:(32, 64), features.12:(64, 76), features.14:(89, 76), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121453095,\n",
      "    \"flops\": 5094360330,\n",
      "    \"accuracy\": 0.9932,\n",
      "    \"inference_time\": 0.2366564866084202,\n",
      "    \"compression_rate\": 1.1057891443606274,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 23:08:09,318 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 51), features.5:(16, 44), features.7:(32, 57), features.10:(32, 76), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:08:25,633 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 51), features.5:(16, 44), features.7:(32, 57), features.10:(32, 76), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0261\n",
      "Epoch 1/3, Loss: 0.0670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:15:17,866 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(16, 35), features.5:(25, 38), features.7:(32, 38), features.10:(51, 64), features.12:(64, 64), features.14:(102, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121462604,\n",
      "    \"flops\": 5015997962,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.3115305520926312,\n",
      "    \"compression_rate\": 1.1057025749258595,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 23:15:18,022 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 16), features.5:(19, 32), features.7:(51, 32), features.10:(32, 64), features.12:(64, 89), features.14:(89, 64), features.17:(76, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 23:15:34,277 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 16), features.5:(19, 32), features.7:(51, 32), features.10:(32, 64), features.12:(64, 89), features.14:(89, 64), features.17:(76, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0329\n",
      "Epoch 1/3, Loss: 0.0653\n",
      "Epoch 2/3, Loss: 0.0263\n",
      "Epoch 3/3, Loss: 0.0258\n",
      "Epoch 3/3, Loss: 0.0220\n",
      "Epoch 2/3, Loss: 0.0267\n",
      "Epoch 1/3, Loss: 0.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:28:56,239 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(28, 16), features.5:(16, 38), features.7:(38, 51), features.10:(44, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121445936,\n",
      "    \"flops\": 3857612298,\n",
      "    \"accuracy\": 0.9928,\n",
      "    \"inference_time\": 0.23504741531015708,\n",
      "    \"compression_rate\": 1.1058543284643136,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 23:28:56,455 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 16), features.5:(16, 51), features.7:(32, 32), features.10:(32, 89), features.12:(128, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 23:29:14,587 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 16), features.5:(16, 51), features.7:(32, 32), features.10:(32, 89), features.12:(128, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 23:29:27,798 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(22, 51), features.5:(16, 44), features.7:(32, 57), features.10:(32, 76), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121472679,\n",
      "    \"flops\": 4089992458,\n",
      "    \"accuracy\": 0.9927,\n",
      "    \"inference_time\": 0.23744577359242047,\n",
      "    \"compression_rate\": 1.1056108674445222,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 23:29:27,867 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(28, 19), features.5:(16, 38), features.7:(44, 38), features.10:(44, 76), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-30 23:29:27,867 - MainProcess - INFO - Evaluated 90 configurations, found 90 accepted models\n",
      "2025-03-30 23:29:46,386 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(28, 19), features.5:(16, 38), features.7:(44, 38), features.10:(44, 76), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0649\n",
      "Epoch 3/3, Loss: 0.0210\n",
      "Epoch 2/3, Loss: 0.0256\n",
      "Epoch 1/3, Loss: 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:38:51,077 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(16, 41), features.5:(22, 32), features.7:(44, 57), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121383429,\n",
      "    \"flops\": 5071668234,\n",
      "    \"accuracy\": 0.993,\n",
      "    \"inference_time\": 0.3124622508978388,\n",
      "    \"compression_rate\": 1.1064237936464951,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 23:38:51,247 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 28), features.5:(25, 57), features.7:(38, 44), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 204), features.28:(128, 128)\n",
      "2025-03-30 23:39:06,430 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 28), features.5:(25, 57), features.7:(38, 44), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 204), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0272\n",
      "Epoch 3/3, Loss: 0.0224\n",
      "Epoch 2/3, Loss: 0.0273\n",
      "Epoch 3/3, Loss: 0.0211\n",
      "Epoch 1/3, Loss: 0.1623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:48:42,583 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(28, 19), features.5:(16, 38), features.7:(44, 38), features.10:(44, 76), features.12:(64, 64), features.14:(89, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121431873,\n",
      "    \"flops\": 4960239882,\n",
      "    \"accuracy\": 0.9934,\n",
      "    \"inference_time\": 0.25465687723423014,\n",
      "    \"compression_rate\": 1.1059823972244915,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 23:48:42,770 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 19), features.5:(16, 51), features.7:(44, 44), features.10:(38, 76), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 23:48:58,758 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 19), features.5:(16, 51), features.7:(44, 44), features.10:(38, 76), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 23:50:40,637 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 22), features.2:(19, 16), features.5:(19, 32), features.7:(51, 32), features.10:(32, 64), features.12:(64, 89), features.14:(89, 64), features.17:(76, 128), features.19:(128, 153), features.21:(128, 153), features.24:(128, 128), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121523833,\n",
      "    \"flops\": 4856164874,\n",
      "    \"accuracy\": 0.9934,\n",
      "    \"inference_time\": 0.2770098587003736,\n",
      "    \"compression_rate\": 1.1051454738100632,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 23:50:40,760 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(35, 16), features.5:(19, 32), features.7:(44, 44), features.10:(44, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-30 23:50:56,930 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(35, 16), features.5:(19, 32), features.7:(44, 44), features.10:(44, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0662\n",
      "Epoch 3/3, Loss: 0.0214\n",
      "Epoch 2/3, Loss: 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 23:57:42,954 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(19, 16), features.5:(16, 51), features.7:(32, 32), features.10:(32, 89), features.12:(128, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121447497,\n",
      "    \"flops\": 4849940490,\n",
      "    \"accuracy\": 0.9935,\n",
      "    \"inference_time\": 0.31183927529936384,\n",
      "    \"compression_rate\": 1.1058401145970098,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 23:57:43,105 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 19), features.5:(32, 38), features.7:(51, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 153)\n",
      "2025-03-30 23:57:58,802 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 19), features.5:(32, 38), features.7:(51, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0273\n",
      "Epoch 1/3, Loss: 0.0664\n",
      "Epoch 3/3, Loss: 0.0219\n",
      "Epoch 1/3, Loss: 0.0580\n",
      "Epoch 3/3, Loss: 0.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 00:07:54,296 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(22, 19), features.5:(16, 51), features.7:(44, 44), features.10:(38, 76), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121376387,\n",
      "    \"flops\": 4897231370,\n",
      "    \"accuracy\": 0.9936,\n",
      "    \"inference_time\": 0.26268798530481424,\n",
      "    \"compression_rate\": 1.106487986003406,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-31 00:07:54,499 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(32, 25), features.5:(19, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 00:08:10,546 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(32, 25), features.5:(19, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 00:10:07,937 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(16, 28), features.5:(25, 57), features.7:(38, 44), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 204), features.28:(128, 128)\",\n",
      "    \"params\": 121500623,\n",
      "    \"flops\": 4921955594,\n",
      "    \"accuracy\": 0.9931,\n",
      "    \"inference_time\": 0.2850831319318962,\n",
      "    \"compression_rate\": 1.1053565873485274,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-31 00:10:08,050 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(28, 19), features.5:(19, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-31 00:10:23,284 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(28, 19), features.5:(19, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0269\n",
      "Epoch 1/3, Loss: 0.1751\n",
      "Epoch 2/3, Loss: 0.0254\n",
      "Epoch 2/3, Loss: 0.0347\n",
      "Epoch 1/3, Loss: 0.1479\n",
      "Epoch 3/3, Loss: 0.0215\n",
      "Epoch 3/3, Loss: 0.0217\n",
      "Epoch 3/3, Loss: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 00:24:46,503 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 25), features.2:(35, 16), features.5:(19, 32), features.7:(44, 44), features.10:(44, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121364137,\n",
      "    \"flops\": 4690257930,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.22092442148050684,\n",
      "    \"compression_rate\": 1.106599670378738,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-31 00:24:46,639 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(16, 25), features.5:(28, 32), features.7:(38, 32), features.10:(38, 76), features.12:(76, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 153), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-31 00:25:02,230 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(16, 25), features.5:(28, 32), features.7:(38, 32), features.10:(38, 76), features.12:(76, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 153), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-31 00:25:32,694 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 19), features.2:(16, 19), features.5:(32, 38), features.7:(51, 32), features.10:(38, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 153)\",\n",
      "    \"params\": 121484761,\n",
      "    \"flops\": 3556193802,\n",
      "    \"accuracy\": 0.9934,\n",
      "    \"inference_time\": 0.21712784048351766,\n",
      "    \"compression_rate\": 1.1055009113447571,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-31 00:25:32,771 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 19), features.5:(22, 32), features.7:(57, 32), features.10:(38, 76), features.12:(64, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(153, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 00:25:48,613 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 19), features.5:(22, 32), features.7:(57, 32), features.10:(38, 76), features.12:(64, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(153, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 00:27:47,827 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 25), features.2:(32, 25), features.5:(19, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121339248,\n",
      "    \"flops\": 2369670666,\n",
      "    \"accuracy\": 0.9916,\n",
      "    \"inference_time\": 0.286022627682696,\n",
      "    \"compression_rate\": 1.1068266551314048,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-31 00:27:47,954 - MainProcess - INFO - Compressing to:features.0:(2, 25), features.2:(16, 32), features.5:(28, 44), features.7:(32, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 00:28:03,868 - MainProcess - INFO - finetuning:features.0:(2, 25), features.2:(16, 32), features.5:(28, 44), features.7:(32, 32), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1527\n",
      "Epoch 1/3, Loss: 0.0664\n",
      "Epoch 1/3, Loss: 0.1182\n",
      "Epoch 3/3, Loss: 0.0265\n",
      "Epoch 2/3, Loss: 0.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 00:40:33,121 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 25), features.2:(28, 19), features.5:(19, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\",\n",
      "    \"params\": 121425474,\n",
      "    \"flops\": 3547524618,\n",
      "    \"accuracy\": 0.9897,\n",
      "    \"inference_time\": 0.30396045494484547,\n",
      "    \"compression_rate\": 1.1060406813812396,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-31 00:40:33,269 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(25, 22), features.5:(25, 32), features.7:(32, 38), features.10:(38, 64), features.12:(89, 64), features.14:(102, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 00:40:33,269 - MainProcess - INFO - Evaluated 100 configurations, found 100 accepted models\n",
      "2025-03-31 00:40:49,251 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(25, 22), features.5:(25, 32), features.7:(32, 38), features.10:(38, 64), features.12:(89, 64), features.14:(102, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 00:42:44,011 - MainProcess - ERROR - Error processing config: {'features.0': (2, 25), 'features.2': (16, 32), 'features.5': (28, 44), 'features.7': (32, 32), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 605.00 MiB is free. Including non-PyTorch memory, this process has 46.93 GiB memory in use. Of the allocated memory 42.03 GiB is allocated by PyTorch, and 4.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 00:42:44,215 - MainProcess - INFO - Compressing to:features.0:(1, 25), features.2:(19, 16), features.5:(16, 32), features.7:(32, 38), features.10:(32, 64), features.12:(76, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 00:42:59,995 - MainProcess - INFO - finetuning:features.0:(1, 25), features.2:(19, 16), features.5:(16, 32), features.7:(32, 38), features.10:(32, 64), features.12:(76, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0317\n",
      "Epoch 1/3, Loss: 0.1794\n",
      "Epoch 1/3, Loss: 0.0606\n",
      "Epoch 3/3, Loss: 0.0250\n",
      "Epoch 2/3, Loss: 0.0348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 00:53:51,788 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 19), features.2:(16, 19), features.5:(22, 32), features.7:(57, 32), features.10:(38, 76), features.12:(64, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 153), features.21:(153, 128), features.24:(128, 179), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121539782,\n",
      "    \"flops\": 4871867402,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.3059930538169391,\n",
      "    \"compression_rate\": 1.1050004516216756,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-31 00:53:51,928 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(32, 28), features.5:(22, 44), features.7:(38, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 89), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(179, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-31 00:54:07,547 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(32, 28), features.5:(22, 44), features.7:(38, 32), features.10:(38, 64), features.12:(64, 64), features.14:(76, 89), features.17:(76, 128), features.19:(128, 128), features.21:(153, 128), features.24:(179, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-31 00:55:14,705 - MainProcess - ERROR - Error processing config: {'features.0': (1, 25), 'features.2': (19, 16), 'features.5': (16, 32), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (76, 89), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 465.00 MiB is free. Including non-PyTorch memory, this process has 47.06 GiB memory in use. Of the allocated memory 43.03 GiB is allocated by PyTorch, and 3.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 00:55:14,812 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(22, 28), features.5:(19, 32), features.7:(44, 32), features.10:(51, 76), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 00:55:30,885 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(22, 28), features.5:(19, 32), features.7:(44, 32), features.10:(51, 76), features.12:(64, 89), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 00:55:42,531 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (22, 28), 'features.5': (19, 32), 'features.7': (44, 32), 'features.10': (51, 76), 'features.12': (64, 89), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 389.00 MiB is free. Including non-PyTorch memory, this process has 47.14 GiB memory in use. Of the allocated memory 44.56 GiB is allocated by PyTorch, and 2.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 00:55:42,580 - MainProcess - INFO - Compressing to:features.0:(1, 41), features.2:(16, 28), features.5:(19, 38), features.7:(38, 57), features.10:(32, 64), features.12:(89, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 00:55:57,866 - MainProcess - INFO - finetuning:features.0:(1, 41), features.2:(16, 28), features.5:(19, 38), features.7:(38, 57), features.10:(32, 64), features.12:(89, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 00:59:21,434 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 25), features.2:(16, 25), features.5:(28, 32), features.7:(38, 32), features.10:(38, 76), features.12:(76, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(153, 153), features.26:(128, 153), features.28:(128, 128)\",\n",
      "    \"params\": 121539583,\n",
      "    \"flops\": 4842964654,\n",
      "    \"accuracy\": 0.9929,\n",
      "    \"inference_time\": 0.31822703294693283,\n",
      "    \"compression_rate\": 1.105002260868379,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-31 00:59:21,568 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 16), features.5:(16, 32), features.7:(38, 44), features.10:(38, 89), features.12:(76, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 00:59:37,626 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 16), features.5:(16, 32), features.7:(38, 44), features.10:(38, 89), features.12:(76, 64), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:00:02,202 - MainProcess - ERROR - Error processing config: {'features.0': (1, 41), 'features.2': (16, 28), 'features.5': (19, 38), 'features.7': (38, 57), 'features.10': (32, 64), 'features.12': (89, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 243.00 MiB is free. Including non-PyTorch memory, this process has 47.28 GiB memory in use. Of the allocated memory 46.36 GiB is allocated by PyTorch, and 531.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:00:02,208 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (32, 28), 'features.5': (22, 44), 'features.7': (38, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (76, 89), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (179, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 249.00 MiB is free. Including non-PyTorch memory, this process has 47.28 GiB memory in use. Of the allocated memory 46.42 GiB is allocated by PyTorch, and 466.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:00:02,222 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 16), features.5:(19, 38), features.7:(32, 32), features.10:(44, 64), features.12:(76, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:00:02,264 - MainProcess - INFO - Compressing to:features.0:(2, 28), features.2:(28, 19), features.5:(19, 38), features.7:(57, 38), features.10:(51, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-31 01:00:20,303 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 16), features.5:(19, 38), features.7:(32, 32), features.10:(44, 64), features.12:(76, 76), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(153, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:00:21,629 - MainProcess - INFO - finetuning:features.0:(2, 28), features.2:(28, 19), features.5:(19, 38), features.7:(57, 38), features.10:(51, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 153), features.28:(128, 128)\n",
      "2025-03-31 01:00:23,421 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 16), 'features.5': (19, 38), 'features.7': (32, 32), 'features.10': (44, 64), 'features.12': (76, 76), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (153, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 23.00 MiB is free. Including non-PyTorch memory, this process has 47.50 GiB memory in use. Of the allocated memory 46.70 GiB is allocated by PyTorch, and 407.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:00:23,427 - MainProcess - ERROR - Error processing config: {'features.0': (2, 28), 'features.2': (28, 19), 'features.5': (19, 38), 'features.7': (57, 38), 'features.10': (51, 64), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 25.00 MiB is free. Including non-PyTorch memory, this process has 47.49 GiB memory in use. Of the allocated memory 46.67 GiB is allocated by PyTorch, and 430.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:00:23,446 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(19, 16), features.5:(22, 44), features.7:(32, 32), features.10:(38, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-31 01:00:23,493 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(35, 35), features.5:(16, 38), features.7:(44, 32), features.10:(38, 89), features.12:(64, 64), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:00:41,540 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(19, 16), features.5:(22, 44), features.7:(32, 32), features.10:(38, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(179, 128), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-31 01:00:41,761 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(35, 35), features.5:(16, 38), features.7:(44, 32), features.10:(38, 89), features.12:(64, 64), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:00:47,958 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (19, 16), 'features.5': (22, 44), 'features.7': (32, 32), 'features.10': (38, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (179, 128), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 151.00 MiB is free. Including non-PyTorch memory, this process has 47.37 GiB memory in use. Of the allocated memory 46.32 GiB is allocated by PyTorch, and 667.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:00:47,993 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(16, 16), features.5:(19, 32), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:01:04,161 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(16, 16), features.5:(19, 32), features.7:(32, 44), features.10:(32, 64), features.12:(64, 64), features.14:(64, 76), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:01:07,210 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (16, 16), 'features.5': (19, 32), 'features.7': (32, 44), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 76), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 307.00 MiB is free. Including non-PyTorch memory, this process has 47.22 GiB memory in use. Of the allocated memory 46.48 GiB is allocated by PyTorch, and 340.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:01:07,267 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(35, 32), features.5:(44, 38), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-31 01:01:23,401 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(35, 32), features.5:(44, 38), features.7:(32, 32), features.10:(32, 76), features.12:(64, 64), features.14:(64, 64), features.17:(76, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(153, 128)\n",
      "2025-03-31 01:02:16,384 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (35, 35), 'features.5': (16, 38), 'features.7': (44, 32), 'features.10': (38, 89), 'features.12': (64, 64), 'features.14': (76, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 283.00 MiB is free. Including non-PyTorch memory, this process has 47.24 GiB memory in use. Of the allocated memory 46.51 GiB is allocated by PyTorch, and 339.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:02:16,388 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (25, 22), 'features.5': (25, 32), 'features.7': (32, 38), 'features.10': (38, 64), 'features.12': (89, 64), 'features.14': (102, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 167.00 MiB is free. Including non-PyTorch memory, this process has 47.36 GiB memory in use. Of the allocated memory 46.67 GiB is allocated by PyTorch, and 293.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:02:16,400 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (35, 32), 'features.5': (44, 38), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (76, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 227.00 MiB is free. Including non-PyTorch memory, this process has 47.30 GiB memory in use. Of the allocated memory 46.29 GiB is allocated by PyTorch, and 619.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:02:16,425 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(28, 19), features.5:(16, 32), features.7:(32, 51), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:02:16,483 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(16, 16), features.5:(28, 44), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-31 01:02:16,485 - MainProcess - INFO - Compressing to:features.0:(1, 28), features.2:(51, 28), features.5:(19, 44), features.7:(32, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:02:34,812 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(28, 19), features.5:(16, 32), features.7:(32, 51), features.10:(32, 64), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 153), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:02:36,331 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(16, 16), features.5:(28, 44), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-31 01:02:36,334 - MainProcess - INFO - finetuning:features.0:(1, 28), features.2:(51, 28), features.5:(19, 44), features.7:(32, 32), features.10:(32, 76), features.12:(76, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:02:39,225 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (28, 19), 'features.5': (16, 32), 'features.7': (32, 51), 'features.10': (32, 64), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 153), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 393.00 MiB is free. Including non-PyTorch memory, this process has 47.13 GiB memory in use. Of the allocated memory 46.24 GiB is allocated by PyTorch, and 499.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:02:39,254 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(41, 41), features.5:(38, 32), features.7:(32, 51), features.10:(44, 102), features.12:(64, 76), features.14:(64, 64), features.17:(64, 153), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:02:55,927 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(41, 41), features.5:(38, 32), features.7:(32, 51), features.10:(44, 102), features.12:(64, 76), features.14:(64, 64), features.17:(64, 153), features.19:(128, 153), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:03:02,670 - MainProcess - ERROR - Error processing config: {'features.0': (1, 28), 'features.2': (51, 28), 'features.5': (19, 44), 'features.7': (32, 32), 'features.10': (32, 76), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 75.00 MiB is free. Including non-PyTorch memory, this process has 47.45 GiB memory in use. Of the allocated memory 46.44 GiB is allocated by PyTorch, and 620.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:03:02,670 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (16, 16), 'features.5': (28, 44), 'features.7': (38, 32), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 75.00 MiB is free. Including non-PyTorch memory, this process has 47.45 GiB memory in use. Of the allocated memory 46.44 GiB is allocated by PyTorch, and 620.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:03:02,678 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 16), 'features.5': (16, 32), 'features.7': (38, 44), 'features.10': (38, 89), 'features.12': (76, 64), 'features.14': (64, 64), 'features.17': (76, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 75.00 MiB is free. Including non-PyTorch memory, this process has 47.45 GiB memory in use. Of the allocated memory 46.44 GiB is allocated by PyTorch, and 612.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:03:02,701 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 25), features.5:(19, 32), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 102), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:03:02,728 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(19, 16), features.5:(22, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-31 01:03:02,728 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(22, 16), features.5:(41, 38), features.7:(38, 51), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:03:21,572 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 25), features.5:(19, 32), features.7:(32, 32), features.10:(44, 64), features.12:(64, 64), features.14:(64, 102), features.17:(64, 128), features.19:(153, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:03:22,710 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(19, 16), features.5:(22, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-31 01:03:22,823 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(22, 16), features.5:(41, 38), features.7:(38, 51), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:03:51,324 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (22, 25), 'features.5': (19, 32), 'features.7': (32, 32), 'features.10': (44, 64), 'features.12': (64, 64), 'features.14': (64, 102), 'features.17': (64, 128), 'features.19': (153, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 187.00 MiB is free. Including non-PyTorch memory, this process has 47.34 GiB memory in use. Of the allocated memory 43.41 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:03:51,425 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(19, 22), features.5:(28, 32), features.7:(38, 57), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\n",
      "2025-03-31 01:04:07,606 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(19, 22), features.5:(28, 32), features.7:(38, 57), features.10:(38, 64), features.12:(64, 64), features.14:(76, 64), features.17:(102, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(153, 128)\n",
      "2025-03-31 01:04:14,338 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (19, 22), 'features.5': (28, 32), 'features.7': (38, 57), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (102, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (153, 128), 'features.28': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 47.00 MiB is free. Including non-PyTorch memory, this process has 47.47 GiB memory in use. Of the allocated memory 46.58 GiB is allocated by PyTorch, and 504.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:04:14,347 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (41, 41), 'features.5': (38, 32), 'features.7': (32, 51), 'features.10': (44, 102), 'features.12': (64, 76), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 145.00 MiB is free. Including non-PyTorch memory, this process has 47.38 GiB memory in use. Of the allocated memory 46.45 GiB is allocated by PyTorch, and 533.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:04:14,375 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(16, 44), features.5:(32, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-31 01:04:14,378 - MainProcess - INFO - Compressing to:features.0:(2, 32), features.2:(19, 16), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-31 01:04:32,560 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(16, 44), features.5:(32, 38), features.7:(32, 38), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 153), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 153)\n",
      "2025-03-31 01:04:32,562 - MainProcess - INFO - finetuning:features.0:(2, 32), features.2:(19, 16), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\n",
      "2025-03-31 01:04:40,196 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (16, 44), 'features.5': (32, 38), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 113.00 MiB is free. Including non-PyTorch memory, this process has 47.41 GiB memory in use. Of the allocated memory 45.23 GiB is allocated by PyTorch, and 1.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:04:40,272 - MainProcess - INFO - Compressing to:features.0:(1, 19), features.2:(16, 16), features.5:(41, 32), features.7:(32, 32), features.10:(51, 64), features.12:(64, 64), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 153)\n",
      "2025-03-31 01:04:56,601 - MainProcess - INFO - finetuning:features.0:(1, 19), features.2:(16, 16), features.5:(41, 32), features.7:(32, 32), features.10:(51, 64), features.12:(64, 64), features.14:(76, 89), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 153)\n",
      "2025-03-31 01:06:09,251 - MainProcess - ERROR - Error processing config: {'features.0': (1, 19), 'features.2': (16, 16), 'features.5': (41, 32), 'features.7': (32, 32), 'features.10': (51, 64), 'features.12': (64, 64), 'features.14': (76, 89), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 393.00 MiB is free. Including non-PyTorch memory, this process has 47.13 GiB memory in use. Of the allocated memory 44.85 GiB is allocated by PyTorch, and 1.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:06:09,354 - MainProcess - INFO - Compressing to:features.0:(1, 16), features.2:(16, 16), features.5:(22, 44), features.7:(32, 32), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:06:23,989 - MainProcess - INFO - finetuning:features.0:(1, 16), features.2:(16, 16), features.5:(22, 44), features.7:(32, 32), features.10:(51, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(153, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:08:36,288 - MainProcess - ERROR - Error processing config: {'features.0': (1, 16), 'features.2': (16, 16), 'features.5': (22, 44), 'features.7': (32, 32), 'features.10': (51, 64), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 153), 'features.21': (128, 128), 'features.24': (153, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 191.00 MiB is free. Including non-PyTorch memory, this process has 47.33 GiB memory in use. Of the allocated memory 44.79 GiB is allocated by PyTorch, and 2.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:08:36,391 - MainProcess - INFO - Compressing to:features.0:(2, 16), features.2:(16, 25), features.5:(19, 32), features.7:(38, 32), features.10:(44, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:08:51,121 - MainProcess - INFO - finetuning:features.0:(2, 16), features.2:(16, 25), features.5:(19, 32), features.7:(38, 32), features.10:(44, 76), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:08:57,105 - MainProcess - ERROR - Error processing config: {'features.0': (2, 16), 'features.2': (16, 25), 'features.5': (19, 32), 'features.7': (38, 32), 'features.10': (44, 76), 'features.12': (64, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 113.00 MiB is free. Including non-PyTorch memory, this process has 47.41 GiB memory in use. Of the allocated memory 43.21 GiB is allocated by PyTorch, and 3.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:08:57,155 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(19, 16), features.5:(16, 32), features.7:(32, 44), features.10:(44, 64), features.12:(89, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:09:11,700 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(19, 16), features.5:(16, 32), features.7:(32, 44), features.10:(44, 64), features.12:(89, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:09:18,457 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (19, 16), 'features.5': (16, 32), 'features.7': (32, 44), 'features.10': (44, 64), 'features.12': (89, 64), 'features.14': (64, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 319.00 MiB is free. Including non-PyTorch memory, this process has 47.21 GiB memory in use. Of the allocated memory 43.28 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:09:18,586 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(19, 16), features.5:(16, 44), features.7:(38, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:09:32,974 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(19, 16), features.5:(16, 44), features.7:(38, 44), features.10:(32, 64), features.12:(64, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:09:57,436 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (19, 16), 'features.5': (16, 44), 'features.7': (38, 44), 'features.10': (32, 64), 'features.12': (64, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 181.00 MiB is free. Including non-PyTorch memory, this process has 47.34 GiB memory in use. Of the allocated memory 43.49 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:09:57,530 - MainProcess - INFO - Compressing to:features.0:(2, 19), features.2:(28, 16), features.5:(16, 38), features.7:(32, 38), features.10:(32, 64), features.12:(76, 89), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:10:12,088 - MainProcess - INFO - finetuning:features.0:(2, 19), features.2:(28, 16), features.5:(16, 38), features.7:(32, 38), features.10:(32, 64), features.12:(76, 89), features.14:(64, 64), features.17:(76, 153), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 128), features.28:(128, 128)\n",
      "2025-03-31 01:10:21,294 - MainProcess - ERROR - Error processing config: {'features.0': (2, 19), 'features.2': (28, 16), 'features.5': (16, 38), 'features.7': (32, 38), 'features.10': (32, 64), 'features.12': (76, 89), 'features.14': (64, 64), 'features.17': (76, 153), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 128), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 189.00 MiB is free. Including non-PyTorch memory, this process has 47.33 GiB memory in use. Of the allocated memory 45.98 GiB is allocated by PyTorch, and 978.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:10:21,330 - MainProcess - INFO - Compressing to:features.0:(2, 22), features.2:(35, 16), features.5:(32, 38), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-31 01:10:36,398 - MainProcess - INFO - finetuning:features.0:(2, 22), features.2:(35, 16), features.5:(32, 38), features.7:(44, 32), features.10:(38, 64), features.12:(64, 64), features.14:(89, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 153), features.26:(128, 153), features.28:(128, 128)\n",
      "2025-03-31 01:10:44,275 - MainProcess - ERROR - Error processing config: {'features.0': (2, 22), 'features.2': (35, 16), 'features.5': (32, 38), 'features.7': (44, 32), 'features.10': (38, 64), 'features.12': (64, 64), 'features.14': (89, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 153), 'features.26': (128, 153), 'features.28': (128, 128)}. Error: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 29.00 MiB is free. Including non-PyTorch memory, this process has 47.49 GiB memory in use. Of the allocated memory 43.72 GiB is allocated by PyTorch, and 3.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-31 01:10:44,374 - MainProcess - INFO - Compressing to:features.0:(1, 22), features.2:(19, 16), features.5:(19, 32), features.7:(32, 38), features.10:(32, 76), features.12:(76, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 153)\n",
      "2025-03-31 01:10:59,447 - MainProcess - INFO - finetuning:features.0:(1, 22), features.2:(19, 16), features.5:(19, 32), features.7:(32, 38), features.10:(32, 76), features.12:(76, 64), features.14:(76, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(128, 153), features.28:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1405\n",
      "Epoch 1/3, Loss: 0.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 01:11:54,419 - MainProcess - ERROR - Error processing config: {'features.0': (1, 22), 'features.2': (19, 16), 'features.5': (19, 32), 'features.7': (32, 38), 'features.10': (32, 76), 'features.12': (76, 64), 'features.14': (76, 64), 'features.17': (64, 128), 'features.19': (128, 128), 'features.21': (128, 128), 'features.24': (128, 128), 'features.26': (128, 153), 'features.28': (128, 153)}. Error: CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 267.00 MiB is free. Including non-PyTorch memory, this process has 47.26 GiB memory in use. Of the allocated memory 44.76 GiB is allocated by PyTorch, and 2.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0662\n",
      "Epoch 2/3, Loss: 0.0271\n",
      "Epoch 2/3, Loss: 0.0322\n",
      "Epoch 3/3, Loss: 0.0212\n",
      "Epoch 2/3, Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 01:21:56,912 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 32), features.2:(19, 16), features.5:(19, 32), features.7:(38, 32), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(128, 128), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121373657,\n",
      "    \"flops\": 2686632458,\n",
      "    \"accuracy\": 0.9928,\n",
      "    \"inference_time\": 0.17827514022778557,\n",
      "    \"compression_rate\": 1.106512873711962,\n",
      "    \"accepted\": true\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0258\n",
      "Epoch 3/3, Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 01:25:47,191 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(1, 16), features.2:(19, 16), features.5:(22, 32), features.7:(44, 32), features.10:(38, 64), features.12:(64, 76), features.14:(64, 64), features.17:(64, 128), features.19:(128, 128), features.21:(128, 128), features.24:(153, 128), features.26:(153, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121433886,\n",
      "    \"flops\": 2167586826,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.10597728214952344,\n",
      "    \"compression_rate\": 1.1059640634410728,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-31 01:25:58,397 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"features.0:(2, 16), features.2:(22, 16), features.5:(41, 38), features.7:(38, 51), features.10:(32, 64), features.12:(64, 64), features.14:(64, 64), features.17:(64, 128), features.19:(128, 153), features.21:(128, 128), features.24:(128, 153), features.26:(128, 128), features.28:(128, 128)\",\n",
      "    \"params\": 121436561,\n",
      "    \"flops\": 3523768842,\n",
      "    \"accuracy\": 0.9932,\n",
      "    \"inference_time\": 0.09429076674637521,\n",
      "    \"compression_rate\": 1.1059397013062648,\n",
      "    \"accepted\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import uuid\n",
    "\n",
    "\n",
    "num_workers = 4\n",
    "num_gpus = 1  # torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "results = []\n",
    "tried_count = 0\n",
    "accepted_models = []\n",
    "\n",
    "sensitivities = precompute_sensitivities(layer_dict)\n",
    "configs = generate_configs(layer_dict, sensitivities, num_cfg=500, alpha=1.0, beta=1.0)\n",
    "acceptance_threshold = ACCU_RQT * baseline_accuracy\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Submit tasks with device indices in round-robin\n",
    "    if num_gpus > 0:\n",
    "        futures = [executor.submit(process_config, config, 0) for config in configs] #- i % num_gpus) for i, config in enumerate(configs)]\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    results.append(result)\n",
    "                    \n",
    "                    if result['accepted']:\n",
    "                        accepted_models.append(result)\n",
    "                    \n",
    "                    tried_count += 1\n",
    "                    if tried_count % 10 == 0:\n",
    "                        logger.info(f\"Evaluated {tried_count} configurations, found {len(accepted_models)} accepted models\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in future processing: {str(e)}\")\n",
    "    else:\n",
    "        logger.warning('NO GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "280199f8-43db-452f-afc1-393324847cc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save top 10 models\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepted_models:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43maccepted_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     top_models \u001b[38;5;241m=\u001b[39m accepted_models[:\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m      5\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(accepted_models)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accepted models, saving top \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(top_models)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save top 10 models\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepted_models:\n\u001b[0;32m----> 3\u001b[0m     accepted_models\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     top_models \u001b[38;5;241m=\u001b[39m accepted_models[:\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m      5\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(accepted_models)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accepted models, saving top \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(top_models)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'score'"
     ]
    }
   ],
   "source": [
    "# Save top 10 models\n",
    "if accepted_models:\n",
    "    accepted_models.sort(key=lambda x: x['score'], reverse=True)\n",
    "    top_models = accepted_models[:10]\n",
    "    logger.info(f\"Found {len(accepted_models)} accepted models, saving top {len(top_models)}\")\n",
    "    \n",
    "    for model_info in top_models:\n",
    "        final_save_path = os.path.join(save_dir, f\"htd_{MODEL_NAME}_{model_info['config_str']}_{timestamp}.pth\")\n",
    "        os.rename(model_info['model_path'], final_save_path)\n",
    "        logger.info(f\"Saved top model {model_info['config_str']} to {final_save_path}\")/home/fmokadem/NAS/tdcnn/README.md\n",
    "    \n",
    "    # Clean up remaining temporary files\n",
    "    for model_info in accepted_models[10:]:\n",
    "        if model_info['model_path'] and os.path.exists(model_info['model_path']):\n",
    "            os.remove(model_info['model_path'])\n",
    "else:\n",
    "    logger.info(\"No accepted models found\")\n",
    "\n",
    "# Clean up temp directory if empty\n",
    "if not os.listdir(temp_dir):\n",
    "    os.rmdir(temp_dir)\n",
    "\n",
    "logger.info(f\"HTD experiment for {MODEL_NAME} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8813f84-0f6f-4563-8920-779e008ad91f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
