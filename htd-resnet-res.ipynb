{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d3d2ac-3f5d-449d-851f-305f00686335",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "- htd on resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93857d92-bc9f-4532-93a1-6c34e0913e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "EXP_DIR = \"/home/fmokadem/NAS/tdcnn/\"\n",
    "sys.path.append(EXP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3741a15-e1ba-4944-97fd-2a98b7b62ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import models\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4466e8-95ac-425e-9cac-a56e502a5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.dataset import load_mnist\n",
    "from common._logging import setup_logger\n",
    "from common.utils import (\n",
    "    count_parameters, \n",
    "    measure_inference_time, \n",
    "    calculate_accuracy, \n",
    "    get_flops, \n",
    "    get_conv2d_layers,\n",
    "    infer_rank, \n",
    "    calculate_layer_params,\n",
    "    replace_conv2d_with_tucker,\n",
    "    fine_tune\n",
    ")\n",
    "from common.load_models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cf3a1b6c-41f3-49c7-8956-f89d578ac0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'resnet'\n",
    "FINETUNE = True\n",
    "MAX_CFG = 500\n",
    "ACCU_RQT = .90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970a0ecf-89d9-4a87-ba02-060ad4595493",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(EXP_DIR, f'finetuned/saved_models/{MODEL_NAME}18_mnist.pth')\n",
    "LOG_DIR = os.path.join(EXP_DIR, 'logs')\n",
    "LOG_PREFIX = 'htd_renet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e247114-c0a4-4336-beba-8c8313bfa166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 15:32:02,096 - MainProcess - INFO - Logging to /home/fmokadem/NAS/tdcnn/logs/htd_renet18_20250329_153202.log\n",
      "2025-03-29 15:32:02,097 - MainProcess - INFO - Starting HTD experiment for resnet\n"
     ]
    }
   ],
   "source": [
    "logger = setup_logger(LOG_PREFIX, LOG_DIR, LOG_PREFIX)\n",
    "logger.info(f\"Starting HTD experiment for {MODEL_NAME}\")\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad31f0a-d456-4517-b6e1-763e3c682ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 15:32:02,791 - MainProcess - INFO - Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# use gpu 0 only\n",
    "device_idx = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(device_idx)\n",
    "    device = f'cuda:{device_idx}'\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c051af6-9518-4d56-8ad1-d7a34f68dc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 15:32:03,641 - MainProcess - INFO - MNIST loaded: 60000 train, 10000 test samples\n",
      "/home/fmokadem/NAS/tdcnn/common/load_models.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_model = torch.load(model_path, map_location=device)\n",
      "2025-03-29 15:32:03,941 - MainProcess - INFO - Loaded resnet from /home/fmokadem/NAS/tdcnn/finetuned/saved_models/resnet18_mnist.pth\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_loader, test_loader = load_mnist()\n",
    "logger.info(f\"MNIST loaded: {len(train_loader.dataset)} train, {len(test_loader.dataset)} test samples\")\n",
    "\n",
    "# Load model\n",
    "model = load_model(MODEL_NAME, MODEL_PATH, device)\n",
    "logger.info(f\"Loaded {MODEL_NAME} from {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b67f4a-c0cd-46e9-8fe1-5caf9d7db788",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, tr = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d58c92b-5c2c-468e-86f0-513cfb10487e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Grayscale(num_output_channels=3)\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b020e5d-9424-4990-b589-c05aa99042c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 122, 122]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 122, 122]             128\n",
      "              ReLU-3         [-1, 64, 122, 122]               0\n",
      "         MaxPool2d-4           [-1, 64, 61, 61]               0\n",
      "            Conv2d-5           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 61, 61]             128\n",
      "              ReLU-7           [-1, 64, 61, 61]               0\n",
      "            Conv2d-8           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 61, 61]             128\n",
      "             ReLU-10           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-11           [-1, 64, 61, 61]               0\n",
      "           Conv2d-12           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 61, 61]             128\n",
      "             ReLU-14           [-1, 64, 61, 61]               0\n",
      "           Conv2d-15           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 61, 61]             128\n",
      "             ReLU-17           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-18           [-1, 64, 61, 61]               0\n",
      "           Conv2d-19          [-1, 128, 31, 31]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 31, 31]             256\n",
      "             ReLU-21          [-1, 128, 31, 31]               0\n",
      "           Conv2d-22          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 31, 31]             256\n",
      "           Conv2d-24          [-1, 128, 31, 31]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 31, 31]             256\n",
      "             ReLU-26          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-27          [-1, 128, 31, 31]               0\n",
      "           Conv2d-28          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 31, 31]             256\n",
      "             ReLU-30          [-1, 128, 31, 31]               0\n",
      "           Conv2d-31          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 31, 31]             256\n",
      "             ReLU-33          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-34          [-1, 128, 31, 31]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,181,642\n",
      "Trainable params: 11,181,642\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 76.08\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 119.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 244, 244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc50a506-356d-4e8d-abf9-4e23b6e7ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 15:32:07,655 - MainProcess - INFO - Found 20 Conv2D layers in resnet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conv1': Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " 'layer1.0.conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer1.0.conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer1.1.conv1': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer1.1.conv2': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer2.0.conv1': Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " 'layer2.0.conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer2.0.downsample.0': Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " 'layer2.1.conv1': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer2.1.conv2': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer3.0.conv1': Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " 'layer3.0.conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer3.0.downsample.0': Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " 'layer3.1.conv1': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer3.1.conv2': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer4.0.conv1': Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " 'layer4.0.conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer4.0.downsample.0': Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " 'layer4.1.conv1': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " 'layer4.1.conv2': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Conv2D layers\n",
    "conv_layers = get_conv2d_layers(model)\n",
    "logger.info(f\"Found {len(conv_layers)} Conv2D layers in {MODEL_NAME}\")\n",
    "conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db6ca7c6-4dc5-4fe6-8f06-859c006c6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 15:32:08,870 - MainProcess - INFO - Layer conv1: initial rank R_i = 3, parameters = 9408\n",
      "2025-03-29 15:32:08,874 - MainProcess - INFO - Layer layer1.0.conv1: initial rank R_i = 64, parameters = 36864\n",
      "2025-03-29 15:32:08,875 - MainProcess - INFO - Layer layer1.0.conv2: initial rank R_i = 64, parameters = 36864\n",
      "2025-03-29 15:32:08,875 - MainProcess - INFO - Layer layer1.1.conv1: initial rank R_i = 64, parameters = 36864\n",
      "2025-03-29 15:32:08,875 - MainProcess - INFO - Layer layer1.1.conv2: initial rank R_i = 64, parameters = 36864\n",
      "2025-03-29 15:32:08,876 - MainProcess - INFO - Layer layer2.0.conv1: initial rank R_i = 64, parameters = 73728\n",
      "2025-03-29 15:32:08,877 - MainProcess - INFO - Layer layer2.0.conv2: initial rank R_i = 128, parameters = 147456\n",
      "2025-03-29 15:32:08,877 - MainProcess - INFO - Layer layer2.0.downsample.0: initial rank R_i = 64, parameters = 8192\n",
      "2025-03-29 15:32:08,878 - MainProcess - INFO - Layer layer2.1.conv1: initial rank R_i = 128, parameters = 147456\n",
      "2025-03-29 15:32:08,878 - MainProcess - INFO - Layer layer2.1.conv2: initial rank R_i = 128, parameters = 147456\n",
      "2025-03-29 15:32:08,879 - MainProcess - INFO - Layer layer3.0.conv1: initial rank R_i = 128, parameters = 294912\n",
      "2025-03-29 15:32:08,879 - MainProcess - INFO - Layer layer3.0.conv2: initial rank R_i = 256, parameters = 589824\n",
      "2025-03-29 15:32:08,880 - MainProcess - INFO - Layer layer3.0.downsample.0: initial rank R_i = 128, parameters = 32768\n",
      "2025-03-29 15:32:08,880 - MainProcess - INFO - Layer layer3.1.conv1: initial rank R_i = 256, parameters = 589824\n",
      "2025-03-29 15:32:08,881 - MainProcess - INFO - Layer layer3.1.conv2: initial rank R_i = 256, parameters = 589824\n",
      "2025-03-29 15:32:08,881 - MainProcess - INFO - Layer layer4.0.conv1: initial rank R_i = 256, parameters = 1179648\n",
      "2025-03-29 15:32:08,881 - MainProcess - INFO - Layer layer4.0.conv2: initial rank R_i = 512, parameters = 2359296\n",
      "2025-03-29 15:32:08,882 - MainProcess - INFO - Layer layer4.0.downsample.0: initial rank R_i = 256, parameters = 131072\n",
      "2025-03-29 15:32:08,882 - MainProcess - INFO - Layer layer4.1.conv1: initial rank R_i = 512, parameters = 2359296\n",
      "2025-03-29 15:32:08,883 - MainProcess - INFO - Layer layer4.1.conv2: initial rank R_i = 512, parameters = 2359296\n"
     ]
    }
   ],
   "source": [
    "# Initialize layer information\n",
    "# Conv2 layers in Pytorch are (Cin, Cout, ks, ks), i.e. a 4D tensor with rank 4, called modes 0 to 3\n",
    "# we are interested in low rank approximating of modes 0 and 1, i.e. compressing the information in  the channels\n",
    "# each mode is almost always full rank, i.e. of rank == size\n",
    "# therefore for the pupose of this exp rank of a layer is the min(Cin, Cout) \n",
    "\n",
    "\n",
    "# TODO: complexity ranks in decreasing order layers that are closest to the middle.  \n",
    "layer_info = {}\n",
    "for name, layer in conv_layers.items():\n",
    "    r_i = infer_rank(layer)\n",
    "    layer_info[name] = {\n",
    "        'layer': layer,\n",
    "        'r_i': r_i,\n",
    "        'params': calculate_layer_params(layer),\n",
    "        'complexity': None\n",
    "    }\n",
    "    logger.info(f\"Layer {name}: initial rank R_i = {r_i}, parameters = {layer_info[name]['params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2242b8e0-52ea-43f2-84b5-8e9ad7b2dae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': {'layer': Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       "  'r_i': 3,\n",
       "  'params': 9408,\n",
       "  'complexity': None},\n",
       " 'layer1.0.conv1': {'layer': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 64,\n",
       "  'params': 36864,\n",
       "  'complexity': None},\n",
       " 'layer1.0.conv2': {'layer': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 64,\n",
       "  'params': 36864,\n",
       "  'complexity': None},\n",
       " 'layer1.1.conv1': {'layer': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 64,\n",
       "  'params': 36864,\n",
       "  'complexity': None},\n",
       " 'layer1.1.conv2': {'layer': Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 64,\n",
       "  'params': 36864,\n",
       "  'complexity': None},\n",
       " 'layer2.0.conv1': {'layer': Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "  'r_i': 64,\n",
       "  'params': 73728,\n",
       "  'complexity': None},\n",
       " 'layer2.0.conv2': {'layer': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 128,\n",
       "  'params': 147456,\n",
       "  'complexity': None},\n",
       " 'layer2.0.downsample.0': {'layer': Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "  'r_i': 64,\n",
       "  'params': 8192,\n",
       "  'complexity': None},\n",
       " 'layer2.1.conv1': {'layer': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 128,\n",
       "  'params': 147456,\n",
       "  'complexity': None},\n",
       " 'layer2.1.conv2': {'layer': Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 128,\n",
       "  'params': 147456,\n",
       "  'complexity': None},\n",
       " 'layer3.0.conv1': {'layer': Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "  'r_i': 128,\n",
       "  'params': 294912,\n",
       "  'complexity': None},\n",
       " 'layer3.0.conv2': {'layer': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 256,\n",
       "  'params': 589824,\n",
       "  'complexity': None},\n",
       " 'layer3.0.downsample.0': {'layer': Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "  'r_i': 128,\n",
       "  'params': 32768,\n",
       "  'complexity': None},\n",
       " 'layer3.1.conv1': {'layer': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 256,\n",
       "  'params': 589824,\n",
       "  'complexity': None},\n",
       " 'layer3.1.conv2': {'layer': Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 256,\n",
       "  'params': 589824,\n",
       "  'complexity': None},\n",
       " 'layer4.0.conv1': {'layer': Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       "  'r_i': 256,\n",
       "  'params': 1179648,\n",
       "  'complexity': None},\n",
       " 'layer4.0.conv2': {'layer': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 512,\n",
       "  'params': 2359296,\n",
       "  'complexity': None},\n",
       " 'layer4.0.downsample.0': {'layer': Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       "  'r_i': 256,\n",
       "  'params': 131072,\n",
       "  'complexity': None},\n",
       " 'layer4.1.conv1': {'layer': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 512,\n",
       "  'params': 2359296,\n",
       "  'complexity': None},\n",
       " 'layer4.1.conv2': {'layer': Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  'r_i': 512,\n",
       "  'params': 2359296,\n",
       "  'complexity': None}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58d648df-fefc-48fc-8972-67241818c1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 15:33:01,042 - MainProcess - INFO - Baseline resnet: params=11181642, FLOPs=1824805898, accuracy=0.9955, inference_time=0.0720s\n"
     ]
    }
   ],
   "source": [
    "# Compute baseline metrics\n",
    "baseline_params = count_parameters(model)\n",
    "baseline_flops = get_flops(model)\n",
    "baseline_accuracy = calculate_accuracy(model, test_loader, device)\n",
    "baseline_inference_time = measure_inference_time(model, test_loader, device, num_runs=3)\n",
    "\n",
    "logger.info(f\"Baseline {MODEL_NAME}: params={baseline_params}, \"\n",
    "            f\"FLOPs={baseline_flops}, accuracy={baseline_accuracy:.4f}, \"\n",
    "            f\"inference_time={baseline_inference_time:.4f}s\")\n",
    "\n",
    "# Timestamp for unique file naming\n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78b8799e-b51c-493e-88ae-a96c3ea13517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 15:33:11,152 - MainProcess - INFO - Total possible configurations: 1050428248894095874, will try: 250\n"
     ]
    }
   ],
   "source": [
    "# Generate possible ranks per layer, that is 1 up to it's rank - 1 \n",
    "# if layer is of rank 1, then possible ranks are just 1\n",
    "possible_ranks = {}\n",
    "for name, info in layer_info.items():\n",
    "    r_i = info['r_i']\n",
    "    ranks = [1] + list(range(2, r_i)) \n",
    "    possible_ranks[name] = ranks\n",
    "\n",
    "total_possible_configs = abs(np.prod([max(1, layer_info[name]['r_i'] - 1) for name in layer_info.keys()]))\n",
    "num_configs_to_try = min(total_possible_configs, MAX_CFG)\n",
    "logger.info(f\"Total possible configurations: {total_possible_configs}, will try: {num_configs_to_try}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9262c9c-1d58-4e50-b60e-ab2ee9f7b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def construct_layer_dict(model):\n",
    "    layer_dict = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            W = module.weight.data\n",
    "            cin = module.in_channels\n",
    "            cout = module.out_channels\n",
    "            layer_dict[name] = (W, cin, cout)\n",
    "    return layer_dict\n",
    "\n",
    "layer_dict = construct_layer_dict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "369c2b8a-708f-4fcb-b449-1e426a6c7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorly.decomposition import partial_tucker\n",
    "import tensorly as tl    \n",
    "from tensorly.tucker_tensor import tucker_to_tensor\n",
    "from tensorly.metrics.regression import MSE\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "# # Heuristic: layers with bigger cin*cout more suseptible to lower ranks \n",
    "# def get_size_probs(cin, cout, rank_candidates, beta=1.0):\n",
    "#     size = cin * cout\n",
    "#     preference = np.log(size + 1)  # +1 to avoid log(0), though unlikely\n",
    "#     scores = [-beta * r / preference for r in rank_candidates]\n",
    "#     probs = np.exp(scores) / np.sum(np.exp(scores))\n",
    "#     return probs\n",
    "\n",
    "# # Heuristic: Layers with higher reconstruction erros are less suseptible to low ranks \n",
    "# def compute_sensitivity(W, cin, cout):\n",
    "#     rank = [max(1, cout // 2), max(1, cin // 2)]\n",
    "#     (core, factors) = partial_tucker(W, modes=[0, 1], rank=rank, init='svd')\n",
    "       \n",
    "#     reconstructed_W = tucker_to_tensor(core, factors)\n",
    "#     return MSE(W, reconstructed_W) \n",
    "\n",
    "# # Precompute sensitivity for all layers\n",
    "# def precompute_sensitivities(layer_dict):\n",
    "#     sensitivities = {}\n",
    "#     for name, (W, cin, cout) in layer_dict.items():\n",
    "#         sensitivities[name] = compute_sensitivity(W, cin, cout).to('cpu')\n",
    "#     # Normalize sensitivities to [0, 1]\n",
    "#     max_error = max(list(sensitivities.values()))\n",
    "#     if max_error > 0:  # Avoid division by zero\n",
    "#         sensitivities = {name: err / max_error for name, err in sensitivities.items()}\n",
    "#     return sensitivities\n",
    "    \n",
    "# def get_sensitivity_probs(sensitivity, rank_candidates, alpha=1.0):\n",
    "#     max_rank = max(rank_candidates)\n",
    "#     scores = [(r / max_rank) ** (alpha * sensitivity) for r in rank_candidates]\n",
    "#     probs = scores / np.sum(scores)\n",
    "#     return probs\n",
    "\n",
    "# def get_rank_candidates(channels, r=(75, 49, -25)):\n",
    "#     s, f, stride = r\n",
    "#     percentages = np.arange(s, f, stride) / 100\n",
    "#     candidates = set([max(1, int(channels * p)) for p in percentages])\n",
    "#     return candidates\n",
    "# def softmax(x: np.ndarray) -> np.ndarray:\n",
    "#     x_max = np.max(x)  # Avoid overflow\n",
    "#     exp_x = np.exp(x - x_max)  # Shift values\n",
    "#     return exp_x / np.sum(exp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e089b161-e0ca-4758-b8c1-eb0236359aeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.special import softmax\n",
    "\n",
    "def get_rank_candidates(channels, r=(90, 24, -5)):\n",
    "    s, f, stride = r\n",
    "    percentages = np.arange(s, f, stride) / 100\n",
    "    candidates = set([max(1, int(channels * p)) for p in percentages])\n",
    "    return candidates\n",
    "\n",
    "def compute_sensitivity(W, cin, cout):\n",
    "    rank = [max(1, cout // 2), max(1, cin // 2)]\n",
    "    (core, factors) = partial_tucker(W, modes=[0, 1], rank=rank, init='svd')\n",
    "    reconstructed_W = tucker_to_tensor(core, factors)\n",
    "    return MSE(W, reconstructed_W)\n",
    "\n",
    "def precompute_sensitivities(layer_dict):\n",
    "    sensitivities = {}\n",
    "    for name, (W, cin, cout) in layer_dict.items():\n",
    "        sensitivities[name] = compute_sensitivity(W, cin, cout).to('cpu').item()\n",
    "    max_error = max(sensitivities.values())\n",
    "    if max_error > 0:\n",
    "        sensitivities = {name: err / max_error for name, err in sensitivities.items()}\n",
    "    return sensitivities\n",
    "\n",
    "def get_sensitivity_scores(sensitivity, rank_candidates, alpha=1.0):\n",
    "    max_rank = max(rank_candidates)\n",
    "    return [(r / max_rank) ** (alpha * sensitivity) for r in rank_candidates]\n",
    "\n",
    "def get_size_based_scores(cin, cout, rank_candidates, beta=1.0):\n",
    "    size = cin * cout\n",
    "    preference = np.log(size + 1)\n",
    "    return [-beta * r / preference for r in rank_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9a60b331-3e2d-4dc9-84c9-8b8ea91c8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_configs(layer_dict, sensitivities, num_cfg=500, alpha=1.0, beta=1.0):\n",
    "    for _ in range(num_cfg):\n",
    "        config = {}\n",
    "        for name, (W, cin, cout) in layer_dict.items():\n",
    "            cin_candidates = list(get_rank_candidates(cin))\n",
    "            cout_candidates = list(get_rank_candidates(cout))\n",
    "            sensitivity = sensitivities[name]\n",
    "\n",
    "            # Combine scores for cin\n",
    "            cin_sen_scores = get_sensitivity_scores(sensitivity, cin_candidates, alpha)\n",
    "            cin_size_scores = get_size_based_scores(cin, cout, cin_candidates, beta)\n",
    "            cin_probs = softmax(np.array(cin_sen_scores) + np.array(cin_size_scores))\n",
    "\n",
    "            # Combine scores for cout\n",
    "            cout_sen_scores = get_sensitivity_scores(sensitivity, cout_candidates, alpha)\n",
    "            cout_size_scores = get_size_based_scores(cin, cout, cout_candidates, beta)\n",
    "            cout_probs = softmax(np.array(cout_sen_scores) + np.array(cout_size_scores))\n",
    "\n",
    "            # Sample ranks\n",
    "            cin_rank = random.choices(cin_candidates, weights=cin_probs)[0]\n",
    "            cout_rank = random.choices(cout_candidates, weights=cout_probs)[0]\n",
    "            config[name] = (cin_rank, cout_rank)\n",
    "        yield config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aae2233f-bc9c-4206-b4b2-f889c1217634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generator function to yield num_cfg configurations\n",
    "# def generate_configs(layer_dict, num_cfg):\n",
    "    \n",
    "    \n",
    "#     # Precompute rank candidates for each layer\n",
    "#     rank_candidates = {}\n",
    "#     for name, (W, cin, cout) in layer_dict.items():\n",
    "#         cin_candidates = get_rank_candidates(cin)  \n",
    "#         cout_candidates = get_rank_candidates(cout)  \n",
    "        \n",
    "#         rank_pairs = list(itertools.product(cin_candidates, cout_candidates))\n",
    "#         rank_candidates[name] = rank_pairs\n",
    "#         # we sort to keep higher ranks on top of the search \n",
    "#         # no heuristic, budget num_cfg accross all layers equally \n",
    "#         # num_cfg / len(layer_dict.keys) searches per layer\n",
    "#         # spl = int(num_cfg ** (1 / len(layer_dict.keys())))\n",
    "#         # rank_candidates[name] = sorted(rank_pairs, key=lambda x: (-x[0], -x[1]))[:spl]\n",
    "    \n",
    "#     # Yield exactly num_cfg random configurations\n",
    "#     for config in itertools.product(*rank_candidates.values()):\n",
    "#         yield dict(zip(layer_dict.keys(), config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ddbb0c-76db-478e-9c9f-ec4e1976d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivities = precompute_sensitivities(layer_dict)\n",
    "configs = generate_configs(layer_dict, sensitivities, num_cfg=500, alpha=1.0, beta=1.0)\n",
    "for config in configs: \n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "39295082-ba41-4233-a6b3-74c62ff07d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "configs = [config for config in generate_configs(layer_dict, sensitivities, num_cfg=500, alpha=1.0, beta=1.0)]\n",
    "\n",
    "def plot_avg_compression_boxplot(layer_dict, configs):\n",
    "    # Step 1: Calculate average rin and rout per layer across configs\n",
    "    avg_ranks = {name: {'rin': [], 'rout': []} for name in layer_dict.keys()}\n",
    "    for config in configs:\n",
    "        for name, (rin, rout) in config.items():\n",
    "            avg_ranks[name]['rin'].append(rin)\n",
    "            avg_ranks[name]['rout'].append(rout)\n",
    "    \n",
    "    # Step 2: Compute compression rates for each config and layer\n",
    "    compression_rates = {name: [] for name in layer_dict.keys()}\n",
    "    for config in configs:\n",
    "        for name, (rin, rout) in config.items():\n",
    "            cin, cout = layer_dict[name][1], layer_dict[name][2]  # Extract cin, cout\n",
    "            if rin > 0 and rout > 0:  # Avoid division by zero\n",
    "                rate = (cin * cout) / (rin * rout)  # Compression rate for this config\n",
    "                compression_rates[name].append(rate)\n",
    "    \n",
    "    # Step 3: Prepare data for plotting\n",
    "    layer_names = list(layer_dict.keys())\n",
    "    data = [compression_rates[name] for name in layer_names if compression_rates[name]]  # Filter out empty lists\n",
    "    \n",
    "    # Step 4: Create box plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(data, labels=layer_names, whis=[min(data), max(data)])\n",
    "    plt.title('Compression Rate Distribution per Layer')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Compression Rate ((cin * cout) / (rin * rout))')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "902bbeae-5afc-4e76-9323-389c97b1f977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3930001/927024760.py:28: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(data, labels=layer_names, whis=[min(data), max(data)])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_avg_compression_boxplot(layer_dict, configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0541106f-2a5f-4fe7-8315-abacb437666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_model(model):\n",
    "    # Check if the model name is valid\n",
    "    model_name = MODEL_NAME\n",
    "    \n",
    "    if model_name == 'vgg':\n",
    "        model_cp = models.vgg16(weights=None)\n",
    "        model_cp.classifier[6] = nn.Linear(4096, 10)\n",
    "        \n",
    "    elif model_name == 'alexnet':\n",
    "        model_cp = models.alexnet(weights=None)\n",
    "        model_cp.classifier[6] = nn.Linear(4096, 10)\n",
    "        \n",
    "    elif model_name == 'resnet':\n",
    "        model_cp = models.resnet18(weights=None)\n",
    "        model_cp.fc = nn.Linear(512, 10)\n",
    "\n",
    "    model_cp.load_state_dict(model.state_dict())   \n",
    "    return model_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f3024b5c-1628-4d25-a3e1-a04c2d947b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_config(config, device_idx):\n",
    "    try:        \n",
    "        # Explicitly create a new scope to help with garbage collection\n",
    "        with torch.enable_grad():\n",
    "\n",
    "            config_str = \", \".join([f\"{k}:{v}\" for k, v in config.items()])\n",
    "            logger.info(f\"Compressing to:{config_str}\")\n",
    "            \n",
    "            # Apply the configuration\n",
    "            model.to('cpu')\n",
    "            compressed_model = duplicate_model(model)\n",
    "            compressed_model.to(device)\n",
    "\n",
    "            for name, rank in config.items():\n",
    "                layer = layer_info[name]['layer']\n",
    "                compressed_model = replace_conv2d_with_tucker(compressed_model, name, layer, rank)\n",
    "\n",
    "            # verify compressed model is still on gpu\n",
    "            compressed_model.to(device)\n",
    "\n",
    "            # Finetune for 3 epochs \n",
    "            if FINETUNE: \n",
    "                logger.info(f\"finetuning:{config_str}\")\n",
    "                compressed_model = fine_tune(compressed_model, train_loader, device, epochs=3, lr=0.001)\n",
    "                \n",
    "            # Evaluate the model\n",
    "            accuracy = calculate_accuracy(compressed_model, test_loader, device)\n",
    "            params = count_parameters(compressed_model)\n",
    "            flops = get_flops(compressed_model)\n",
    "            inference_time = measure_inference_time(compressed_model, test_loader, device, num_runs=3)\n",
    "            compression_rate = baseline_params / params if params > 0 else float('inf')\n",
    "            \n",
    "            result = {\n",
    "                'config_str': config_str,\n",
    "                'params': params,\n",
    "                'flops': flops,\n",
    "                'accuracy': accuracy,\n",
    "                'inference_time': inference_time,\n",
    "                'compression_rate': compression_rate,\n",
    "                'accepted': True if accuracy >= acceptance_threshold else False\n",
    "            }\n",
    "            result_str = json.dumps(result, indent=4, default=str)\n",
    "            logger.info(f\"compressed_model:\\n{result_str}\")\n",
    "\n",
    "            return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing config: {config}. Error: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        # Explicit cleanup\n",
    "        if 'compressed_model' in locals():\n",
    "            del compressed_model\n",
    "        \n",
    "        # Clear CUDA cache\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4777eedf-946d-424e-95e2-267f377bdcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 18:12:28,680 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(25, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 18:12:28,682 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(35, 16), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:12:28,684 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 22), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:12:28,687 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 41), layer1.0.conv2:(35, 19), layer1.1.conv1:(25, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(16, 64), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 18:12:45,972 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(35, 16), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:12:46,572 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 41), layer1.0.conv2:(35, 19), layer1.1.conv1:(25, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(16, 64), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 18:12:46,995 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(25, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 18:12:47,186 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 22), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1327\n",
      "Epoch 1/3, Loss: 0.1411\n",
      "Epoch 1/3, Loss: 0.1324\n",
      "Epoch 1/3, Loss: 0.1304\n",
      "Epoch 2/3, Loss: 0.0497\n",
      "Epoch 2/3, Loss: 0.0502\n",
      "Epoch 2/3, Loss: 0.0498\n",
      "Epoch 2/3, Loss: 0.0485\n",
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 3/3, Loss: 0.0361\n",
      "Epoch 3/3, Loss: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 18:28:02,279 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(35, 16), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1531508,\n",
      "    \"flops\": 509313482,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.19993132643891998,\n",
      "    \"compression_rate\": 7.301066661094817,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:28:02,417 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 28), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:28:19,378 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(19, 41), layer1.0.conv2:(35, 19), layer1.1.conv1:(25, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(16, 64), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1505364,\n",
      "    \"flops\": 733822858,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.19872947559235202,\n",
      "    \"compression_rate\": 7.427865951357944,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:28:19,388 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 35), layer1.1.conv2:(16, 19), layer2.0.conv1:(35, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:28:22,862 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 28), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:28:36,665 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(25, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1541653,\n",
      "    \"flops\": 919020906,\n",
      "    \"accuracy\": 0.9893,\n",
      "    \"inference_time\": 0.19455888620607412,\n",
      "    \"compression_rate\": 7.253021270026394,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:28:36,711 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(28, 22), layer1.0.conv2:(19, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 18:28:38,291 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 35), layer1.1.conv2:(16, 19), layer2.0.conv1:(35, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:28:49,815 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(19, 22), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1464053,\n",
      "    \"flops\": 676446602,\n",
      "    \"accuracy\": 0.9898,\n",
      "    \"inference_time\": 0.19208697655145276,\n",
      "    \"compression_rate\": 7.637457113915958,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:28:49,840 - MainProcess - INFO - Compressing to:conv1:(1, 32), layer1.0.conv1:(16, 38), layer1.0.conv2:(28, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 51), layer2.1.conv1:(44, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 18:28:56,105 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(28, 22), layer1.0.conv2:(19, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 18:29:08,911 - MainProcess - INFO - finetuning:conv1:(1, 32), layer1.0.conv1:(16, 38), layer1.0.conv2:(28, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 51), layer2.1.conv1:(44, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1596\n",
      "Epoch 1/3, Loss: 0.1350\n",
      "Epoch 1/3, Loss: 0.1392\n",
      "Epoch 1/3, Loss: 0.1420\n",
      "Epoch 2/3, Loss: 0.0526\n",
      "Epoch 2/3, Loss: 0.0498\n",
      "Epoch 2/3, Loss: 0.0494\n",
      "Epoch 2/3, Loss: 0.0530\n",
      "Epoch 3/3, Loss: 0.0402\n",
      "Epoch 3/3, Loss: 0.0378\n",
      "Epoch 3/3, Loss: 0.0371\n",
      "Epoch 3/3, Loss: 0.0398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 18:41:23,922 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 28), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1511702,\n",
      "    \"flops\": 500418218,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.1823409079492978,\n",
      "    \"compression_rate\": 7.396723692897145,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:41:24,050 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(115, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:41:39,420 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(115, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:41:43,441 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 35), layer1.1.conv2:(16, 19), layer2.0.conv1:(35, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1590683,\n",
      "    \"flops\": 315039850,\n",
      "    \"accuracy\": 0.9896,\n",
      "    \"inference_time\": 0.17964594632450437,\n",
      "    \"compression_rate\": 7.02945967235458,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:41:43,463 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 54), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 22), layer2.0.conv1:(41, 44), layer2.0.conv2:(76, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:41:58,741 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 54), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 22), layer2.0.conv1:(41, 44), layer2.0.conv2:(76, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:42:13,784 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(28, 22), layer1.0.conv2:(19, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1568964,\n",
      "    \"flops\": 555757642,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.17588525061394758,\n",
      "    \"compression_rate\": 7.126767726984175,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:42:13,797 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(57, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:42:29,712 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(57, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:42:34,073 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 32), layer1.0.conv1:(16, 38), layer1.0.conv2:(28, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 51), layer2.1.conv1:(44, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1507881,\n",
      "    \"flops\": 307827050,\n",
      "    \"accuracy\": 0.9898,\n",
      "    \"inference_time\": 0.17031347321350357,\n",
      "    \"compression_rate\": 7.415467135669194,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:42:34,145 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 35), layer2.0.conv1:(16, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 18:42:50,613 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 35), layer2.0.conv1:(16, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1250\n",
      "Epoch 1/3, Loss: 0.1345\n",
      "Epoch 1/3, Loss: 0.1188\n",
      "Epoch 1/3, Loss: 0.1582\n",
      "Epoch 2/3, Loss: 0.0491\n",
      "Epoch 2/3, Loss: 0.0508\n",
      "Epoch 2/3, Loss: 0.0463\n",
      "Epoch 2/3, Loss: 0.0539\n",
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 3/3, Loss: 0.0372\n",
      "Epoch 3/3, Loss: 0.0357\n",
      "Epoch 3/3, Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 18:54:09,835 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(115, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1519880,\n",
      "    \"flops\": 702977946,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.1690485877342791,\n",
      "    \"compression_rate\": 7.356924230860331,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:54:09,964 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(28, 19), layer1.1.conv1:(19, 16), layer1.1.conv2:(19, 32), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(32, 64), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:54:21,499 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(28, 19), layer1.1.conv1:(19, 16), layer1.1.conv2:(19, 32), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(32, 64), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:54:32,123 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 54), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 22), layer2.0.conv1:(41, 44), layer2.0.conv2:(76, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1518022,\n",
      "    \"flops\": 524507402,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.1623102510051363,\n",
      "    \"compression_rate\": 7.365928820530928,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:54:32,207 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(64, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(102, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:54:32,207 - MainProcess - INFO - Evaluated 10 configurations, found 10 accepted models\n",
      "2025-03-29 18:54:44,195 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(64, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(102, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:55:15,103 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(57, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1572968,\n",
      "    \"flops\": 318556678,\n",
      "    \"accuracy\": 0.9916,\n",
      "    \"inference_time\": 0.1561033472640246,\n",
      "    \"compression_rate\": 7.108626494626718,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:55:15,131 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 32), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:55:26,687 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 32), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:55:38,198 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 35), layer2.0.conv1:(16, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1549053,\n",
      "    \"flops\": 701850358,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.1560665862575458,\n",
      "    \"compression_rate\": 7.2183727735590715,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 18:55:38,236 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(32, 44), layer1.0.conv2:(32, 22), layer1.1.conv1:(38, 19), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 44), layer2.0.conv2:(57, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 18:55:50,662 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(32, 44), layer1.0.conv2:(32, 22), layer1.1.conv1:(38, 19), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 44), layer2.0.conv2:(57, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1280\n",
      "Epoch 1/3, Loss: 0.1360\n",
      "Epoch 1/3, Loss: 0.1307\n",
      "Epoch 1/3, Loss: 0.1171\n",
      "Epoch 2/3, Loss: 0.0486\n",
      "Epoch 2/3, Loss: 0.0507\n",
      "Epoch 2/3, Loss: 0.0499\n",
      "Epoch 2/3, Loss: 0.0454\n",
      "Epoch 3/3, Loss: 0.0371\n",
      "Epoch 3/3, Loss: 0.0385\n",
      "Epoch 3/3, Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:06:52,794 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(28, 19), layer1.1.conv1:(19, 16), layer1.1.conv2:(19, 32), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(32, 64), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1544876,\n",
      "    \"flops\": 524830410,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.16312303411479714,\n",
      "    \"compression_rate\": 7.237889642922798,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:06:52,873 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(35, 22), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(70, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:07:05,096 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(35, 22), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(70, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 19:07:19,404 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(64, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(102, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1560922,\n",
      "    \"flops\": 524103446,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.1606610762845179,\n",
      "    \"compression_rate\": 7.163485427202641,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:07:19,450 - MainProcess - INFO - Compressing to:conv1:(2, 32), layer1.0.conv1:(28, 32), layer1.0.conv2:(25, 25), layer1.1.conv1:(22, 32), layer1.1.conv2:(16, 32), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(51, 38), layer3.0.conv1:(70, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:07:31,687 - MainProcess - INFO - finetuning:conv1:(2, 32), layer1.0.conv1:(28, 32), layer1.0.conv2:(25, 25), layer1.1.conv1:(22, 32), layer1.1.conv2:(16, 32), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(51, 38), layer3.0.conv1:(70, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:08:12,016 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 32), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1571645,\n",
      "    \"flops\": 303585610,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.15751638736441384,\n",
      "    \"compression_rate\": 7.11461048773737,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:08:12,034 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(38, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(32, 22), layer1.1.conv2:(16, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:08:24,127 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(38, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(32, 22), layer1.1.conv2:(16, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:08:41,826 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(32, 44), layer1.0.conv2:(32, 22), layer1.1.conv1:(38, 19), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 44), layer2.0.conv2:(57, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1618921,\n",
      "    \"flops\": 385578486,\n",
      "    \"accuracy\": 0.9897,\n",
      "    \"inference_time\": 0.1602707258455313,\n",
      "    \"compression_rate\": 6.90684845029498,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:08:41,881 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(16, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(41, 22), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:08:54,366 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(16, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(41, 22), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1237\n",
      "Epoch 1/3, Loss: 0.1246\n",
      "Epoch 1/3, Loss: 0.1413\n",
      "Epoch 1/3, Loss: 0.1359\n",
      "Epoch 2/3, Loss: 0.0499\n",
      "Epoch 2/3, Loss: 0.0473\n",
      "Epoch 2/3, Loss: 0.0504\n",
      "Epoch 2/3, Loss: 0.0498\n",
      "Epoch 3/3, Loss: 0.0371\n",
      "Epoch 3/3, Loss: 0.0363\n",
      "Epoch 3/3, Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:19:41,325 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(35, 22), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(70, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1550106,\n",
      "    \"flops\": 337706858,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.17300977777776697,\n",
      "    \"compression_rate\": 7.21346927242395,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:19:41,444 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(38, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:19:52,961 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(38, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:20:05,013 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 32), layer1.0.conv1:(28, 32), layer1.0.conv2:(25, 25), layer1.1.conv1:(22, 32), layer1.1.conv2:(16, 32), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(51, 38), layer3.0.conv1:(70, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1605596,\n",
      "    \"flops\": 558973610,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.16030673869349646,\n",
      "    \"compression_rate\": 6.964169068682284,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:20:05,057 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(38, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(57, 57), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:20:17,541 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(38, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(57, 57), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:21:10,924 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(38, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(32, 22), layer1.1.conv2:(16, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1531003,\n",
      "    \"flops\": 325752426,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.1623578208267309,\n",
      "    \"compression_rate\": 7.303474911544916,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:21:10,983 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(28, 25), layer1.0.conv2:(28, 16), layer1.1.conv1:(48, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(38, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 70), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:21:23,308 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(28, 25), layer1.0.conv2:(28, 16), layer1.1.conv1:(48, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(38, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 70), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:21:45,230 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 25), layer1.0.conv1:(16, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(41, 22), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1467004,\n",
      "    \"flops\": 529216890,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.16401755683234795,\n",
      "    \"compression_rate\": 7.622093736622395,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:21:45,284 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 38), layer1.1.conv2:(22, 16), layer2.0.conv1:(41, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 51), layer2.1.conv1:(44, 70), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(179, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:21:45,284 - MainProcess - INFO - Evaluated 20 configurations, found 20 accepted models\n",
      "2025-03-29 19:21:57,517 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 38), layer1.1.conv2:(22, 16), layer2.0.conv1:(41, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 51), layer2.1.conv1:(44, 70), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(179, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1481\n",
      "Epoch 1/3, Loss: 0.1323\n",
      "Epoch 1/3, Loss: 0.1312\n",
      "Epoch 1/3, Loss: 0.1238\n",
      "Epoch 2/3, Loss: 0.0526\n",
      "Epoch 2/3, Loss: 0.0487\n",
      "Epoch 2/3, Loss: 0.0492\n",
      "Epoch 2/3, Loss: 0.0467\n",
      "Epoch 3/3, Loss: 0.0391\n",
      "Epoch 3/3, Loss: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:32:25,234 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(38, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1546558,\n",
      "    \"flops\": 306884682,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.16987207993833375,\n",
      "    \"compression_rate\": 7.230017884877256,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:32:25,348 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 32), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 38), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(115, 64), layer3.0.downsample.0:(76, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:32:36,887 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 32), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 38), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(115, 64), layer3.0.downsample.0:(76, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:32:51,707 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(38, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(57, 57), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1499706,\n",
      "    \"flops\": 724003258,\n",
      "    \"accuracy\": 0.9838,\n",
      "    \"inference_time\": 0.15976186466824477,\n",
      "    \"compression_rate\": 7.455889354313445,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:32:51,777 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 35), layer1.1.conv2:(25, 25), layer2.0.conv1:(25, 51), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:33:03,944 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 35), layer1.1.conv2:(25, 25), layer2.0.conv1:(25, 51), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:34:13,018 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(28, 25), layer1.0.conv2:(28, 16), layer1.1.conv1:(48, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(38, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 70), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1479825,\n",
      "    \"flops\": 543382986,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.16838799717573097,\n",
      "    \"compression_rate\": 7.556056966195327,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:34:13,086 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(25, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(41, 64), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(96, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 179), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:34:25,667 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(25, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(41, 64), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(96, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 179), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:34:48,293 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 38), layer1.1.conv2:(22, 16), layer2.0.conv1:(41, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 51), layer2.1.conv1:(44, 70), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(179, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1643501,\n",
      "    \"flops\": 358857610,\n",
      "    \"accuracy\": 0.9895,\n",
      "    \"inference_time\": 0.1627882453286724,\n",
      "    \"compression_rate\": 6.803550469394299,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:34:48,317 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(22, 38), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(57, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:35:00,714 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(22, 38), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(57, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1363\n",
      "Epoch 1/3, Loss: 0.1339\n",
      "Epoch 1/3, Loss: 0.1286\n",
      "Epoch 1/3, Loss: 0.1512\n",
      "Epoch 2/3, Loss: 0.0501\n",
      "Epoch 2/3, Loss: 0.0491\n",
      "Epoch 2/3, Loss: 0.0481\n",
      "Epoch 2/3, Loss: 0.0526\n",
      "Epoch 3/3, Loss: 0.0372\n",
      "Epoch 3/3, Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:44:52,871 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 32), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 38), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(115, 64), layer3.0.downsample.0:(76, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1562553,\n",
      "    \"flops\": 511433418,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.17010818570535904,\n",
      "    \"compression_rate\": 7.156008148203613,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:44:52,990 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:45:05,434 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:45:18,596 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 28), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 35), layer1.1.conv2:(25, 25), layer2.0.conv1:(25, 51), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1575250,\n",
      "    \"flops\": 498573270,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.15873855542225443,\n",
      "    \"compression_rate\": 7.098328519282654,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:45:18,676 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(32, 54), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(70, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 19:45:30,632 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(32, 54), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(70, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:47:01,009 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(25, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(41, 64), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(96, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 179), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1553998,\n",
      "    \"flops\": 516178186,\n",
      "    \"accuracy\": 0.992,\n",
      "    \"inference_time\": 0.17006833487508655,\n",
      "    \"compression_rate\": 7.195403082886851,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:47:01,049 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 25), layer1.0.conv2:(19, 32), layer1.1.conv1:(28, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:47:13,021 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 25), layer1.0.conv2:(19, 32), layer1.1.conv1:(28, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:47:33,740 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(22, 38), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(57, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1512479,\n",
      "    \"flops\": 521233418,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.16262967368852813,\n",
      "    \"compression_rate\": 7.392923802578416,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 19:47:33,771 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(28, 19), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:47:46,097 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(28, 19), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1283\n",
      "Epoch 1/3, Loss: 0.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:50:03,176 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (19, 16), 'layer1.1.conv2': (16, 22), 'layer2.0.conv1': (16, 44), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (44, 44), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 145.12 MiB is free. Process 3928929 has 37.66 GiB memory in use. Including non-PyTorch memory, this process has 6.09 GiB memory in use. Process 3530538 has 3.62 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:50:03,223 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(35, 48), layer1.1.conv2:(32, 16), layer2.0.conv1:(41, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:50:23,748 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(35, 48), layer1.1.conv2:(32, 16), layer2.0.conv1:(41, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:50:41,799 - MainProcess - ERROR - Error processing config: {'conv1': (2, 25), 'layer1.0.conv1': (19, 19), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (35, 48), 'layer1.1.conv2': (32, 16), 'layer2.0.conv1': (41, 51), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 89), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 13.12 MiB is free. Process 3928929 has 37.92 GiB memory in use. Including non-PyTorch memory, this process has 5.96 GiB memory in use. Process 3530538 has 3.62 GiB memory in use. Of the allocated memory 5.47 GiB is allocated by PyTorch, and 83.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:50:41,799 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (19, 25), 'layer1.0.conv2': (19, 32), 'layer1.1.conv1': (28, 28), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (16, 44), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (51, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 13.12 MiB is free. Process 3928929 has 37.92 GiB memory in use. Including non-PyTorch memory, this process has 5.96 GiB memory in use. Process 3530538 has 3.62 GiB memory in use. Of the allocated memory 5.47 GiB is allocated by PyTorch, and 83.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:50:41,806 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (32, 54), 'layer1.0.conv2': (19, 22), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (32, 44), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (70, 32), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (76, 76), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 13.12 MiB is free. Process 3928929 has 37.92 GiB memory in use. Including non-PyTorch memory, this process has 5.96 GiB memory in use. Process 3530538 has 3.62 GiB memory in use. Of the allocated memory 5.47 GiB is allocated by PyTorch, and 83.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:50:41,909 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 38), layer1.0.conv2:(38, 22), layer1.1.conv1:(44, 22), layer1.1.conv2:(32, 22), layer2.0.conv1:(32, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:50:41,922 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(25, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 28), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(64, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(102, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:50:41,926 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 25), layer1.1.conv2:(19, 41), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 102), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:51:03,098 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 38), layer1.0.conv2:(38, 22), layer1.1.conv1:(44, 22), layer1.1.conv2:(32, 22), layer2.0.conv1:(32, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:51:04,659 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 25), layer1.1.conv2:(19, 41), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 102), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:51:06,178 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(25, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 28), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(64, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(102, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:51:08,753 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (25, 22), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (19, 28), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (64, 44), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (102, 153), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (89, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 25.12 MiB is free. Process 3928929 has 37.97 GiB memory in use. Including non-PyTorch memory, this process has 5.90 GiB memory in use. Process 3530538 has 3.62 GiB memory in use. Of the allocated memory 5.34 GiB is allocated by PyTorch, and 156.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:51:08,768 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (28, 19), 'layer1.0.conv2': (25, 19), 'layer1.1.conv1': (19, 19), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (44, 44), 'layer2.0.downsample.0': (19, 38), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (38, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 39.12 MiB is free. Process 3928929 has 37.97 GiB memory in use. Including non-PyTorch memory, this process has 5.88 GiB memory in use. Process 3530538 has 3.62 GiB memory in use. Of the allocated memory 5.31 GiB is allocated by PyTorch, and 169.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:51:08,787 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(28, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(19, 32), layer1.1.conv2:(38, 28), layer2.0.conv1:(25, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 64), layer2.1.conv2:(38, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 19:51:08,789 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 38), layer1.1.conv1:(22, 28), layer1.1.conv2:(16, 22), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(51, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:51:31,029 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(28, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(19, 32), layer1.1.conv2:(38, 28), layer2.0.conv1:(25, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 64), layer2.1.conv2:(38, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 19:51:31,649 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 38), layer1.1.conv1:(22, 28), layer1.1.conv2:(16, 22), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(51, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:51:36,188 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (25, 25), 'layer1.1.conv2': (19, 41), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (44, 44), 'layer2.0.downsample.0': (25, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (44, 38), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (76, 102), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 17.12 MiB is free. Process 3928929 has 37.97 GiB memory in use. Including non-PyTorch memory, this process has 5.90 GiB memory in use. Process 3530538 has 3.62 GiB memory in use. Of the allocated memory 5.44 GiB is allocated by PyTorch, and 64.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:51:36,195 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (25, 16), 'layer1.0.conv2': (16, 38), 'layer1.1.conv1': (22, 28), 'layer1.1.conv2': (16, 22), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (16, 57), 'layer2.1.conv1': (51, 44), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (44, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 89), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 17.12 MiB is free. Process 3928929 has 37.97 GiB memory in use. Including non-PyTorch memory, this process has 5.90 GiB memory in use. Process 3530538 has 3.62 GiB memory in use. Of the allocated memory 5.44 GiB is allocated by PyTorch, and 64.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:51:36,204 - MainProcess - ERROR - Error processing config: {'conv1': (1, 25), 'layer1.0.conv1': (28, 16), 'layer1.0.conv2': (19, 28), 'layer1.1.conv1': (19, 32), 'layer1.1.conv2': (38, 28), 'layer2.0.conv1': (25, 51), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 64), 'layer2.1.conv2': (38, 57), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (89, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 17.12 MiB is free. Process 3928929 has 37.97 GiB memory in use. Including non-PyTorch memory, this process has 5.90 GiB memory in use. Process 3530538 has 3.62 GiB memory in use. Of the allocated memory 5.44 GiB is allocated by PyTorch, and 64.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:51:36,243 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(48, 28), layer1.0.conv2:(48, 19), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 28), layer2.0.conv1:(22, 38), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 179), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:51:36,266 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(32, 38), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(35, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(51, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:51:36,266 - MainProcess - INFO - Compressing to:conv1:(1, 41), layer1.0.conv1:(22, 19), layer1.0.conv2:(22, 22), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 51), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:51:54,981 - MainProcess - INFO - finetuning:conv1:(1, 41), layer1.0.conv1:(22, 19), layer1.0.conv2:(22, 22), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 51), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:51:55,150 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(32, 38), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(35, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(51, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:51:55,261 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(48, 28), layer1.0.conv2:(48, 19), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 28), layer2.0.conv1:(22, 38), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 179), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:52:04,324 - MainProcess - ERROR - Error processing config: {'conv1': (2, 28), 'layer1.0.conv1': (32, 38), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (22, 16), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (35, 32), 'layer2.0.conv2': (32, 57), 'layer2.0.downsample.0': (25, 32), 'layer2.1.conv1': (38, 51), 'layer2.1.conv2': (51, 38), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (89, 76), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (89, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 23.12 MiB is free. Process 3928929 has 37.97 GiB memory in use. Including non-PyTorch memory, this process has 5.87 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 5.22 GiB is allocated by PyTorch, and 246.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:52:04,341 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(35, 16), layer1.0.conv2:(28, 22), layer1.1.conv1:(19, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(115, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:52:18,461 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(35, 16), layer1.0.conv2:(28, 22), layer1.1.conv1:(19, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(115, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:52:20,924 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (35, 16), 'layer1.0.conv2': (28, 22), 'layer1.1.conv1': (19, 19), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (32, 51), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (32, 44), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (102, 64), 'layer3.0.downsample.0': (44, 89), 'layer3.1.conv1': (115, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 37.97 GiB memory in use. Including non-PyTorch memory, this process has 5.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 5.37 GiB is allocated by PyTorch, and 104.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:52:20,930 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (48, 28), 'layer1.0.conv2': (48, 19), 'layer1.1.conv1': (32, 16), 'layer1.1.conv2': (19, 28), 'layer2.0.conv1': (22, 38), 'layer2.0.conv2': (64, 32), 'layer2.0.downsample.0': (19, 44), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 179), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 37.97 GiB memory in use. Including non-PyTorch memory, this process has 5.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 5.38 GiB is allocated by PyTorch, and 103.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:52:20,935 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (19, 38), 'layer1.0.conv2': (38, 22), 'layer1.1.conv1': (44, 22), 'layer1.1.conv2': (32, 22), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (51, 32), 'layer2.0.downsample.0': (32, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 153), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 37.97 GiB memory in use. Including non-PyTorch memory, this process has 5.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 5.38 GiB is allocated by PyTorch, and 97.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:52:20,961 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 44), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 16), layer2.0.conv1:(25, 51), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:52:20,965 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 22), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:52:21,024 - MainProcess - INFO - Compressing to:conv1:(2, 32), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(48, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:52:32,128 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 44), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 16), layer2.0.conv1:(25, 51), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:52:32,667 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 22), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:52:32,735 - MainProcess - INFO - finetuning:conv1:(2, 32), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(48, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:53:57,086 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 19), 'layer1.0.conv2': (19, 44), 'layer1.1.conv1': (19, 16), 'layer1.1.conv2': (28, 16), 'layer2.0.conv1': (25, 51), 'layer2.0.conv2': (38, 44), 'layer2.0.downsample.0': (35, 38), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (51, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (89, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 102), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 3.12 MiB is free. Process 3928929 has 38.39 GiB memory in use. Including non-PyTorch memory, this process has 5.46 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.85 GiB is allocated by PyTorch, and 212.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:53:57,100 - MainProcess - ERROR - Error processing config: {'conv1': (2, 32), 'layer1.0.conv1': (19, 19), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (48, 38), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (25, 38), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (38, 38), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 17.12 MiB is free. Process 3928929 has 38.39 GiB memory in use. Including non-PyTorch memory, this process has 5.45 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.86 GiB is allocated by PyTorch, and 191.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:53:57,161 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(38, 16), layer1.1.conv1:(22, 19), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(102, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:53:57,173 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 70), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:54:08,305 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 70), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 19:54:08,653 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(38, 16), layer1.1.conv1:(22, 19), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(102, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 19:55:39,067 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (16, 22), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (22, 22), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (32, 44), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (51, 76), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.91 GiB is allocated by PyTorch, and 104.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:55:39,072 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (38, 16), 'layer1.1.conv1': (22, 19), 'layer1.1.conv2': (16, 22), 'layer2.0.conv1': (22, 38), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (25, 38), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (102, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.91 GiB is allocated by PyTorch, and 104.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:55:39,135 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(28, 28), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 70), layer2.1.conv2:(83, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:55:39,136 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(19, 22), layer1.0.conv2:(22, 28), layer1.1.conv1:(32, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(76, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 70), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-29 19:55:50,810 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(19, 22), layer1.0.conv2:(22, 28), layer1.1.conv1:(32, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(76, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 70), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-29 19:55:51,147 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(28, 28), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 70), layer2.1.conv2:(83, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:55:51,403 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (28, 28), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (19, 19), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (28, 38), 'layer2.1.conv1': (32, 70), 'layer2.1.conv2': (83, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.89 GiB is allocated by PyTorch, and 118.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:55:51,409 - MainProcess - ERROR - Error processing config: {'conv1': (1, 41), 'layer1.0.conv1': (22, 19), 'layer1.0.conv2': (22, 22), 'layer1.1.conv1': (22, 16), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (16, 51), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (38, 32), 'layer2.1.conv1': (44, 32), 'layer2.1.conv2': (32, 57), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (89, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 153)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.91 GiB is allocated by PyTorch, and 102.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:55:51,458 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(28, 35), layer1.1.conv1:(22, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(38, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:55:51,462 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(22, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 25), layer1.1.conv2:(22, 28), layer2.0.conv1:(28, 32), layer2.0.conv2:(38, 64), layer2.0.downsample.0:(38, 64), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:56:02,913 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(28, 35), layer1.1.conv1:(22, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(38, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:56:03,419 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(22, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 25), layer1.1.conv2:(22, 28), layer2.0.conv1:(28, 32), layer2.0.conv2:(38, 64), layer2.0.downsample.0:(38, 64), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:56:03,764 - MainProcess - ERROR - Error processing config: {'conv1': (1, 25), 'layer1.0.conv1': (19, 22), 'layer1.0.conv2': (22, 28), 'layer1.1.conv1': (32, 25), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (16, 38), 'layer2.0.conv2': (76, 51), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 70), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (89, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (179, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 15.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.40 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.82 GiB is allocated by PyTorch, and 181.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:56:03,791 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 25), layer1.1.conv2:(41, 16), layer2.0.conv1:(41, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 19:56:16,949 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 25), layer1.1.conv2:(41, 16), layer2.0.conv1:(41, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 19:56:21,101 - MainProcess - ERROR - Error processing config: {'conv1': (2, 25), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (22, 25), 'layer1.1.conv2': (22, 28), 'layer2.0.conv1': (28, 32), 'layer2.0.conv2': (38, 64), 'layer2.0.downsample.0': (38, 64), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 89), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (89, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 27.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.39 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.74 GiB is allocated by PyTorch, and 252.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:56:21,149 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 28), layer1.0.conv2:(32, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 179), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 179), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 19:56:34,172 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 28), layer1.0.conv2:(32, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 179), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 179), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 19:56:43,116 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (22, 28), 'layer1.0.conv2': (32, 25), 'layer1.1.conv1': (25, 16), 'layer1.1.conv2': (25, 16), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (38, 76), 'layer3.0.conv2': (89, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 179), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 179), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 25.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.39 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.89 GiB is allocated by PyTorch, and 97.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:56:43,122 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (19, 25), 'layer1.0.conv2': (28, 35), 'layer1.1.conv1': (22, 22), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (38, 38), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (32, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (102, 64), 'layer3.0.downsample.0': (51, 76), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 25.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.39 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.88 GiB is allocated by PyTorch, and 113.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:56:43,130 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (16, 19), 'layer1.1.conv1': (22, 16), 'layer1.1.conv2': (22, 25), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 70), 'layer2.0.downsample.0': (32, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (51, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 153)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 49.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.37 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.87 GiB is allocated by PyTorch, and 97.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:56:43,171 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 19), layer1.0.conv2:(28, 25), layer1.1.conv1:(25, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 51), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:56:43,172 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(28, 51), layer1.0.conv2:(48, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(48, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 19:56:43,177 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(28, 19), layer1.1.conv1:(25, 28), layer1.1.conv2:(41, 57), layer2.0.conv1:(28, 70), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:56:54,400 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 19), layer1.0.conv2:(28, 25), layer1.1.conv1:(25, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 51), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:56:54,895 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(28, 51), layer1.0.conv2:(48, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(48, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 19:56:54,924 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(28, 19), layer1.1.conv1:(25, 28), layer1.1.conv2:(41, 57), layer2.0.conv1:(28, 70), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:56:55,149 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (19, 19), 'layer1.0.conv2': (28, 25), 'layer1.1.conv1': (25, 22), 'layer1.1.conv2': (25, 22), 'layer2.0.conv1': (19, 44), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (28, 51), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (57, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 5.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.88 GiB is allocated by PyTorch, and 127.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:56:55,155 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (28, 19), 'layer1.1.conv1': (25, 28), 'layer1.1.conv2': (41, 57), 'layer2.0.conv1': (28, 70), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (38, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (44, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (57, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 5.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.88 GiB is allocated by PyTorch, and 127.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:56:55,164 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (28, 51), 'layer1.0.conv2': (48, 16), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (48, 38), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 51), 'layer2.0.downsample.0': (16, 44), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (44, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.87 GiB is allocated by PyTorch, and 132.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:56:55,261 - MainProcess - INFO - Compressing to:conv1:(2, 35), layer1.0.conv1:(22, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 22), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 51), layer2.1.conv2:(44, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:56:55,261 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:56:55,272 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 35), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(76, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:57:06,682 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:57:06,766 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 35), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(76, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:57:07,059 - MainProcess - INFO - finetuning:conv1:(2, 35), layer1.0.conv1:(22, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 22), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 51), layer2.1.conv2:(44, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:57:28,530 - MainProcess - ERROR - Error processing config: {'conv1': (2, 25), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (22, 16), 'layer1.1.conv2': (16, 38), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (19, 38), 'layer2.1.conv1': (44, 32), 'layer2.1.conv2': (32, 51), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 23.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.39 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.82 GiB is allocated by PyTorch, and 170.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:57:28,536 - MainProcess - ERROR - Error processing config: {'conv1': (2, 35), 'layer1.0.conv1': (22, 28), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (19, 25), 'layer1.1.conv2': (22, 22), 'layer2.0.conv1': (35, 38), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (19, 44), 'layer2.1.conv1': (32, 51), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (57, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.84 GiB is allocated by PyTorch, and 164.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:57:28,544 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (16, 35), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (76, 32), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (38, 76), 'layer3.0.conv2': (89, 76), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 89), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 38.44 GiB memory in use. Including non-PyTorch memory, this process has 5.41 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.85 GiB is allocated by PyTorch, and 162.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:57:28,619 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(25, 28), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 32), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(64, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 102), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:57:28,632 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(41, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:57:28,637 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(32, 25), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:57:39,308 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(25, 28), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 32), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(64, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 102), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:57:40,207 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(41, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:57:40,433 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(32, 25), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:58:26,322 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (22, 25), 'layer1.1.conv2': (41, 16), 'layer2.0.conv1': (41, 32), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (25, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (38, 38), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (89, 76), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 38.57 GiB memory in use. Including non-PyTorch memory, this process has 5.28 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.78 GiB is allocated by PyTorch, and 105.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:58:26,323 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (22, 22), 'layer1.0.conv2': (25, 28), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (25, 32), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (64, 44), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (76, 102), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (179, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 25.12 MiB is free. Process 3928929 has 38.57 GiB memory in use. Including non-PyTorch memory, this process has 5.27 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.76 GiB is allocated by PyTorch, and 110.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:58:26,328 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (25, 16), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (41, 44), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (51, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 38.57 GiB memory in use. Including non-PyTorch memory, this process has 5.28 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.79 GiB is allocated by PyTorch, and 89.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 19:58:26,402 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 28), layer2.0.conv1:(16, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 179), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:58:26,405 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 32), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:58:26,413 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(32, 25), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 32), layer1.1.conv2:(16, 38), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:58:37,918 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 32), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:58:38,572 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 28), layer2.0.conv1:(16, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 179), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 19:58:39,262 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(32, 25), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 32), layer1.1.conv2:(16, 38), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1257\n",
      "Epoch 1/3, Loss: 0.1617\n",
      "Epoch 1/3, Loss: 0.1317\n",
      "Epoch 1/3, Loss: 0.1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:02:50,544 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (22, 25), 'layer1.0.conv2': (16, 32), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (51, 38), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (44, 44), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 179), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 27.12 MiB is free. Process 3928929 has 38.88 GiB memory in use. Including non-PyTorch memory, this process has 4.95 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.41 GiB is allocated by PyTorch, and 140.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 20:02:50,554 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (16, 25), 'layer1.0.conv2': (32, 25), 'layer1.1.conv1': (16, 28), 'layer1.1.conv2': (19, 22), 'layer2.0.conv1': (22, 38), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 11.12 MiB is free. Process 3928929 has 38.88 GiB memory in use. Including non-PyTorch memory, this process has 4.96 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.42 GiB is allocated by PyTorch, and 144.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 20:02:50,590 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 35), layer1.0.conv2:(25, 22), layer1.1.conv1:(41, 38), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(57, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:02:50,594 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(22, 28), layer1.1.conv1:(35, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 20:03:01,778 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(22, 28), layer1.1.conv1:(35, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 20:03:02,410 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 35), layer1.0.conv2:(25, 22), layer1.1.conv1:(41, 38), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(57, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:03:42,658 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (19, 25), 'layer1.0.conv2': (22, 28), 'layer1.1.conv1': (35, 22), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (28, 32), 'layer2.1.conv1': (32, 51), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 38.88 GiB memory in use. Including non-PyTorch memory, this process has 4.97 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.22 GiB is allocated by PyTorch, and 354.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 20:03:42,678 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:03:55,589 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:03:55,866 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (16, 35), 'layer1.0.conv2': (25, 22), 'layer1.1.conv1': (41, 38), 'layer1.1.conv2': (25, 22), 'layer2.0.conv1': (16, 38), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (25, 38), 'layer2.1.conv1': (57, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 19.12 MiB is free. Process 3928929 has 38.88 GiB memory in use. Including non-PyTorch memory, this process has 4.96 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 155.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 20:03:55,913 - MainProcess - INFO - Compressing to:conv1:(2, 32), layer1.0.conv1:(38, 16), layer1.0.conv2:(16, 35), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:04:08,573 - MainProcess - INFO - finetuning:conv1:(2, 32), layer1.0.conv1:(38, 16), layer1.0.conv2:(16, 35), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:05:47,855 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (25, 16), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (32, 44), 'layer2.1.conv2': (51, 32), 'layer3.0.conv1': (32, 89), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 89), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 38.88 GiB memory in use. Including non-PyTorch memory, this process has 4.97 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.44 GiB is allocated by PyTorch, and 132.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-29 20:05:47,863 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:06:00,828 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1350\n",
      "Epoch 3/3, Loss: 0.0407\n",
      "Epoch 3/3, Loss: 0.0366\n",
      "Epoch 1/3, Loss: 0.1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:11:30,249 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 28), layer2.0.conv1:(16, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 179), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1562274,\n",
      "    \"flops\": 626184558,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.17086516924977554,\n",
      "    \"compression_rate\": 7.15728610986293,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:11:30,297 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(35, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:11:40,922 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(32, 25), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 32), layer1.1.conv2:(16, 38), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1554270,\n",
      "    \"flops\": 738138043,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.1670966209120052,\n",
      "    \"compression_rate\": 7.19414387461638,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:11:41,004 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 35), layer1.1.conv1:(32, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:11:41,004 - MainProcess - INFO - Evaluated 30 configurations, found 30 accepted models\n",
      "2025-03-29 20:11:41,985 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(35, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:11:53,414 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 35), layer1.1.conv1:(32, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0529\n",
      "Epoch 3/3, Loss: 0.0370\n",
      "Epoch 1/3, Loss: 0.1303\n",
      "Epoch 1/3, Loss: 0.1271\n",
      "Epoch 3/3, Loss: 0.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:17:20,139 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 32), layer1.0.conv1:(38, 16), layer1.0.conv2:(16, 35), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1500590,\n",
      "    \"flops\": 513979850,\n",
      "    \"accuracy\": 0.9899,\n",
      "    \"inference_time\": 0.16930242809773502,\n",
      "    \"compression_rate\": 7.451497077816059,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:17:20,246 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(16, 25), layer1.0.conv2:(19, 16), layer1.1.conv1:(41, 16), layer1.1.conv2:(54, 28), layer2.0.conv1:(22, 57), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:17:32,857 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(16, 25), layer1.0.conv2:(19, 16), layer1.1.conv1:(41, 16), layer1.1.conv2:(54, 28), layer2.0.conv1:(22, 57), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:18:55,520 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1443525,\n",
      "    \"flops\": 480763338,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.1674031269778112,\n",
      "    \"compression_rate\": 7.746067439081416,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:18:55,587 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(35, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 28), layer2.0.conv1:(41, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:19:08,459 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(35, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 28), layer2.0.conv1:(41, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0477\n",
      "Epoch 1/3, Loss: 0.1346\n",
      "Epoch 3/3, Loss: 0.0359\n",
      "Epoch 1/3, Loss: 0.1347\n",
      "Epoch 3/3, Loss: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:24:17,904 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(35, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1565742,\n",
      "    \"flops\": 316583546,\n",
      "    \"accuracy\": 0.9893,\n",
      "    \"inference_time\": 0.17091495418751065,\n",
      "    \"compression_rate\": 7.1414332629513675,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:24:18,025 - MainProcess - INFO - Compressing to:conv1:(2, 32), layer1.0.conv1:(35, 16), layer1.0.conv2:(28, 32), layer1.1.conv1:(32, 32), layer1.1.conv2:(28, 19), layer2.0.conv1:(54, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:24:30,459 - MainProcess - INFO - finetuning:conv1:(2, 32), layer1.0.conv1:(35, 16), layer1.0.conv2:(28, 32), layer1.1.conv1:(32, 32), layer1.1.conv2:(28, 19), layer2.0.conv1:(54, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 20:24:38,767 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 35), layer1.1.conv1:(32, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1508579,\n",
      "    \"flops\": 316483978,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.16699573290069644,\n",
      "    \"compression_rate\": 7.412036094894599,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:24:38,813 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:24:50,475 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0489\n",
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 1/3, Loss: 0.1208\n",
      "Epoch 1/3, Loss: 0.1336\n",
      "Epoch 3/3, Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:30:19,918 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 25), layer1.0.conv1:(16, 25), layer1.0.conv2:(19, 16), layer1.1.conv1:(41, 16), layer1.1.conv2:(54, 28), layer2.0.conv1:(22, 57), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1511776,\n",
      "    \"flops\": 555630634,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.17217799204929618,\n",
      "    \"compression_rate\": 7.396361630294435,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:30:20,000 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(25, 19), layer1.1.conv2:(25, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:30:31,928 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(25, 19), layer1.1.conv2:(25, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:31:43,662 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(35, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 28), layer2.0.conv1:(41, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1543662,\n",
      "    \"flops\": 320095082,\n",
      "    \"accuracy\": 0.9899,\n",
      "    \"inference_time\": 0.16667612849274005,\n",
      "    \"compression_rate\": 7.243581820372595,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:31:43,713 - MainProcess - INFO - Compressing to:conv1:(2, 38), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 32), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 64), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:31:56,355 - MainProcess - INFO - finetuning:conv1:(2, 38), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 32), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 64), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0492\n",
      "Epoch 1/3, Loss: 0.1265\n",
      "Epoch 3/3, Loss: 0.0358\n",
      "Epoch 1/3, Loss: 0.1297\n",
      "Epoch 3/3, Loss: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:37:29,518 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 32), layer1.0.conv1:(35, 16), layer1.0.conv2:(28, 32), layer1.1.conv1:(32, 32), layer1.1.conv2:(28, 19), layer2.0.conv1:(54, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1589007,\n",
      "    \"flops\": 368094698,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.1825894615958957,\n",
      "    \"compression_rate\": 7.03687397223549,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:37:29,619 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(16, 28), layer1.0.conv2:(19, 22), layer1.1.conv1:(25, 35), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:37:42,354 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(16, 28), layer1.0.conv2:(19, 22), layer1.1.conv1:(25, 35), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:37:51,969 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1545975,\n",
      "    \"flops\": 369510602,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.17504429412242462,\n",
      "    \"compression_rate\": 7.232744384611653,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:37:52,017 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 35), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 22), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(102, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:38:04,421 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 35), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 22), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(102, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0501\n",
      "Epoch 1/3, Loss: 0.1326\n",
      "Epoch 3/3, Loss: 0.0371\n",
      "Epoch 1/3, Loss: 0.1249\n",
      "Epoch 3/3, Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:43:17,215 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(25, 19), layer1.1.conv2:(25, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1462954,\n",
      "    \"flops\": 502894090,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.18100405549294374,\n",
      "    \"compression_rate\": 7.643194522862647,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:43:17,284 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 76), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(96, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(153, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=76, which is larger than max(matrix.shape)=64. Setting n_eigenvecs to 64.\n",
      "  warnings.warn(\n",
      "2025-03-29 20:43:30,380 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 76), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(96, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(153, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:44:37,771 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 38), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 32), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 64), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1494852,\n",
      "    \"flops\": 531927510,\n",
      "    \"accuracy\": 0.9896,\n",
      "    \"inference_time\": 0.167282294315897,\n",
      "    \"compression_rate\": 7.480099702177874,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:44:37,803 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 28), layer1.0.conv2:(19, 22), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(32, 38), layer2.0.conv2:(64, 44), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-29 20:44:37,803 - MainProcess - INFO - Evaluated 40 configurations, found 40 accepted models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:44:50,888 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 28), layer1.0.conv2:(19, 22), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(32, 38), layer2.0.conv2:(64, 44), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0479\n",
      "Epoch 1/3, Loss: 0.1111\n",
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 1/3, Loss: 0.1303\n",
      "Epoch 3/3, Loss: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:50:30,738 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(16, 28), layer1.0.conv2:(19, 22), layer1.1.conv1:(25, 35), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1474649,\n",
      "    \"flops\": 482998522,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.17222954766259324,\n",
      "    \"compression_rate\": 7.582578633966456,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:50:30,792 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(54, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 32), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 20:50:42,776 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(54, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 32), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:51:00,106 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 35), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 22), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(102, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1657494,\n",
      "    \"flops\": 329552621,\n",
      "    \"accuracy\": 0.9921,\n",
      "    \"inference_time\": 0.167951159163392,\n",
      "    \"compression_rate\": 6.746113108101749,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:51:00,185 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 28), layer1.0.conv2:(35, 35), layer1.1.conv1:(16, 25), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(32, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 20:51:12,787 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 28), layer1.0.conv2:(35, 35), layer1.1.conv1:(16, 25), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(32, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0493\n",
      "Epoch 1/3, Loss: 0.1254\n",
      "Epoch 3/3, Loss: 0.0341\n",
      "Epoch 1/3, Loss: 0.1299\n",
      "Epoch 3/3, Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:56:31,987 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 76), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(96, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(153, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1635838,\n",
      "    \"flops\": 316976575,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.18017222825635515,\n",
      "    \"compression_rate\": 6.835421355904436,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:56:32,080 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(35, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 57), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 102), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:56:44,315 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(35, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 57), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 102), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 20:57:36,702 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 28), layer1.0.conv2:(19, 22), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(32, 38), layer2.0.conv2:(64, 44), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\",\n",
      "    \"params\": 1575888,\n",
      "    \"flops\": 322972019,\n",
      "    \"accuracy\": 0.9918,\n",
      "    \"inference_time\": 0.16760497994230558,\n",
      "    \"compression_rate\": 7.095454753129664,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 20:57:36,749 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(28, 25), layer2.0.conv1:(35, 32), layer2.0.conv2:(64, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(57, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(89, 89), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 20:57:49,601 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(28, 25), layer2.0.conv1:(35, 32), layer2.0.conv2:(64, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(57, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(89, 89), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0485\n",
      "Epoch 1/3, Loss: 0.1384\n",
      "Epoch 3/3, Loss: 0.0376\n",
      "Epoch 1/3, Loss: 0.1204\n",
      "Epoch 3/3, Loss: 0.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:03:11,930 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 28), layer1.0.conv1:(54, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 32), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1605950,\n",
      "    \"flops\": 437268586,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.1697429709626864,\n",
      "    \"compression_rate\": 6.9626339549799185,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:03:12,022 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 28), layer1.1.conv2:(25, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:03:24,125 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 28), layer1.1.conv2:(25, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:03:54,377 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(16, 28), layer1.0.conv2:(35, 35), layer1.1.conv1:(16, 25), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(32, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1557898,\n",
      "    \"flops\": 350580138,\n",
      "    \"accuracy\": 0.9882,\n",
      "    \"inference_time\": 0.1668327679806201,\n",
      "    \"compression_rate\": 7.177390304114904,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:03:54,461 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(51, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:04:06,821 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(51, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0471\n",
      "Epoch 1/3, Loss: 0.1370\n",
      "Epoch 3/3, Loss: 0.0381\n",
      "Epoch 1/3, Loss: 0.1345\n",
      "Epoch 3/3, Loss: 0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:09:51,883 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(35, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 57), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 102), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1538260,\n",
      "    \"flops\": 515924170,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.1796295880765166,\n",
      "    \"compression_rate\": 7.269019541559945,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:09:52,014 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n",
      "2025-03-29 21:10:04,469 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n",
      "2025-03-29 21:10:43,666 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(28, 25), layer2.0.conv1:(35, 32), layer2.0.conv2:(64, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(57, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(89, 89), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1562200,\n",
      "    \"flops\": 341470254,\n",
      "    \"accuracy\": 0.9916,\n",
      "    \"inference_time\": 0.16817785372399982,\n",
      "    \"compression_rate\": 7.157625144027653,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:10:43,702 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(28, 22), layer1.0.conv2:(32, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(16, 38), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 70), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(64, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(89, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:10:55,405 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(28, 22), layer1.0.conv2:(32, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(16, 38), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 70), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(64, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(89, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0512\n",
      "Epoch 1/3, Loss: 0.1272\n",
      "Epoch 3/3, Loss: 0.0375\n",
      "Epoch 1/3, Loss: 0.1388\n",
      "Epoch 3/3, Loss: 0.0389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:15:54,141 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 28), layer1.1.conv2:(25, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1493430,\n",
      "    \"flops\": 461094346,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.17051124572753906,\n",
      "    \"compression_rate\": 7.48722203250236,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:15:54,226 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(22, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(44, 28), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 57), layer3.0.conv1:(70, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 21:16:06,714 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(22, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(44, 28), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 57), layer3.0.conv1:(70, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 21:16:52,875 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(51, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1497448,\n",
      "    \"flops\": 308832138,\n",
      "    \"accuracy\": 0.9894,\n",
      "    \"inference_time\": 0.16532140223590178,\n",
      "    \"compression_rate\": 7.46713208071332,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:16:52,935 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(28, 16), layer1.1.conv1:(38, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(204, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:16:52,935 - MainProcess - INFO - Evaluated 50 configurations, found 50 accepted models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:17:04,989 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(28, 16), layer1.1.conv1:(38, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(204, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0507\n",
      "Epoch 1/3, Loss: 0.1185\n",
      "Epoch 3/3, Loss: 0.0361\n",
      "Epoch 1/3, Loss: 0.1312\n",
      "Epoch 3/3, Loss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:22:56,255 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\",\n",
      "    \"params\": 1577673,\n",
      "    \"flops\": 485319946,\n",
      "    \"accuracy\": 0.989,\n",
      "    \"inference_time\": 0.18058643978872116,\n",
      "    \"compression_rate\": 7.087426862220498,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:22:56,347 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 32), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:23:08,306 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 32), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:23:26,822 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(28, 22), layer1.0.conv2:(32, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(16, 38), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 70), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(64, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(89, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1595377,\n",
      "    \"flops\": 366056298,\n",
      "    \"accuracy\": 0.9896,\n",
      "    \"inference_time\": 0.16799905851894628,\n",
      "    \"compression_rate\": 7.008777235725474,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:23:26,881 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(22, 41), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:23:39,305 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(22, 41), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0493\n",
      "Epoch 1/3, Loss: 0.1330\n",
      "Epoch 3/3, Loss: 0.0363\n",
      "Epoch 1/3, Loss: 0.1297\n",
      "Epoch 3/3, Loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:29:03,022 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(22, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(44, 28), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 57), layer3.0.conv1:(70, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1583529,\n",
      "    \"flops\": 553972866,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.16821342162518996,\n",
      "    \"compression_rate\": 7.061217066438316,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:29:03,152 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(25, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 28), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:29:15,687 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(25, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 28), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:30:09,283 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(28, 16), layer1.1.conv1:(38, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(204, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1653722,\n",
      "    \"flops\": 507148662,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.1653425470785477,\n",
      "    \"compression_rate\": 6.7615004214735,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:30:09,377 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(16, 57), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:30:21,685 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(16, 57), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0487\n",
      "Epoch 2/3, Loss: 0.0491\n",
      "Epoch 1/3, Loss: 0.1355\n",
      "Epoch 1/3, Loss: 0.1264\n",
      "Epoch 3/3, Loss: 0.0371\n",
      "Epoch 3/3, Loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:35:56,692 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 32), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1494321,\n",
      "    \"flops\": 495591914,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.18005932162015556,\n",
      "    \"compression_rate\": 7.482757720730686,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:35:56,808 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(35, 25), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:36:09,625 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(35, 25), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:36:09,928 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(22, 41), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1477245,\n",
      "    \"flops\": 515191914,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.16802413144688697,\n",
      "    \"compression_rate\": 7.569253576759441,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:36:09,990 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(32, 35), layer1.0.conv2:(25, 35), layer1.1.conv1:(35, 35), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:36:22,347 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(32, 35), layer1.0.conv2:(25, 35), layer1.1.conv1:(35, 35), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0495\n",
      "Epoch 3/3, Loss: 0.0370\n",
      "Epoch 1/3, Loss: 0.1387\n",
      "Epoch 1/3, Loss: 0.1195\n",
      "Epoch 3/3, Loss: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:41:40,887 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(25, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 28), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1560832,\n",
      "    \"flops\": 313287414,\n",
      "    \"accuracy\": 0.9916,\n",
      "    \"inference_time\": 0.17076528198906316,\n",
      "    \"compression_rate\": 7.163898484910612,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:41:40,968 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(32, 57), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(51, 64), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 115), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:41:53,263 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(32, 57), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(51, 64), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 115), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:42:56,725 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(16, 57), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1510344,\n",
      "    \"flops\": 309921506,\n",
      "    \"accuracy\": 0.9894,\n",
      "    \"inference_time\": 0.16637033413929544,\n",
      "    \"compression_rate\": 7.403374330616072,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:42:56,767 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(19, 16), layer1.1.conv2:(25, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 70), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 21:43:09,081 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(19, 16), layer1.1.conv2:(25, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 70), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0490\n",
      "Epoch 2/3, Loss: 0.0471\n",
      "Epoch 1/3, Loss: 0.1269\n",
      "Epoch 1/3, Loss: 0.1370\n",
      "Epoch 3/3, Loss: 0.0370\n",
      "Epoch 3/3, Loss: 0.0357\n",
      "Epoch 2/3, Loss: 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:49:14,994 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(35, 25), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1515303,\n",
      "    \"flops\": 324930794,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.18114865762666024,\n",
      "    \"compression_rate\": 7.379145952987621,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:49:15,063 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(25, 25), layer1.0.conv2:(22, 41), layer1.1.conv1:(32, 22), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:49:17,655 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(32, 35), layer1.0.conv2:(25, 35), layer1.1.conv1:(35, 35), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1503346,\n",
      "    \"flops\": 775635146,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.1734551097683593,\n",
      "    \"compression_rate\": 7.437836665677762,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:49:17,728 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(32, 38), layer1.1.conv2:(25, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:49:17,728 - MainProcess - INFO - Evaluated 60 configurations, found 60 accepted models\n",
      "2025-03-29 21:49:26,670 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(25, 25), layer1.0.conv2:(22, 41), layer1.1.conv1:(32, 22), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:49:29,128 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(32, 38), layer1.1.conv2:(25, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0510\n",
      "Epoch 3/3, Loss: 0.0357\n",
      "Epoch 1/3, Loss: 0.1456\n",
      "Epoch 1/3, Loss: 0.1276\n",
      "Epoch 3/3, Loss: 0.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:54:15,921 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(32, 57), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(51, 64), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 115), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1584678,\n",
      "    \"flops\": 331923290,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.16962507474700864,\n",
      "    \"compression_rate\": 7.056097200819346,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:54:16,021 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(25, 16), layer1.0.conv2:(38, 16), layer1.1.conv1:(41, 16), layer1.1.conv2:(19, 35), layer2.0.conv1:(28, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 57), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 21:54:27,897 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(25, 16), layer1.0.conv2:(38, 16), layer1.1.conv1:(41, 16), layer1.1.conv2:(19, 35), layer2.0.conv1:(28, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 57), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 21:55:45,619 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(19, 16), layer1.1.conv2:(25, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 70), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1533705,\n",
      "    \"flops\": 296335178,\n",
      "    \"accuracy\": 0.9891,\n",
      "    \"inference_time\": 0.16982275462707389,\n",
      "    \"compression_rate\": 7.290608037399631,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 21:55:45,666 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(38, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 21:55:58,700 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(38, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0528\n",
      "Epoch 2/3, Loss: 0.0478\n",
      "Epoch 1/3, Loss: 0.1232\n",
      "Epoch 1/3, Loss: 0.1436\n",
      "Epoch 3/3, Loss: 0.0399\n",
      "Epoch 3/3, Loss: 0.0372\n",
      "Epoch 2/3, Loss: 0.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:02:10,921 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(32, 38), layer1.1.conv2:(25, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1447254,\n",
      "    \"flops\": 314295050,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.1746376932553172,\n",
      "    \"compression_rate\": 7.726108893117587,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:02:11,019 - MainProcess - INFO - Compressing to:conv1:(2, 32), layer1.0.conv1:(41, 19), layer1.0.conv2:(22, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(76, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:02:21,493 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(25, 25), layer1.0.conv2:(22, 41), layer1.1.conv1:(32, 22), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1514620,\n",
      "    \"flops\": 346887498,\n",
      "    \"accuracy\": 0.9925,\n",
      "    \"inference_time\": 0.17786826905171582,\n",
      "    \"compression_rate\": 7.382473491700889,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:02:21,543 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(19, 28), layer1.0.conv2:(25, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(22, 32), layer2.0.conv1:(38, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 22:02:23,556 - MainProcess - INFO - finetuning:conv1:(2, 32), layer1.0.conv1:(41, 19), layer1.0.conv2:(22, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(76, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:02:33,357 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(19, 28), layer1.0.conv2:(25, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(22, 32), layer2.0.conv1:(38, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0510\n",
      "Epoch 3/3, Loss: 0.0366\n",
      "Epoch 1/3, Loss: 0.1188\n",
      "Epoch 1/3, Loss: 0.1239\n",
      "Epoch 3/3, Loss: 0.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:07:11,766 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 28), layer1.0.conv1:(25, 16), layer1.0.conv2:(38, 16), layer1.1.conv1:(41, 16), layer1.1.conv2:(19, 35), layer2.0.conv1:(28, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 57), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1577086,\n",
      "    \"flops\": 511944586,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.16687110680177208,\n",
      "    \"compression_rate\": 7.090064841105685,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:07:11,880 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(25, 19), layer1.0.conv2:(32, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(64, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:07:24,246 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(25, 19), layer1.0.conv2:(32, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(64, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:08:55,490 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(38, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1474268,\n",
      "    \"flops\": 310378186,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.16786781339382162,\n",
      "    \"compression_rate\": 7.584538225071697,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:08:55,539 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 54), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 128), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:09:08,289 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 54), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 128), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0470\n",
      "Epoch 2/3, Loss: 0.0482\n",
      "Epoch 1/3, Loss: 0.1360\n",
      "Epoch 1/3, Loss: 0.1314\n",
      "Epoch 3/3, Loss: 0.0359\n",
      "Epoch 3/3, Loss: 0.0363\n",
      "Epoch 2/3, Loss: 0.0488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:14:51,283 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 32), layer1.0.conv1:(41, 19), layer1.0.conv2:(22, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(76, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1587226,\n",
      "    \"flops\": 537661354,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.17330743704631826,\n",
      "    \"compression_rate\": 7.044769931944159,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:14:51,385 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(32, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 51), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:15:03,987 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(32, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 51), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:15:20,727 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(19, 28), layer1.0.conv2:(25, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(22, 32), layer2.0.conv1:(38, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1578847,\n",
      "    \"flops\": 537717802,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.17690472845818586,\n",
      "    \"compression_rate\": 7.082156789099894,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:15:20,790 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:15:33,434 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0507\n",
      "Epoch 3/3, Loss: 0.0372\n",
      "Epoch 1/3, Loss: 0.1356\n",
      "Epoch 1/3, Loss: 0.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:19:55,798 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(25, 19), layer1.0.conv2:(32, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(64, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1490242,\n",
      "    \"flops\": 508002634,\n",
      "    \"accuracy\": 0.989,\n",
      "    \"inference_time\": 0.1684075576231485,\n",
      "    \"compression_rate\": 7.503239071238094,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:19:55,926 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(22, 28), layer1.1.conv2:(19, 19), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:20:08,149 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(22, 28), layer1.1.conv2:(19, 19), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:21:47,321 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 54), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 128), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1594230,\n",
      "    \"flops\": 329526602,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.17125405424972504,\n",
      "    \"compression_rate\": 7.01381983779003,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:21:47,390 - MainProcess - INFO - Compressing to:conv1:(2, 32), layer1.0.conv1:(22, 32), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(28, 19), layer2.0.conv1:(32, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 51), layer3.0.conv1:(64, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(115, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 22:21:47,390 - MainProcess - INFO - Evaluated 70 configurations, found 70 accepted models\n",
      "2025-03-29 22:22:00,030 - MainProcess - INFO - finetuning:conv1:(2, 32), layer1.0.conv1:(22, 32), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(28, 19), layer2.0.conv1:(32, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 51), layer3.0.conv1:(64, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(115, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0496\n",
      "Epoch 2/3, Loss: 0.0491\n",
      "Epoch 1/3, Loss: 0.1391\n",
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 1/3, Loss: 0.1222\n",
      "Epoch 3/3, Loss: 0.0364\n",
      "Epoch 2/3, Loss: 0.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:27:31,676 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(32, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 51), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1541321,\n",
      "    \"flops\": 493823994,\n",
      "    \"accuracy\": 0.9881,\n",
      "    \"inference_time\": 0.17240405234561604,\n",
      "    \"compression_rate\": 7.254583568250871,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:27:31,797 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(35, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(204, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 204), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:27:43,132 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(35, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(204, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 204), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:28:19,650 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1508239,\n",
      "    \"flops\": 302679306,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.17386297967023912,\n",
      "    \"compression_rate\": 7.413706978801105,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:28:19,691 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:28:32,389 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0471\n",
      "Epoch 3/3, Loss: 0.0370\n",
      "Epoch 1/3, Loss: 0.1174\n",
      "Epoch 1/3, Loss: 0.1164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:32:26,361 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(22, 28), layer1.1.conv2:(19, 19), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1517783,\n",
      "    \"flops\": 510865802,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.17201263332569425,\n",
      "    \"compression_rate\": 7.367088707674285,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:32:26,429 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(41, 16), layer1.1.conv1:(41, 32), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(38, 51), layer2.1.conv1:(38, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 22:32:38,988 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(41, 16), layer1.1.conv1:(41, 32), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(38, 51), layer2.1.conv1:(38, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:34:32,514 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 32), layer1.0.conv1:(22, 32), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(28, 19), layer2.0.conv1:(32, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 51), layer3.0.conv1:(64, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(115, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1577953,\n",
      "    \"flops\": 530673562,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.1702799154188476,\n",
      "    \"compression_rate\": 7.086169233177414,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:34:32,577 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(51, 70), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 115), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:34:44,820 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(51, 70), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 115), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0476\n",
      "Epoch 1/3, Loss: 0.1244\n",
      "Epoch 3/3, Loss: 0.0357\n",
      "Epoch 1/3, Loss: 0.1422\n",
      "Epoch 3/3, Loss: 0.0353\n",
      "Epoch 2/3, Loss: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:40:19,499 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(35, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(204, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 204), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1750570,\n",
      "    \"flops\": 730971254,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.1755098238619017,\n",
      "    \"compression_rate\": 6.387429237334126,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:40:19,578 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 44), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(51, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:40:31,743 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 44), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(51, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:41:21,581 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1518935,\n",
      "    \"flops\": 307010122,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.1753644755944578,\n",
      "    \"compression_rate\": 7.361501315066148,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:41:21,623 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(25, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:41:34,101 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(25, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0517\n",
      "Epoch 3/3, Loss: 0.0386\n",
      "Epoch 1/3, Loss: 0.1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:45:13,767 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(41, 16), layer1.1.conv1:(41, 32), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(38, 51), layer2.1.conv1:(38, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1568955,\n",
      "    \"flops\": 561578058,\n",
      "    \"accuracy\": 0.9897,\n",
      "    \"inference_time\": 0.17086341578489658,\n",
      "    \"compression_rate\": 7.126808608277484,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:45:13,834 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(41, 32), layer1.1.conv1:(22, 16), layer1.1.conv2:(35, 22), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(35, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 102), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:45:26,397 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(41, 32), layer1.1.conv1:(22, 16), layer1.1.conv2:(35, 22), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(35, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 102), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:47:30,361 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(51, 70), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 115), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1598566,\n",
      "    \"flops\": 506612406,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.17296829496978952,\n",
      "    \"compression_rate\": 6.99479533531928,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:47:30,438 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 35), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(57, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 179), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:47:44,559 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 35), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(57, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 179), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0499\n",
      "Epoch 1/3, Loss: 0.1334\n",
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 1/3, Loss: 0.1209\n",
      "Epoch 3/3, Loss: 0.0383\n",
      "Epoch 2/3, Loss: 0.0487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:53:07,206 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 44), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(51, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1543670,\n",
      "    \"flops\": 526983862,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.18385842347600656,\n",
      "    \"compression_rate\": 7.2435442808372255,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:53:07,335 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 32), layer1.1.conv1:(38, 16), layer1.1.conv2:(25, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 22:53:19,628 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 32), layer1.1.conv1:(38, 16), layer1.1.conv2:(25, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 22:54:29,854 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(25, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1456245,\n",
      "    \"flops\": 480006582,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.17799312951964685,\n",
      "    \"compression_rate\": 7.678407136161841,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:54:29,877 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(19, 38), layer1.1.conv2:(22, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:54:29,877 - MainProcess - INFO - Evaluated 80 configurations, found 80 accepted models\n",
      "2025-03-29 22:54:42,515 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(19, 38), layer1.1.conv2:(22, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0473\n",
      "Epoch 3/3, Loss: 0.0367\n",
      "Epoch 1/3, Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 22:58:13,164 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(41, 32), layer1.1.conv1:(22, 16), layer1.1.conv2:(35, 22), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(35, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 102), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1580808,\n",
      "    \"flops\": 354975242,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.1932850486407108,\n",
      "    \"compression_rate\": 7.07337133921387,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 22:58:13,302 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(25, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 41), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 22:58:26,471 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(25, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 41), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1326\n",
      "Epoch 3/3, Loss: 0.0348\n",
      "Epoch 2/3, Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:00:55,436 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(16, 35), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(57, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 179), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1702960,\n",
      "    \"flops\": 515768497,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.1988555691550998,\n",
      "    \"compression_rate\": 6.566003899093343,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:00:55,594 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(35, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 35), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(41, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(128, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(179, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 23:01:12,007 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(35, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 35), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(41, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(128, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(179, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1546\n",
      "Epoch 2/3, Loss: 0.0485\n",
      "Epoch 3/3, Loss: 0.0361\n",
      "Epoch 1/3, Loss: 0.1220\n",
      "Epoch 2/3, Loss: 0.0522\n",
      "Epoch 3/3, Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:06:24,545 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 32), layer1.1.conv1:(38, 16), layer1.1.conv2:(25, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1508230,\n",
      "    \"flops\": 528643786,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.1776551952281069,\n",
      "    \"compression_rate\": 7.413751218315509,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:06:24,650 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(28, 25), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 28), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(115, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 23:06:36,913 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(28, 25), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 28), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(115, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 23:08:19,353 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(19, 38), layer1.1.conv2:(22, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1499996,\n",
      "    \"flops\": 513425562,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.20487237482820095,\n",
      "    \"compression_rate\": 7.454447878527676,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:08:19,429 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(38, 22), layer1.1.conv1:(16, 28), layer1.1.conv2:(22, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(25, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 23:08:36,819 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(38, 22), layer1.1.conv1:(16, 28), layer1.1.conv2:(22, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(25, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0470\n",
      "Epoch 3/3, Loss: 0.0389\n",
      "Epoch 1/3, Loss: 0.1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:11:51,198 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(25, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 41), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1467435,\n",
      "    \"flops\": 678964026,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.20585361964636797,\n",
      "    \"compression_rate\": 7.619855053205082,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:11:51,348 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(51, 51), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 23:12:07,476 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(51, 51), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1280\n",
      "Epoch 3/3, Loss: 0.0360\n",
      "Epoch 2/3, Loss: 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:14:59,096 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(35, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 35), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(41, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(128, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(179, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1692677,\n",
      "    \"flops\": 347276362,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.2081388956422259,\n",
      "    \"compression_rate\": 6.605892323225282,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:14:59,192 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(16, 22), layer1.0.conv2:(25, 32), layer1.1.conv1:(16, 16), layer1.1.conv2:(28, 48), layer2.0.conv1:(16, 70), layer2.0.conv2:(70, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 70), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(115, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 23:15:15,643 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(16, 22), layer1.0.conv2:(25, 32), layer1.1.conv1:(16, 16), layer1.1.conv2:(28, 48), layer2.0.conv1:(16, 70), layer2.0.conv2:(70, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 70), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(115, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1305\n",
      "Epoch 2/3, Loss: 0.0481\n",
      "Epoch 3/3, Loss: 0.0359\n",
      "Epoch 1/3, Loss: 0.1306\n",
      "Epoch 2/3, Loss: 0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:20:26,070 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(28, 25), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 28), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(115, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1597522,\n",
      "    \"flops\": 481281366,\n",
      "    \"accuracy\": 0.9921,\n",
      "    \"inference_time\": 0.20494204367295446,\n",
      "    \"compression_rate\": 6.9993665188961405,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:20:26,182 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(51, 57), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(44, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 23:20:43,192 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(51, 57), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(44, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:23:00,383 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(38, 22), layer1.1.conv1:(16, 28), layer1.1.conv2:(22, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(25, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1533897,\n",
      "    \"flops\": 529213754,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.21558051352288313,\n",
      "    \"compression_rate\": 7.289695461950835,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:23:00,474 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 57), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 64), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:23:17,963 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 57), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 64), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 1/3, Loss: 0.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:26:01,222 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(51, 51), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1548859,\n",
      "    \"flops\": 302723994,\n",
      "    \"accuracy\": 0.9889,\n",
      "    \"inference_time\": 0.20704620000916174,\n",
      "    \"compression_rate\": 7.219276899963134,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:26:01,347 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(64, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 23:26:18,891 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(64, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0367\n",
      "Epoch 1/3, Loss: 0.1233\n",
      "Epoch 2/3, Loss: 0.0489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:29:32,175 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 28), layer1.0.conv1:(16, 22), layer1.0.conv2:(25, 32), layer1.1.conv1:(16, 16), layer1.1.conv2:(28, 48), layer2.0.conv1:(16, 70), layer2.0.conv2:(70, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 70), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(115, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1631831,\n",
      "    \"flops\": 375394522,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.2089421885788061,\n",
      "    \"compression_rate\": 6.8522058963213714,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:29:32,318 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 25), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 41), layer1.1.conv2:(22, 16), layer2.0.conv1:(32, 44), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 23:29:32,318 - MainProcess - INFO - Evaluated 90 configurations, found 90 accepted models\n",
      "2025-03-29 23:29:49,120 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 25), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 41), layer1.1.conv2:(22, 16), layer2.0.conv1:(32, 44), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1316\n",
      "Epoch 2/3, Loss: 0.0475\n",
      "Epoch 3/3, Loss: 0.0362\n",
      "Epoch 1/3, Loss: 0.1304\n",
      "Epoch 2/3, Loss: 0.0493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:34:42,019 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(51, 57), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(44, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1504096,\n",
      "    \"flops\": 382408970,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.20555918434369844,\n",
      "    \"compression_rate\": 7.434127874816501,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:34:42,124 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 70), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 23:34:56,112 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 70), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:37:49,355 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 57), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 64), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1554418,\n",
      "    \"flops\": 311687466,\n",
      "    \"accuracy\": 0.9917,\n",
      "    \"inference_time\": 0.2329309720648828,\n",
      "    \"compression_rate\": 7.193458902302984,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:37:49,477 - MainProcess - INFO - Compressing to:conv1:(2, 54), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 22), layer2.0.conv1:(44, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0486\n",
      "Epoch 3/3, Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:38:09,076 - MainProcess - INFO - finetuning:conv1:(2, 54), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 22), layer2.0.conv1:(44, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:40:26,138 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(64, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1495115,\n",
      "    \"flops\": 466346362,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.2146313413186691,\n",
      "    \"compression_rate\": 7.478783906254703,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:40:26,278 - MainProcess - INFO - Compressing to:conv1:(2, 48), layer1.0.conv1:(22, 22), layer1.0.conv2:(32, 57), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 23:40:43,036 - MainProcess - INFO - finetuning:conv1:(2, 48), layer1.0.conv1:(22, 22), layer1.0.conv2:(32, 57), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 1/3, Loss: 0.1283\n",
      "Epoch 2/3, Loss: 0.0489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:44:24,098 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(19, 25), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 41), layer1.1.conv2:(22, 16), layer2.0.conv1:(32, 44), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1496604,\n",
      "    \"flops\": 321924938,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.2062189072813451,\n",
      "    \"compression_rate\": 7.471343120825549,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:44:24,192 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-29 23:44:36,494 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1224\n",
      "Epoch 2/3, Loss: 0.0497\n",
      "Epoch 3/3, Loss: 0.0367\n",
      "Epoch 2/3, Loss: 0.0490\n",
      "Epoch 1/3, Loss: 0.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:48:40,746 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 70), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1496868,\n",
      "    \"flops\": 504570282,\n",
      "    \"accuracy\": 0.9895,\n",
      "    \"inference_time\": 0.18103911719757534,\n",
      "    \"compression_rate\": 7.470025413062475,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:48:40,862 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(32, 22), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 23:48:53,277 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(32, 22), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0370\n",
      "Epoch 3/3, Loss: 0.0368\n",
      "Epoch 2/3, Loss: 0.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:52:11,315 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 54), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 22), layer2.0.conv1:(44, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1560079,\n",
      "    \"flops\": 318603914,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.2065650176596996,\n",
      "    \"compression_rate\": 7.167356268496659,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:52:11,413 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(25, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(57, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-29 23:52:26,983 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(25, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(57, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:54:07,721 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 48), layer1.0.conv1:(22, 22), layer1.0.conv2:(32, 57), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1625330,\n",
      "    \"flops\": 371946931,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.19909078300378882,\n",
      "    \"compression_rate\": 6.879613370823156,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:54:07,779 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 22), layer1.0.conv2:(22, 32), layer1.1.conv1:(28, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-29 23:54:23,703 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 22), layer1.0.conv2:(22, 32), layer1.1.conv1:(28, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0400\n",
      "Epoch 1/3, Loss: 0.1369\n",
      "Epoch 2/3, Loss: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:58:03,374 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1472070,\n",
      "    \"flops\": 480957770,\n",
      "    \"accuracy\": 0.9895,\n",
      "    \"inference_time\": 0.20241664574657528,\n",
      "    \"compression_rate\": 7.595862968472967,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-29 23:58:03,441 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(41, 51), layer2.1.conv1:(38, 57), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:58:19,004 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(41, 51), layer2.1.conv1:(38, 57), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0494\n",
      "Epoch 3/3, Loss: 0.0353\n",
      "Epoch 2/3, Loss: 0.0483\n",
      "Epoch 1/3, Loss: 0.1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 00:02:21,128 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(32, 22), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1679979,\n",
      "    \"flops\": 530969130,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.1983708510226758,\n",
      "    \"compression_rate\": 6.65582248349533,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:02:21,244 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 28), layer1.1.conv1:(28, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(35, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:02:37,408 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 28), layer1.1.conv1:(28, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(35, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0377\n",
      "Epoch 3/3, Loss: 0.0361\n",
      "Epoch 2/3, Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 00:06:18,032 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(25, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(57, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1498171,\n",
      "    \"flops\": 296795778,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.20674082630505733,\n",
      "    \"compression_rate\": 7.4635285291198405,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:06:18,128 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(28, 19), layer1.1.conv1:(19, 32), layer1.1.conv2:(16, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-30 00:06:18,128 - MainProcess - INFO - Evaluated 100 configurations, found 100 accepted models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 00:06:33,848 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(28, 19), layer1.1.conv1:(19, 32), layer1.1.conv2:(16, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-30 00:07:47,245 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(22, 22), layer1.0.conv2:(22, 32), layer1.1.conv1:(28, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1483741,\n",
      "    \"flops\": 308432298,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.19521078233253172,\n",
      "    \"compression_rate\": 7.536114456633604,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:07:47,319 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(38, 32), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 32), layer1.1.conv2:(28, 35), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(44, 38), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:08:06,355 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(38, 32), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 32), layer1.1.conv2:(28, 35), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(44, 38), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:08:23,260 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (19, 19), 'layer1.0.conv2': (19, 28), 'layer1.1.conv1': (28, 25), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (51, 32), 'layer2.0.downsample.0': (35, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (57, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 11.12 MiB is free. Process 3928929 has 38.34 GiB memory in use. Including non-PyTorch memory, this process has 5.50 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.95 GiB is allocated by PyTorch, and 148.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:08:23,264 - MainProcess - ERROR - Error processing config: {'conv1': (1, 28), 'layer1.0.conv1': (38, 32), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (16, 32), 'layer1.1.conv2': (28, 35), 'layer2.0.conv1': (22, 44), 'layer2.0.conv2': (32, 44), 'layer2.0.downsample.0': (32, 38), 'layer2.1.conv1': (44, 38), 'layer2.1.conv2': (57, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (89, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 11.12 MiB is free. Process 3928929 has 38.34 GiB memory in use. Including non-PyTorch memory, this process has 5.50 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.96 GiB is allocated by PyTorch, and 144.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:08:23,354 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(32, 28), layer1.0.conv2:(16, 28), layer1.1.conv1:(35, 35), layer1.1.conv2:(16, 28), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:08:23,368 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(28, 28), layer1.1.conv1:(32, 16), layer1.1.conv2:(54, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:08:43,076 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(28, 28), layer1.1.conv1:(32, 16), layer1.1.conv2:(54, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:08:44,000 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(32, 28), layer1.0.conv2:(16, 28), layer1.1.conv1:(35, 35), layer1.1.conv2:(16, 28), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:09:19,657 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 25), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (41, 51), 'layer2.1.conv1': (38, 57), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 38.48 GiB memory in use. Including non-PyTorch memory, this process has 5.37 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.74 GiB is allocated by PyTorch, and 236.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:09:19,662 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (28, 16), 'layer1.0.conv2': (28, 28), 'layer1.1.conv1': (32, 16), 'layer1.1.conv2': (54, 16), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (19, 44), 'layer2.1.conv1': (51, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (44, 76), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 38.48 GiB memory in use. Including non-PyTorch memory, this process has 5.37 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.76 GiB is allocated by PyTorch, and 216.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:09:19,705 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(22, 44), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:09:19,707 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(19, 28), layer1.0.conv2:(25, 19), layer1.1.conv1:(22, 35), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 64), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:09:40,384 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(19, 28), layer1.0.conv2:(25, 19), layer1.1.conv1:(22, 35), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 64), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:09:40,471 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(22, 44), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:10:04,836 - MainProcess - ERROR - Error processing config: {'conv1': (2, 28), 'layer1.0.conv1': (22, 25), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (19, 16), 'layer1.1.conv2': (22, 44), 'layer2.0.conv1': (16, 38), 'layer2.0.conv2': (32, 64), 'layer2.0.downsample.0': (25, 44), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (89, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (89, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 15.12 MiB is free. Process 3928929 has 38.99 GiB memory in use. Including non-PyTorch memory, this process has 4.85 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.29 GiB is allocated by PyTorch, and 159.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:10:04,852 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(35, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:10:23,075 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(35, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 00:11:00,800 - MainProcess - ERROR - Error processing config: {'conv1': (2, 28), 'layer1.0.conv1': (32, 28), 'layer1.0.conv2': (16, 28), 'layer1.1.conv1': (35, 35), 'layer1.1.conv2': (16, 28), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 89), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 38.80 GiB memory in use. Including non-PyTorch memory, this process has 5.05 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.54 GiB is allocated by PyTorch, and 113.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:11:00,801 - MainProcess - ERROR - Error processing config: {'conv1': (2, 25), 'layer1.0.conv1': (19, 28), 'layer1.0.conv2': (25, 19), 'layer1.1.conv1': (22, 35), 'layer1.1.conv2': (16, 25), 'layer2.0.conv1': (16, 38), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (51, 64), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 89), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (89, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 38.80 GiB memory in use. Including non-PyTorch memory, this process has 5.05 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.56 GiB is allocated by PyTorch, and 87.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:11:00,818 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (22, 25), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (35, 16), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (25, 38), 'layer2.1.conv1': (32, 51), 'layer2.1.conv2': (44, 44), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 35.12 MiB is free. Process 3928929 has 38.80 GiB memory in use. Including non-PyTorch memory, this process has 5.02 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.50 GiB is allocated by PyTorch, and 121.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:11:00,855 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (25, 19), 'layer1.0.conv2': (28, 19), 'layer1.1.conv1': (19, 32), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (38, 44), 'layer3.0.conv1': (38, 76), 'layer3.0.conv2': (76, 89), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (89, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (102, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 153)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 38.80 GiB memory in use. Including non-PyTorch memory, this process has 5.05 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 4.53 GiB is allocated by PyTorch, and 119.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:11:00,887 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 28), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:00,889 - MainProcess - INFO - Compressing to:conv1:(1, 41), layer1.0.conv1:(48, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(32, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(70, 38), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(115, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(115, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:00,893 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(25, 48), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 22), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:00,901 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:21,071 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(25, 48), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 22), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:21,386 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 28), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:22,111 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(25, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:22,524 - MainProcess - INFO - finetuning:conv1:(1, 41), layer1.0.conv1:(48, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(32, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(70, 38), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(115, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(115, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:24,276 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (25, 48), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (16, 22), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (41, 38), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (89, 64), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 179.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.19 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 1.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:11:24,287 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(35, 32), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 35), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(41, 32), layer2.1.conv1:(44, 57), layer2.1.conv2:(32, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:24,361 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (25, 16), 'layer1.1.conv1': (22, 16), 'layer1.1.conv2': (22, 19), 'layer2.0.conv1': (16, 51), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (44, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (115, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 29.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.33 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.76 GiB is allocated by PyTorch, and 175.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:11:24,379 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(22, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:42,210 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(22, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:42,306 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(35, 32), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 35), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(41, 32), layer2.1.conv1:(44, 57), layer2.1.conv2:(32, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:50,668 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (35, 32), 'layer1.1.conv1': (19, 25), 'layer1.1.conv2': (16, 35), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (41, 32), 'layer2.1.conv1': (44, 57), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 133.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.23 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.65 GiB is allocated by PyTorch, and 1.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:11:50,677 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 41), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:11:58,990 - MainProcess - ERROR - Error processing config: {'conv1': (1, 41), 'layer1.0.conv1': (48, 19), 'layer1.0.conv2': (16, 19), 'layer1.1.conv1': (22, 19), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (32, 38), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (22, 38), 'layer2.1.conv1': (70, 38), 'layer2.1.conv2': (51, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (115, 64), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (115, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 43.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.32 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.68 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:11:59,001 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(25, 35), layer1.0.conv2:(28, 41), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:12:07,364 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 41), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:12:13,482 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(25, 35), layer1.0.conv2:(28, 41), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:12:13,738 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (16, 19), 'layer1.0.conv2': (16, 25), 'layer1.1.conv1': (25, 16), 'layer1.1.conv2': (16, 41), 'layer2.0.conv1': (35, 38), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (19, 44), 'layer2.1.conv1': (32, 44), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (57, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (57, 76), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (89, 64), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 17.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.34 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.82 GiB is allocated by PyTorch, and 123.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:12:13,759 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:12:28,034 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:12:29,113 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (25, 35), 'layer1.0.conv2': (28, 41), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (28, 32), 'layer2.0.conv2': (32, 44), 'layer2.0.downsample.0': (38, 38), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 141.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.22 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.67 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:12:29,141 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 41), layer1.0.conv2:(16, 16), layer1.1.conv1:(32, 22), layer1.1.conv2:(32, 22), layer2.0.conv1:(38, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:12:43,293 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 41), layer1.0.conv2:(16, 16), layer1.1.conv1:(32, 22), layer1.1.conv2:(32, 22), layer2.0.conv1:(38, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:12:44,789 - MainProcess - ERROR - Error processing config: {'conv1': (2, 25), 'layer1.0.conv1': (22, 19), 'layer1.0.conv2': (16, 19), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (16, 25), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (51, 38), 'layer2.0.downsample.0': (28, 38), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (89, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 185.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.18 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 1.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:12:44,803 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(28, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:12:59,349 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(28, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:12:59,641 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (28, 19), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (16, 25), 'layer1.1.conv2': (16, 32), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (102, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (102, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 97.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.26 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 548.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:12:59,650 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (19, 41), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (32, 22), 'layer1.1.conv2': (32, 22), 'layer2.0.conv1': (38, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (28, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (64, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (89, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.35 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.88 GiB is allocated by PyTorch, and 74.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:12:59,667 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(57, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:12:59,674 - MainProcess - INFO - Compressing to:conv1:(2, 32), layer1.0.conv1:(22, 16), layer1.0.conv2:(32, 16), layer1.1.conv1:(16, 28), layer1.1.conv2:(32, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:13:17,079 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(57, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:13:18,250 - MainProcess - INFO - finetuning:conv1:(2, 32), layer1.0.conv1:(22, 16), layer1.0.conv2:(32, 16), layer1.1.conv1:(16, 28), layer1.1.conv2:(32, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:13:19,041 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (25, 16), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (25, 19), 'layer1.1.conv2': (16, 22), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (44, 38), 'layer2.0.downsample.0': (25, 32), 'layer2.1.conv1': (32, 44), 'layer2.1.conv2': (57, 32), 'layer3.0.conv1': (38, 89), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (179, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 133.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.23 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:13:19,054 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (16, 28), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (28, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (38, 44), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 76), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 167.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.75 GiB is allocated by PyTorch, and 1.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:13:19,061 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 35), layer1.0.conv2:(22, 25), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:13:19,062 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 35), layer1.1.conv2:(16, 22), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(64, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:13:31,527 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 35), layer1.1.conv2:(16, 22), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(64, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:13:32,194 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 35), layer1.0.conv2:(22, 25), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:13:32,761 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (19, 35), 'layer1.0.conv2': (22, 25), 'layer1.1.conv1': (19, 25), 'layer1.1.conv2': (16, 22), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (51, 32), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 95.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.27 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.67 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:13:32,773 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 41), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:13:48,782 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 41), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:13:51,845 - MainProcess - ERROR - Error processing config: {'conv1': (1, 25), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (22, 41), 'layer1.1.conv1': (19, 16), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (51, 32), 'layer2.0.downsample.0': (32, 32), 'layer2.1.conv1': (44, 38), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (57, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (115, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 85.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.28 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.71 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:13:51,861 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(35, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:14:07,609 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(35, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:14:09,492 - MainProcess - ERROR - Error processing config: {'conv1': (2, 32), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (32, 16), 'layer1.1.conv1': (16, 28), 'layer1.1.conv2': (32, 38), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (44, 38), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (51, 32), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (102, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (89, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 45.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.31 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.72 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:14:09,510 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (35, 16), 'layer1.1.conv1': (19, 19), 'layer1.1.conv2': (22, 19), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (51, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (44, 44), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (51, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 65.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.29 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.76 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:14:09,520 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:14:09,525 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(28, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 28), layer2.0.conv1:(16, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:14:25,458 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:14:25,877 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(28, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 28), layer2.0.conv1:(16, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:14:26,102 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (19, 19), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (19, 38), 'layer2.1.conv1': (57, 44), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (70, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 143.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.22 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.66 GiB is allocated by PyTorch, and 164.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:14:26,110 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(28, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(22, 22), layer2.0.conv1:(32, 32), layer2.0.conv2:(57, 44), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 51), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 179), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:14:42,367 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(28, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(22, 22), layer2.0.conv1:(32, 32), layer2.0.conv2:(57, 44), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 51), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 179), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:14:44,305 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (28, 16), 'layer1.0.conv2': (19, 22), 'layer1.1.conv1': (19, 19), 'layer1.1.conv2': (16, 28), 'layer2.0.conv1': (16, 51), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (51, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (102, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 41.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.32 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.72 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:14:44,315 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(51, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 00:15:00,377 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(51, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 00:15:00,627 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (28, 25), 'layer1.1.conv1': (25, 16), 'layer1.1.conv2': (22, 22), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (57, 44), 'layer2.0.downsample.0': (16, 44), 'layer2.1.conv1': (32, 51), 'layer2.1.conv2': (51, 32), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 179), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 17.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.34 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.85 GiB is allocated by PyTorch, and 88.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:15:00,632 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (19, 22), 'layer1.1.conv1': (22, 35), 'layer1.1.conv2': (16, 22), 'layer2.0.conv1': (28, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (64, 38), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (64, 89), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 17.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.34 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.85 GiB is allocated by PyTorch, and 88.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:15:00,654 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(25, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(25, 44), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 00:15:00,656 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 00:15:16,476 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:15:17,833 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(25, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(25, 44), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 00:15:18,152 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 19), 'layer1.0.conv2': (22, 25), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 57), 'layer2.0.downsample.0': (22, 44), 'layer2.1.conv1': (44, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 25.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.33 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.81 GiB is allocated by PyTorch, and 124.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:15:18,176 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(22, 16), layer1.1.conv1:(35, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:15:27,827 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (19, 25), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (51, 32), 'layer2.0.conv2': (44, 38), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (38, 38), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 153)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 51.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.31 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.71 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:15:27,838 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(28, 16), layer1.0.conv2:(28, 48), layer1.1.conv1:(28, 32), layer1.1.conv2:(22, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(64, 44), layer2.1.conv2:(32, 57), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(96, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:15:34,752 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(22, 16), layer1.1.conv1:(35, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:15:44,296 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(28, 16), layer1.0.conv2:(28, 48), layer1.1.conv1:(28, 32), layer1.1.conv2:(22, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(64, 44), layer2.1.conv2:(32, 57), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(96, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:15:45,825 - MainProcess - ERROR - Error processing config: {'conv1': (2, 25), 'layer1.0.conv1': (28, 16), 'layer1.0.conv2': (28, 48), 'layer1.1.conv1': (28, 32), 'layer1.1.conv2': (22, 19), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (19, 38), 'layer2.1.conv1': (64, 44), 'layer2.1.conv2': (32, 57), 'layer3.0.conv1': (38, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (96, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 123.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.24 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.67 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:15:45,832 - MainProcess - ERROR - Error processing config: {'conv1': (2, 25), 'layer1.0.conv1': (25, 28), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (19, 19), 'layer1.1.conv2': (28, 16), 'layer2.0.conv1': (25, 44), 'layer2.0.conv2': (51, 44), 'layer2.0.downsample.0': (25, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (70, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (57, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 153), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 153)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 123.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.24 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.67 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:15:45,839 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 32), layer1.0.conv2:(38, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(38, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:15:45,841 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 25), layer1.0.conv2:(28, 35), layer1.1.conv1:(28, 38), layer1.1.conv2:(44, 16), layer2.0.conv1:(28, 57), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(25, 64), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:16:01,642 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 25), layer1.0.conv2:(28, 35), layer1.1.conv1:(28, 38), layer1.1.conv2:(44, 16), layer2.0.conv1:(28, 57), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(25, 64), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:16:02,663 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 32), layer1.0.conv2:(38, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(38, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:16:03,184 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 32), 'layer1.0.conv2': (38, 22), 'layer1.1.conv1': (19, 22), 'layer1.1.conv2': (38, 22), 'layer2.0.conv1': (19, 44), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (22, 38), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.36 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.70 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:16:03,196 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 48), layer1.0.conv2:(32, 16), layer1.1.conv1:(19, 38), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(51, 32), layer2.1.conv2:(57, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:16:14,903 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 25), 'layer1.0.conv2': (28, 35), 'layer1.1.conv1': (28, 38), 'layer1.1.conv2': (44, 16), 'layer2.0.conv1': (28, 57), 'layer2.0.conv2': (32, 51), 'layer2.0.downsample.0': (25, 64), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 113.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.25 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.68 GiB is allocated by PyTorch, and 1.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:16:14,914 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 25), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(57, 51), layer2.0.downsample.0:(48, 38), layer2.1.conv1:(44, 38), layer2.1.conv2:(44, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n",
      "2025-03-30 00:16:18,883 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 48), layer1.0.conv2:(32, 16), layer1.1.conv1:(19, 38), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(51, 32), layer2.1.conv2:(57, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:16:30,487 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 25), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(57, 51), layer2.0.downsample.0:(48, 38), layer2.1.conv1:(44, 38), layer2.1.conv2:(44, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n",
      "2025-03-30 00:16:32,077 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (25, 19), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (22, 25), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (57, 51), 'layer2.0.downsample.0': (48, 38), 'layer2.1.conv1': (44, 38), 'layer2.1.conv2': (44, 51), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 179)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 195.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.17 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.68 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:16:32,088 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(41, 22), layer1.1.conv1:(28, 19), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:16:32,225 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (19, 48), 'layer1.0.conv2': (32, 16), 'layer1.1.conv1': (19, 38), 'layer1.1.conv2': (25, 16), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (28, 38), 'layer2.1.conv1': (51, 32), 'layer2.1.conv2': (57, 38), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (89, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 189.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.17 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.67 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:16:32,237 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(25, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 22), layer1.1.conv2:(32, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:16:48,004 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(41, 22), layer1.1.conv1:(28, 19), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:16:48,017 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(25, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 22), layer1.1.conv2:(32, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:16:48,325 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (25, 22), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (25, 57), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 29.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.33 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.76 GiB is allocated by PyTorch, and 172.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:16:48,329 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (16, 22), 'layer1.0.conv2': (41, 22), 'layer1.1.conv1': (28, 19), 'layer1.1.conv2': (25, 16), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (32, 44), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 29.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.33 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.76 GiB is allocated by PyTorch, and 172.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:16:48,341 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(22, 25), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 25), layer1.1.conv2:(41, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:16:48,348 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 35), layer1.0.conv2:(19, 41), layer1.1.conv1:(41, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(32, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 76), layer3.1.conv1:(64, 115), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:17:04,751 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 35), layer1.0.conv2:(19, 41), layer1.1.conv1:(41, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(32, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 76), layer3.1.conv1:(64, 115), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:17:05,326 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(22, 25), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 25), layer1.1.conv2:(41, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:17:07,042 - MainProcess - ERROR - Error processing config: {'conv1': (2, 28), 'layer1.0.conv1': (25, 16), 'layer1.0.conv2': (25, 22), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (32, 16), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (44, 51), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 89), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 57.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.30 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.73 GiB is allocated by PyTorch, and 1.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:17:07,051 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 32), layer1.0.conv2:(28, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 38), layer2.0.conv1:(32, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 51), layer2.1.conv1:(76, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:17:21,850 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 32), layer1.0.conv2:(28, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 38), layer2.0.conv1:(32, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 51), layer2.1.conv1:(76, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:17:24,792 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (19, 35), 'layer1.0.conv2': (19, 41), 'layer1.1.conv1': (41, 16), 'layer1.1.conv2': (16, 22), 'layer2.0.conv1': (32, 44), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (22, 38), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (51, 44), 'layer3.0.conv1': (57, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (64, 76), 'layer3.1.conv1': (64, 115), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 115.12 MiB is free. Process 3928929 has 39.50 GiB memory in use. Including non-PyTorch memory, this process has 4.25 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.68 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:17:24,802 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(38, 16), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:17:41,099 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(38, 16), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:17:41,361 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (22, 16), 'layer1.1.conv2': (38, 16), 'layer2.0.conv1': (22, 44), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (51, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (70, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 3.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.77 GiB is allocated by PyTorch, and 44.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:17:41,374 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(32, 16), layer1.0.conv2:(22, 25), layer1.1.conv1:(25, 19), layer1.1.conv2:(22, 28), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(102, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:17:44,274 - MainProcess - ERROR - Error processing config: {'conv1': (1, 28), 'layer1.0.conv1': (22, 25), 'layer1.0.conv2': (25, 22), 'layer1.1.conv1': (16, 25), 'layer1.1.conv2': (41, 16), 'layer2.0.conv1': (22, 38), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (44, 32), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 17.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.72 GiB is allocated by PyTorch, and 83.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:17:44,279 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (22, 32), 'layer1.0.conv2': (28, 19), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (16, 38), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (19, 51), 'layer2.1.conv1': (76, 44), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 17.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.72 GiB is allocated by PyTorch, and 84.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:17:44,301 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 38), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 22), layer1.1.conv2:(19, 35), layer2.0.conv1:(32, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:17:44,347 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 44), layer1.1.conv1:(28, 19), layer1.1.conv2:(22, 28), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 51), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:17:58,078 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(32, 16), layer1.0.conv2:(22, 25), layer1.1.conv1:(25, 19), layer1.1.conv2:(22, 28), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(102, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:02,102 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 38), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 22), layer1.1.conv2:(19, 35), layer2.0.conv1:(32, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:02,402 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 44), layer1.1.conv1:(28, 19), layer1.1.conv2:(22, 28), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 51), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:02,687 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (32, 16), 'layer1.0.conv2': (22, 25), 'layer1.1.conv1': (25, 19), 'layer1.1.conv2': (22, 28), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (32, 57), 'layer2.0.downsample.0': (28, 44), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (51, 38), 'layer3.0.conv1': (32, 89), 'layer3.0.conv2': (102, 76), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 102), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 11.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.68 GiB is allocated by PyTorch, and 131.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:18:02,692 - MainProcess - ERROR - Error processing config: {'conv1': (2, 25), 'layer1.0.conv1': (16, 22), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (35, 16), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (22, 57), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (38, 44), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 11.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.67 GiB is allocated by PyTorch, and 139.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:18:02,705 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(28, 25), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 38), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 115), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:02,710 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 28), layer1.0.conv2:(19, 19), layer1.1.conv1:(19, 38), layer1.1.conv2:(19, 25), layer2.0.conv1:(22, 51), layer2.0.conv2:(38, 83), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(57, 83), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:18,912 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(28, 25), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 38), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 115), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:19,053 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 28), layer1.0.conv2:(19, 19), layer1.1.conv1:(19, 38), layer1.1.conv2:(19, 25), layer2.0.conv1:(22, 51), layer2.0.conv2:(38, 83), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(57, 83), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:19,258 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 38), 'layer1.0.conv2': (19, 22), 'layer1.1.conv1': (22, 22), 'layer1.1.conv2': (19, 35), 'layer2.0.conv1': (32, 38), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (22, 38), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (89, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 193.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.03 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.40 GiB is allocated by PyTorch, and 230.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:18:19,282 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(38, 16), layer1.0.conv2:(44, 32), layer1.1.conv1:(28, 25), layer1.1.conv2:(16, 25), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:21,382 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (19, 28), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (19, 38), 'layer1.1.conv2': (19, 25), 'layer2.0.conv1': (22, 51), 'layer2.0.conv2': (38, 83), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (57, 83), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 89), 'layer3.0.conv2': (89, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 15.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 196.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:18:21,416 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(28, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(28, 38), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:35,673 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(38, 16), layer1.0.conv2:(44, 32), layer1.1.conv1:(28, 25), layer1.1.conv2:(16, 25), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:37,145 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(28, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(28, 38), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:37,672 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (28, 25), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (22, 38), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (89, 64), 'layer3.1.conv2': (76, 115), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 15.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.76 GiB is allocated by PyTorch, and 40.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:18:37,675 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (28, 19), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (28, 38), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (38, 51), 'layer2.0.downsample.0': (22, 44), 'layer2.1.conv1': (38, 44), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 15.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.76 GiB is allocated by PyTorch, and 40.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:18:37,720 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(32, 19), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 54), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 64), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:37,726 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(44, 19), layer1.0.conv2:(28, 19), layer1.1.conv1:(19, 16), layer1.1.conv2:(22, 35), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(57, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 115), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:18:54,050 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(32, 19), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 54), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 64), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:54,250 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(44, 19), layer1.0.conv2:(28, 19), layer1.1.conv1:(19, 16), layer1.1.conv2:(22, 35), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(57, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 115), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:18:54,251 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (32, 19), 'layer1.0.conv2': (28, 16), 'layer1.1.conv1': (16, 54), 'layer1.1.conv2': (16, 25), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (44, 64), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.22 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.72 GiB is allocated by PyTorch, and 101.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:18:54,255 - MainProcess - ERROR - Error processing config: {'conv1': (2, 28), 'layer1.0.conv1': (38, 16), 'layer1.0.conv2': (44, 32), 'layer1.1.conv1': (28, 25), 'layer1.1.conv2': (16, 25), 'layer2.0.conv1': (35, 38), 'layer2.0.conv2': (32, 64), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (44, 32), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.22 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.72 GiB is allocated by PyTorch, and 101.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:18:54,357 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 25), layer1.0.conv2:(16, 22), layer1.1.conv1:(28, 19), layer1.1.conv2:(25, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(57, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:18:54,366 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(35, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(32, 51), layer2.1.conv1:(57, 70), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:19:10,111 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 25), layer1.0.conv2:(16, 22), layer1.1.conv1:(28, 19), layer1.1.conv2:(25, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(57, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:10,303 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 25), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (28, 19), 'layer1.1.conv2': (25, 25), 'layer2.0.conv1': (16, 38), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (19, 38), 'layer2.1.conv1': (57, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (44, 89), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (51, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (89, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 15.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.71 GiB is allocated by PyTorch, and 97.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:19:10,307 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (44, 19), 'layer1.0.conv2': (28, 19), 'layer1.1.conv1': (19, 16), 'layer1.1.conv2': (22, 35), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (57, 32), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (32, 115), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 15.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.71 GiB is allocated by PyTorch, and 97.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:19:10,376 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(28, 38), layer1.1.conv1:(25, 22), layer1.1.conv2:(22, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:10,377 - MainProcess - INFO - Compressing to:conv1:(1, 35), layer1.0.conv1:(25, 51), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 35), layer1.1.conv2:(19, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(44, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:11,045 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(35, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(32, 51), layer2.1.conv1:(57, 70), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:19:18,565 - MainProcess - ERROR - Error processing config: {'conv1': (2, 28), 'layer1.0.conv1': (22, 19), 'layer1.0.conv2': (16, 44), 'layer1.1.conv1': (28, 19), 'layer1.1.conv2': (22, 28), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (44, 51), 'layer3.0.conv1': (70, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (57, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.22 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.70 GiB is allocated by PyTorch, and 116.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:19:18,569 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (16, 19), 'layer1.0.conv2': (35, 22), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (16, 38), 'layer2.0.conv2': (32, 44), 'layer2.0.downsample.0': (32, 51), 'layer2.1.conv1': (57, 70), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.22 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.70 GiB is allocated by PyTorch, and 121.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:19:18,600 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(25, 16), layer1.1.conv1:(22, 44), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:19:18,650 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(19, 32), layer1.0.conv2:(35, 22), layer1.1.conv1:(35, 28), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(38, 51), layer2.1.conv1:(38, 57), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 102), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:27,591 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(28, 38), layer1.1.conv1:(25, 22), layer1.1.conv2:(22, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:27,667 - MainProcess - INFO - finetuning:conv1:(1, 35), layer1.0.conv1:(25, 51), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 35), layer1.1.conv2:(19, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(44, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:34,740 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(25, 16), layer1.1.conv1:(22, 44), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:19:35,279 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(19, 32), layer1.0.conv2:(35, 22), layer1.1.conv1:(35, 28), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(38, 51), layer2.1.conv1:(38, 57), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 102), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:35,555 - MainProcess - ERROR - Error processing config: {'conv1': (1, 25), 'layer1.0.conv1': (19, 32), 'layer1.0.conv2': (35, 22), 'layer1.1.conv1': (35, 28), 'layer1.1.conv2': (22, 22), 'layer2.0.conv1': (16, 38), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (38, 51), 'layer2.1.conv1': (38, 57), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 102), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 3.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.70 GiB is allocated by PyTorch, and 119.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:19:35,561 - MainProcess - ERROR - Error processing config: {'conv1': (1, 35), 'layer1.0.conv1': (25, 51), 'layer1.0.conv2': (25, 19), 'layer1.1.conv1': (19, 35), 'layer1.1.conv2': (19, 22), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (38, 44), 'layer2.0.downsample.0': (44, 38), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (38, 76), 'layer3.0.conv2': (76, 76), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (102, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 3.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.67 GiB is allocated by PyTorch, and 148.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:19:35,595 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 35), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(38, 32), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:35,600 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(16, 25), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:51,596 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(16, 25), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:52,322 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 35), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(38, 32), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:19:55,835 - MainProcess - ERROR - Error processing config: {'conv1': (1, 25), 'layer1.0.conv1': (16, 25), 'layer1.0.conv2': (22, 19), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (32, 51), 'layer2.1.conv2': (38, 38), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (76, 89), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (89, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 23.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.58 GiB is allocated by PyTorch, and 216.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:19:55,854 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(102, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:20:10,938 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(102, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:20:11,352 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (19, 19), 'layer1.0.conv2': (28, 38), 'layer1.1.conv1': (25, 22), 'layer1.1.conv2': (22, 22), 'layer2.0.conv1': (22, 38), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (25, 32), 'layer2.1.conv1': (32, 44), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 169.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.05 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.70 GiB is allocated by PyTorch, and 973.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:20:11,368 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 35), layer1.0.conv2:(22, 22), layer1.1.conv1:(28, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(44, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 102), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n",
      "2025-03-30 00:20:18,719 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (16, 19), 'layer1.0.conv2': (25, 16), 'layer1.1.conv1': (22, 44), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (28, 32), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (32, 51), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 89), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 151.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.07 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:20:18,729 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(28, 22), layer1.1.conv1:(19, 35), layer1.1.conv2:(35, 25), layer2.0.conv1:(32, 57), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:20:27,772 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 35), layer1.0.conv2:(22, 22), layer1.1.conv1:(28, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(44, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 102), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n",
      "2025-03-30 00:20:28,026 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (19, 22), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (22, 19), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (44, 44), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (32, 51), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (102, 64), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (76, 153), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.71 GiB is allocated by PyTorch, and 94.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:20:28,052 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(28, 19), layer1.0.conv2:(25, 22), layer1.1.conv1:(38, 28), layer1.1.conv2:(19, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:20:34,870 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(28, 22), layer1.1.conv1:(19, 35), layer1.1.conv2:(35, 25), layer2.0.conv1:(32, 57), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:20:35,079 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (25, 16), 'layer1.0.conv2': (28, 22), 'layer1.1.conv1': (19, 35), 'layer1.1.conv2': (35, 25), 'layer2.0.conv1': (32, 57), 'layer2.0.conv2': (51, 32), 'layer2.0.downsample.0': (25, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (57, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 7.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.70 GiB is allocated by PyTorch, and 109.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:20:35,125 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(35, 25), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:20:42,993 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(28, 19), layer1.0.conv2:(25, 22), layer1.1.conv1:(38, 28), layer1.1.conv2:(19, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:20:51,151 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(35, 25), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:20:52,243 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (28, 19), 'layer1.0.conv2': (25, 22), 'layer1.1.conv1': (38, 28), 'layer1.1.conv2': (19, 32), 'layer2.0.conv1': (16, 38), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (19, 44), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (89, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 19.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.76 GiB is allocated by PyTorch, and 41.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:20:52,259 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(38, 25), layer1.0.conv2:(25, 16), layer1.1.conv1:(19, 28), layer1.1.conv2:(54, 19), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:20:55,994 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (19, 22), 'layer1.1.conv2': (35, 25), 'layer2.0.conv1': (28, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (44, 44), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (102, 64), 'layer3.0.downsample.0': (44, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 149.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.07 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.70 GiB is allocated by PyTorch, and 991.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:20:56,006 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(32, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(22, 28), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(44, 57), layer2.1.conv2:(76, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(70, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:21:08,214 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(38, 25), layer1.0.conv2:(25, 16), layer1.1.conv1:(19, 28), layer1.1.conv2:(54, 19), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:21:11,942 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(32, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(22, 28), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(44, 57), layer2.1.conv2:(76, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(70, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:21:14,215 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (38, 25), 'layer1.0.conv2': (25, 16), 'layer1.1.conv1': (19, 28), 'layer1.1.conv2': (54, 19), 'layer2.0.conv1': (16, 44), 'layer2.0.conv2': (44, 44), 'layer2.0.downsample.0': (19, 38), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (32, 89), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 115.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.73 GiB is allocated by PyTorch, and 1001.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:21:14,246 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(41, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(28, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:21:17,429 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (16, 35), 'layer1.0.conv2': (22, 22), 'layer1.1.conv1': (28, 28), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (16, 57), 'layer2.1.conv1': (44, 38), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (44, 102), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 179)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 5.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 59.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:21:17,436 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (16, 35), 'layer1.1.conv1': (32, 16), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (38, 32), 'layer2.0.conv2': (64, 32), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (57, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 5.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.75 GiB is allocated by PyTorch, and 59.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:21:17,446 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(22, 19), layer1.0.conv2:(25, 28), layer1.1.conv1:(19, 16), layer1.1.conv2:(35, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:21:17,705 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(22, 28), layer1.0.conv2:(32, 16), layer1.1.conv1:(22, 32), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(57, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(51, 153), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=153, which is larger than max(matrix.shape)=128. Setting n_eigenvecs to 128.\n",
      "  warnings.warn(\n",
      "2025-03-30 00:21:31,290 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(41, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(28, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:21:34,362 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(22, 28), layer1.0.conv2:(32, 16), layer1.1.conv1:(22, 32), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(57, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(51, 153), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:21:34,653 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(22, 19), layer1.0.conv2:(25, 28), layer1.1.conv1:(19, 16), layer1.1.conv2:(35, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:21:37,711 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 19), 'layer1.0.conv2': (41, 25), 'layer1.1.conv1': (25, 16), 'layer1.1.conv2': (28, 19), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (51, 38), 'layer2.0.downsample.0': (28, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (64, 64), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 85.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.13 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.51 GiB is allocated by PyTorch, and 232.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:21:37,715 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (22, 19), 'layer1.0.conv2': (25, 28), 'layer1.1.conv1': (19, 16), 'layer1.1.conv2': (35, 19), 'layer2.0.conv1': (19, 51), 'layer2.0.conv2': (32, 44), 'layer2.0.downsample.0': (16, 44), 'layer2.1.conv1': (38, 44), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (89, 89), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 35.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.18 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.60 GiB is allocated by PyTorch, and 187.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:21:37,736 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(38, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 00:21:37,738 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(28, 22), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:21:54,214 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(28, 22), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:21:54,734 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(38, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 00:21:54,971 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (22, 28), 'layer1.0.conv2': (32, 16), 'layer1.1.conv1': (22, 32), 'layer1.1.conv2': (19, 32), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (51, 32), 'layer2.0.downsample.0': (28, 44), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (44, 38), 'layer3.0.conv1': (57, 64), 'layer3.0.conv2': (76, 76), 'layer3.0.downsample.0': (51, 153), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 19.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.20 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.64 GiB is allocated by PyTorch, and 156.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:21:54,977 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(57, 22), layer1.1.conv1:(25, 16), layer1.1.conv2:(28, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(38, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 115), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 102), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:21:54,978 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (16, 25), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (22, 16), 'layer1.1.conv2': (38, 19), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (44, 38), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 153)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 5.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.21 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.67 GiB is allocated by PyTorch, and 146.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:21:55,022 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(28, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(35, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(179, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 00:22:10,041 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(57, 22), layer1.1.conv1:(25, 16), layer1.1.conv2:(28, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(38, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 115), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 102), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:10,594 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(28, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(35, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(179, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 00:22:10,980 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (57, 22), 'layer1.1.conv1': (25, 16), 'layer1.1.conv2': (28, 19), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (32, 38), 'layer2.1.conv1': (38, 51), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 115), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 102), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (102, 153), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 49.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.17 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.48 GiB is allocated by PyTorch, and 291.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:22:11,001 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(35, 25), layer1.1.conv2:(19, 19), layer2.0.conv1:(51, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(57, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:11,310 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (28, 22), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (35, 16), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (38, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 89), 'layer3.0.downsample.0': (51, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (179, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 153)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 169.12 MiB is free. Process 3928929 has 39.64 GiB memory in use. Including non-PyTorch memory, this process has 4.05 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 2.45 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:22:11,339 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(35, 54), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(28, 57), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(102, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-30 00:22:27,688 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(35, 25), layer1.1.conv2:(19, 19), layer2.0.conv1:(51, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(57, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:28,004 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(35, 54), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(28, 57), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(102, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-30 00:22:28,289 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (25, 19), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (35, 25), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (51, 44), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (25, 38), 'layer2.1.conv1': (57, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 157.12 MiB is free. Process 3928929 has 39.83 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 198.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:22:28,311 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (16, 22), 'layer1.0.conv2': (28, 22), 'layer1.1.conv1': (28, 16), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (44, 38), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (32, 102), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 19.12 MiB is free. Process 3928929 has 39.83 GiB memory in use. Including non-PyTorch memory, this process has 4.01 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.46 GiB is allocated by PyTorch, and 154.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:22:28,312 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(28, 35), layer1.1.conv2:(32, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(76, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(76, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:28,314 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (28, 16), 'layer1.0.conv2': (35, 54), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (16, 38), 'layer2.0.conv2': (44, 38), 'layer2.0.downsample.0': (28, 57), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (38, 76), 'layer3.0.conv2': (64, 89), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (102, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 153)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 19.12 MiB is free. Process 3928929 has 39.83 GiB memory in use. Including non-PyTorch memory, this process has 4.01 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.48 GiB is allocated by PyTorch, and 135.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:22:28,321 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (32, 19), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (28, 16), 'layer1.1.conv2': (22, 28), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (44, 57), 'layer2.1.conv2': (76, 38), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (70, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 19.12 MiB is free. Process 3928929 has 39.83 GiB memory in use. Including non-PyTorch memory, this process has 4.01 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.49 GiB is allocated by PyTorch, and 118.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:22:28,332 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(44, 16), layer1.0.conv2:(16, 38), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 51), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:28,338 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 38), layer1.0.conv2:(22, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:28,373 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(19, 35), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(35, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:22:46,954 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 38), layer1.0.conv2:(22, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:47,062 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(19, 35), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(35, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:22:47,068 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(28, 35), layer1.1.conv2:(32, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(76, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(76, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:47,267 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (28, 35), 'layer1.1.conv2': (32, 22), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (44, 44), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (76, 32), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (76, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (89, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 13.12 MiB is free. Process 3928929 has 39.96 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.38 GiB is allocated by PyTorch, and 102.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:22:47,269 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(44, 16), layer1.0.conv2:(16, 38), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 51), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:47,304 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 38), layer1.1.conv1:(28, 25), layer1.1.conv2:(32, 41), layer2.0.conv1:(19, 51), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:49,606 - MainProcess - ERROR - Error processing config: {'conv1': (2, 28), 'layer1.0.conv1': (19, 35), 'layer1.0.conv2': (19, 22), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (35, 16), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (32, 51), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 89), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (51, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 13.12 MiB is free. Process 3928929 has 39.96 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.41 GiB is allocated by PyTorch, and 69.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:22:49,610 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (16, 38), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (19, 19), 'layer1.1.conv2': (16, 25), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (38, 44), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 13.12 MiB is free. Process 3928929 has 39.96 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.40 GiB is allocated by PyTorch, and 76.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:22:49,670 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(32, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 35), layer2.0.conv1:(16, 32), layer2.0.conv2:(51, 51), layer2.0.downsample.0:(28, 51), layer2.1.conv1:(38, 38), layer2.1.conv2:(51, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:22:49,675 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(32, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 44), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(38, 51), layer3.0.conv1:(57, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 179), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:23:03,803 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 38), layer1.1.conv1:(28, 25), layer1.1.conv2:(32, 41), layer2.0.conv1:(19, 51), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:23:06,160 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(19, 16), layer1.0.conv2:(32, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 35), layer2.0.conv1:(16, 32), layer2.0.conv2:(51, 51), layer2.0.downsample.0:(28, 51), layer2.1.conv1:(38, 38), layer2.1.conv2:(51, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:23:06,375 - MainProcess - ERROR - Error processing config: {'conv1': (1, 25), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (32, 16), 'layer1.1.conv1': (28, 16), 'layer1.1.conv2': (16, 35), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (51, 51), 'layer2.0.downsample.0': (28, 51), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (51, 51), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 76), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 39.96 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.37 GiB is allocated by PyTorch, and 116.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:23:06,381 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (16, 22), 'layer1.0.conv2': (19, 38), 'layer1.1.conv1': (28, 25), 'layer1.1.conv2': (32, 41), 'layer2.0.conv1': (19, 51), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (22, 38), 'layer2.1.conv1': (32, 51), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 39.96 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.37 GiB is allocated by PyTorch, and 116.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:23:06,412 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(44, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:23:06,456 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(28, 16), layer1.0.conv2:(28, 25), layer1.1.conv1:(22, 32), layer1.1.conv2:(19, 25), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:23:06,588 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(32, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 44), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(38, 51), layer3.0.conv1:(57, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 179), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 00:23:10,378 - MainProcess - ERROR - Error processing config: {'conv1': (1, 25), 'layer1.0.conv1': (32, 16), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (16, 28), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (22, 44), 'layer2.0.conv2': (57, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 51), 'layer2.1.conv2': (38, 51), 'layer3.0.conv1': (57, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 89), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (76, 153), 'layer4.1.conv1': (128, 179), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 39.96 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 151.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:23:10,382 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (44, 16), 'layer1.0.conv2': (16, 38), 'layer1.1.conv1': (19, 19), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (16, 51), 'layer2.0.conv2': (32, 44), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (38, 44), 'layer2.1.conv2': (38, 44), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 39.96 GiB memory in use. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Process 3530538 has 3.66 GiB memory in use. Of the allocated memory 3.33 GiB is allocated by PyTorch, and 158.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 00:23:10,458 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(35, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:23:10,459 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(22, 19), layer1.1.conv1:(41, 32), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:23:24,602 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(28, 16), layer1.0.conv2:(28, 25), layer1.1.conv1:(22, 32), layer1.1.conv2:(19, 25), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:23:24,904 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(44, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:23:27,894 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(22, 19), layer1.1.conv1:(41, 32), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:23:28,504 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(35, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1445\n",
      "Epoch 1/3, Loss: 0.1407\n",
      "Epoch 1/3, Loss: 0.1176\n",
      "Epoch 1/3, Loss: 0.1195\n",
      "Epoch 2/3, Loss: 0.0513\n",
      "Epoch 2/3, Loss: 0.0515\n",
      "Epoch 2/3, Loss: 0.0473\n",
      "Epoch 2/3, Loss: 0.0481\n",
      "Epoch 3/3, Loss: 0.0385\n",
      "Epoch 3/3, Loss: 0.0398\n",
      "Epoch 3/3, Loss: 0.0351\n",
      "Epoch 3/3, Loss: 0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 00:37:13,040 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(44, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1581457,\n",
      "    \"flops\": 511638826,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.19850856787080218,\n",
      "    \"compression_rate\": 7.07046856158593,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:37:13,140 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(41, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 16), layer1.1.conv2:(25, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 64), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(140, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:37:20,246 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 28), layer1.0.conv1:(35, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1510206,\n",
      "    \"flops\": 332728458,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.1963017766389624,\n",
      "    \"compression_rate\": 7.404050838097584,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:37:20,255 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(48, 19), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:37:27,493 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(41, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 16), layer1.1.conv2:(25, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 64), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(140, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:37:33,838 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(48, 19), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:37:35,670 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(28, 16), layer1.0.conv2:(28, 25), layer1.1.conv1:(22, 32), layer1.1.conv2:(19, 25), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1489282,\n",
      "    \"flops\": 326843754,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.19060258855232515,\n",
      "    \"compression_rate\": 7.508075703594081,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:37:35,729 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(32, 19), layer1.0.conv2:(19, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(32, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(22, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:37:42,391 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(22, 19), layer1.1.conv1:(41, 32), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1490653,\n",
      "    \"flops\": 336736266,\n",
      "    \"accuracy\": 0.9898,\n",
      "    \"inference_time\": 0.19656346507386288,\n",
      "    \"compression_rate\": 7.5011702924825565,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:37:42,398 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(35, 41), layer1.1.conv1:(25, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 102), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:37:49,840 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(32, 19), layer1.0.conv2:(19, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(32, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(22, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:37:56,425 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(35, 41), layer1.1.conv1:(25, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 102), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1334\n",
      "Epoch 1/3, Loss: 0.1288\n",
      "Epoch 1/3, Loss: 0.1350\n",
      "Epoch 1/3, Loss: 0.1338\n",
      "Epoch 2/3, Loss: 0.0480\n",
      "Epoch 2/3, Loss: 0.0489\n",
      "Epoch 2/3, Loss: 0.0488\n",
      "Epoch 2/3, Loss: 0.0484\n",
      "Epoch 3/3, Loss: 0.0372\n",
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 3/3, Loss: 0.0367\n",
      "Epoch 3/3, Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 00:49:46,017 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(41, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 16), layer1.1.conv2:(25, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 64), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(140, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1576098,\n",
      "    \"flops\": 547506042,\n",
      "    \"accuracy\": 0.9891,\n",
      "    \"inference_time\": 0.19767324939654887,\n",
      "    \"compression_rate\": 7.094509351575854,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:49:46,092 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(35, 41), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 25), layer1.1.conv2:(28, 35), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:49:54,306 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(48, 19), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1540437,\n",
      "    \"flops\": 371362410,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.18817332646396256,\n",
      "    \"compression_rate\": 7.258746706291786,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:49:54,317 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(35, 22), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:49:56,049 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(35, 41), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 25), layer1.1.conv2:(28, 35), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:50:05,381 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(35, 22), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:50:37,404 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(32, 19), layer1.0.conv2:(19, 25), layer1.1.conv1:(25, 16), layer1.1.conv2:(32, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(22, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1455951,\n",
      "    \"flops\": 323290666,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.18268687102445372,\n",
      "    \"compression_rate\": 7.6799576359369235,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:50:37,444 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(22, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:50:48,290 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(22, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:50:49,248 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(35, 41), layer1.1.conv1:(25, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 102), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1477875,\n",
      "    \"flops\": 382732762,\n",
      "    \"accuracy\": 0.9919,\n",
      "    \"inference_time\": 0.17752495996511664,\n",
      "    \"compression_rate\": 7.5660268967267195,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 00:50:49,324 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 35), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(38, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 00:50:59,906 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 35), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(38, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1261\n",
      "Epoch 1/3, Loss: 0.1329\n",
      "Epoch 1/3, Loss: 0.1210\n",
      "Epoch 1/3, Loss: 0.1457\n",
      "Epoch 2/3, Loss: 0.0477\n",
      "Epoch 2/3, Loss: 0.0486\n",
      "Epoch 2/3, Loss: 0.0469\n",
      "Epoch 2/3, Loss: 0.0517\n",
      "Epoch 3/3, Loss: 0.0355\n",
      "Epoch 3/3, Loss: 0.0363\n",
      "Epoch 3/3, Loss: 0.0359\n",
      "Epoch 3/3, Loss: 0.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:01:53,800 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(35, 41), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 25), layer1.1.conv2:(28, 35), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1547454,\n",
      "    \"flops\": 575111466,\n",
      "    \"accuracy\": 0.9917,\n",
      "    \"inference_time\": 0.19334430856562976,\n",
      "    \"compression_rate\": 7.2258315917629865,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:01:53,930 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 35), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:01:53,931 - MainProcess - INFO - Evaluated 110 configurations, found 110 accepted models\n",
      "2025-03-30 01:02:04,423 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(35, 22), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1531280,\n",
      "    \"flops\": 515645066,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.19087087576556358,\n",
      "    \"compression_rate\": 7.302153753722376,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:02:04,438 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 44), layer1.1.conv1:(16, 35), layer1.1.conv2:(22, 22), layer2.0.conv1:(48, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 64), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:02:07,632 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 35), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:02:18,481 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 44), layer1.1.conv1:(16, 35), layer1.1.conv2:(22, 22), layer2.0.conv1:(48, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 64), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:03:11,548 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(22, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1515467,\n",
      "    \"flops\": 307043638,\n",
      "    \"accuracy\": 0.9916,\n",
      "    \"inference_time\": 0.18802812145014478,\n",
      "    \"compression_rate\": 7.378347400504267,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:03:11,562 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(32, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 70), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 01:03:24,658 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(32, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 70), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 01:03:30,256 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(16, 35), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(38, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1471165,\n",
      "    \"flops\": 398087370,\n",
      "    \"accuracy\": 0.9899,\n",
      "    \"inference_time\": 0.18656600458100595,\n",
      "    \"compression_rate\": 7.600535629925943,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:03:30,270 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(28, 22), layer1.0.conv2:(35, 16), layer1.1.conv1:(48, 16), layer1.1.conv2:(19, 32), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 01:03:44,670 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(28, 22), layer1.0.conv2:(35, 16), layer1.1.conv1:(48, 16), layer1.1.conv2:(19, 32), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1360\n",
      "Epoch 1/3, Loss: 0.1329\n",
      "Epoch 1/3, Loss: 0.1195\n",
      "Epoch 1/3, Loss: 0.1254\n",
      "Epoch 2/3, Loss: 0.0487\n",
      "Epoch 2/3, Loss: 0.0481\n",
      "Epoch 2/3, Loss: 0.0467\n",
      "Epoch 2/3, Loss: 0.0484\n",
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 3/3, Loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:14:39,753 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 35), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1574165,\n",
      "    \"flops\": 498922346,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.19342453413961294,\n",
      "    \"compression_rate\": 7.103221072759209,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:14:39,839 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(22, 28), layer1.1.conv1:(28, 35), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(57, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:14:52,023 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 44), layer1.1.conv1:(16, 35), layer1.1.conv2:(22, 22), layer2.0.conv1:(48, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 64), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1489769,\n",
      "    \"flops\": 535288970,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.18956364846280174,\n",
      "    \"compression_rate\": 7.505621341295194,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:14:52,060 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(44, 28), layer1.0.conv2:(19, 28), layer1.1.conv1:(28, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:14:53,900 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(22, 28), layer1.1.conv1:(28, 35), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(57, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:15:05,794 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(44, 28), layer1.0.conv2:(19, 28), layer1.1.conv1:(28, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:16:18,564 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(32, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 70), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1696004,\n",
      "    \"flops\": 323257738,\n",
      "    \"accuracy\": 0.9917,\n",
      "    \"inference_time\": 0.19340327185936543,\n",
      "    \"compression_rate\": 6.592933743080795,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:16:18,624 - MainProcess - INFO - Compressing to:conv1:(2, 35), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 35), layer1.1.conv2:(16, 35), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 179), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 01:16:32,384 - MainProcess - INFO - finetuning:conv1:(2, 35), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 35), layer1.1.conv2:(16, 35), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 179), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 01:16:44,071 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(28, 22), layer1.0.conv2:(35, 16), layer1.1.conv1:(48, 16), layer1.1.conv2:(19, 32), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1564362,\n",
      "    \"flops\": 503204554,\n",
      "    \"accuracy\": 0.9898,\n",
      "    \"inference_time\": 0.19835728546110185,\n",
      "    \"compression_rate\": 7.147733069455791,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:16:44,134 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 01:16:58,384 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1349\n",
      "Epoch 1/3, Loss: 0.1211\n",
      "Epoch 1/3, Loss: 0.1338\n",
      "Epoch 1/3, Loss: 0.1408\n",
      "Epoch 2/3, Loss: 0.0472\n",
      "Epoch 2/3, Loss: 0.0459\n",
      "Epoch 2/3, Loss: 0.0514\n",
      "Epoch 2/3, Loss: 0.0504\n",
      "Epoch 3/3, Loss: 0.0358\n",
      "Epoch 3/3, Loss: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:27:14,106 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(22, 28), layer1.1.conv1:(28, 35), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(57, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1469027,\n",
      "    \"flops\": 642375530,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.18599897939434984,\n",
      "    \"compression_rate\": 7.611597336195999,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:27:14,193 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 57), layer2.0.conv1:(16, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 115), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:27:29,816 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(44, 28), layer1.0.conv2:(19, 28), layer1.1.conv1:(28, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1595971,\n",
      "    \"flops\": 481094186,\n",
      "    \"accuracy\": 0.992,\n",
      "    \"inference_time\": 0.1876588778890622,\n",
      "    \"compression_rate\": 7.006168658453067,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:27:29,888 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(19, 41), layer1.0.conv2:(28, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(28, 32), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 64), layer2.1.conv1:(32, 44), layer2.1.conv2:(38, 64), layer3.0.conv1:(51, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:27:30,918 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 57), layer2.0.conv1:(16, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 115), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:27:41,546 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(19, 41), layer1.0.conv2:(28, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(28, 32), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 64), layer2.1.conv1:(32, 44), layer2.1.conv2:(38, 64), layer3.0.conv1:(51, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:29:24,105 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 35), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 35), layer1.1.conv2:(16, 35), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 179), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1514894,\n",
      "    \"flops\": 555506566,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.1978987017508019,\n",
      "    \"compression_rate\": 7.381138218251574,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:29:24,182 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(28, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:29:24,182 - MainProcess - INFO - Evaluated 120 configurations, found 120 accepted models\n",
      "2025-03-30 01:29:38,138 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(28, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:29:54,088 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(25, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1546305,\n",
      "    \"flops\": 297464138,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.19525190928432848,\n",
      "    \"compression_rate\": 7.231200830366584,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:29:54,138 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(25, 19), layer1.0.conv2:(28, 35), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 35), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:30:07,785 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(25, 19), layer1.0.conv2:(28, 35), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 35), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1380\n",
      "Epoch 1/3, Loss: 0.1265\n",
      "Epoch 1/3, Loss: 0.1318\n",
      "Epoch 1/3, Loss: 0.1305\n",
      "Epoch 2/3, Loss: 0.0506\n",
      "Epoch 2/3, Loss: 0.0480\n",
      "Epoch 2/3, Loss: 0.0489\n",
      "Epoch 2/3, Loss: 0.0483\n",
      "Epoch 3/3, Loss: 0.0384\n",
      "Epoch 3/3, Loss: 0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:39:36,285 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 57), layer2.0.conv1:(16, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 115), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1531338,\n",
      "    \"flops\": 521622870,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.17924400702150511,\n",
      "    \"compression_rate\": 7.301877181915423,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:39:36,390 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(44, 19), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(35, 38), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:39:48,894 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(19, 41), layer1.0.conv2:(28, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(28, 32), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 64), layer2.1.conv1:(32, 44), layer2.1.conv2:(38, 64), layer3.0.conv1:(51, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1507629,\n",
      "    \"flops\": 350283002,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.1801339618213111,\n",
      "    \"compression_rate\": 7.416706630079416,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:39:48,975 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(22, 41), layer1.1.conv1:(19, 41), layer1.1.conv2:(25, 19), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 51), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(96, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 64), layer4.0.conv1:(89, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:39:52,478 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(44, 19), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(35, 38), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:40:05,569 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(22, 41), layer1.1.conv1:(19, 41), layer1.1.conv2:(25, 19), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 51), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(96, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 64), layer4.0.conv1:(89, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0357\n",
      "Epoch 3/3, Loss: 0.0365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:42:28,258 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(28, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1480250,\n",
      "    \"flops\": 486147066,\n",
      "    \"accuracy\": 0.992,\n",
      "    \"inference_time\": 0.20917137413267875,\n",
      "    \"compression_rate\": 7.553887519000169,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:42:28,343 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 32), layer1.1.conv1:(19, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(38, 44), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(76, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 01:42:44,387 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 32), layer1.1.conv1:(19, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(38, 44), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(76, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 01:43:11,656 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(25, 19), layer1.0.conv2:(28, 35), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 35), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1550476,\n",
      "    \"flops\": 389883626,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.2109540546522525,\n",
      "    \"compression_rate\": 7.211747876136103,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:43:11,681 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(25, 16), layer1.1.conv2:(28, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(51, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:43:27,915 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(25, 16), layer1.1.conv2:(28, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(51, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1253\n",
      "Epoch 1/3, Loss: 0.1354\n",
      "Epoch 2/3, Loss: 0.0518\n",
      "Epoch 1/3, Loss: 0.1270\n",
      "Epoch 2/3, Loss: 0.0478\n",
      "Epoch 2/3, Loss: 0.0517\n",
      "Epoch 3/3, Loss: 0.0388\n",
      "Epoch 3/3, Loss: 0.0361\n",
      "Epoch 2/3, Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:52:26,881 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 25), layer1.0.conv1:(44, 19), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(35, 38), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1514232,\n",
      "    \"flops\": 521340042,\n",
      "    \"accuracy\": 0.9917,\n",
      "    \"inference_time\": 0.19664341578311473,\n",
      "    \"compression_rate\": 7.384365143518298,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:52:26,935 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(35, 51), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(89, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 102), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:52:40,920 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(22, 41), layer1.1.conv1:(19, 41), layer1.1.conv2:(25, 19), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 51), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(96, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(102, 64), layer4.0.conv1:(89, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1612698,\n",
      "    \"flops\": 352165043,\n",
      "    \"accuracy\": 0.9916,\n",
      "    \"inference_time\": 0.1903925974657581,\n",
      "    \"compression_rate\": 6.9335002585729,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:52:40,979 - MainProcess - INFO - Compressing to:conv1:(2, 38), layer1.0.conv1:(19, 22), layer1.0.conv2:(41, 19), layer1.1.conv1:(16, 38), layer1.1.conv2:(28, 41), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(35, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:52:41,181 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(35, 51), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(89, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 102), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:52:54,636 - MainProcess - INFO - finetuning:conv1:(2, 38), layer1.0.conv1:(19, 22), layer1.0.conv2:(41, 19), layer1.1.conv1:(16, 38), layer1.1.conv2:(28, 41), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(35, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0390\n",
      "Epoch 3/3, Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:55:41,031 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 25), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 32), layer1.1.conv1:(19, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(38, 44), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(76, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1597377,\n",
      "    \"flops\": 713698362,\n",
      "    \"accuracy\": 0.9898,\n",
      "    \"inference_time\": 0.19606493789932022,\n",
      "    \"compression_rate\": 7.0000018780788755,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:55:41,121 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 25), layer1.0.conv2:(25, 41), layer1.1.conv1:(22, 32), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(28, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:55:53,692 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 25), layer1.0.conv2:(25, 41), layer1.1.conv1:(22, 32), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(28, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1421\n",
      "Epoch 1/3, Loss: 0.1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 01:56:29,163 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 28), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(25, 16), layer1.1.conv2:(28, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(51, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1483281,\n",
      "    \"flops\": 302544458,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.18725978897888443,\n",
      "    \"compression_rate\": 7.538451581325454,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 01:56:29,254 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(57, 51), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(54, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(57, 102), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 01:56:42,697 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(57, 51), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(54, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(57, 102), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1318\n",
      "Epoch 2/3, Loss: 0.0496\n",
      "Epoch 2/3, Loss: 0.0481\n",
      "Epoch 1/3, Loss: 0.1247\n",
      "Epoch 3/3, Loss: 0.0377\n",
      "Epoch 2/3, Loss: 0.0482\n",
      "Epoch 3/3, Loss: 0.0375\n",
      "Epoch 2/3, Loss: 0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:04:59,184 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 25), layer1.0.conv1:(35, 51), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(89, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 102), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1572360,\n",
      "    \"flops\": 374398058,\n",
      "    \"accuracy\": 0.9897,\n",
      "    \"inference_time\": 0.1915280818939209,\n",
      "    \"compression_rate\": 7.111375257574601,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:04:59,312 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(16, 19), layer1.0.conv2:(25, 28), layer1.1.conv1:(28, 32), layer1.1.conv2:(41, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 102), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 204), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:04:59,312 - MainProcess - INFO - Evaluated 130 configurations, found 130 accepted models\n",
      "2025-03-30 02:05:13,619 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(16, 19), layer1.0.conv2:(25, 28), layer1.1.conv1:(28, 32), layer1.1.conv2:(41, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 102), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 204), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:05:14,257 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 38), layer1.0.conv1:(19, 22), layer1.0.conv2:(41, 19), layer1.1.conv1:(16, 38), layer1.1.conv2:(28, 41), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(35, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1539550,\n",
      "    \"flops\": 350801226,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.1869390957421305,\n",
      "    \"compression_rate\": 7.262928777889643,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:05:14,298 - MainProcess - INFO - Compressing to:conv1:(2, 35), layer1.0.conv1:(19, 25), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(70, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:05:28,716 - MainProcess - INFO - finetuning:conv1:(2, 35), layer1.0.conv1:(19, 25), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(70, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0371\n",
      "Epoch 3/3, Loss: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:08:38,330 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 25), layer1.0.conv2:(25, 41), layer1.1.conv1:(22, 32), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(28, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1547282,\n",
      "    \"flops\": 341913802,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.1931917140944495,\n",
      "    \"compression_rate\": 7.226634834503342,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:08:38,452 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 25), layer1.1.conv2:(25, 19), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(32, 96), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=96, which is larger than max(matrix.shape)=64. Setting n_eigenvecs to 64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:08:52,553 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 25), layer1.1.conv2:(25, 19), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(32, 96), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:09:42,890 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(57, 51), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(54, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(57, 102), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1581186,\n",
      "    \"flops\": 409716866,\n",
      "    \"accuracy\": 0.9918,\n",
      "    \"inference_time\": 0.1967932676813405,\n",
      "    \"compression_rate\": 7.071680371569189,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:09:42,958 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(28, 28), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 57), layer2.1.conv1:(51, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:09:56,782 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(28, 28), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 57), layer2.1.conv1:(51, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0460\n",
      "Epoch 2/3, Loss: 0.0492\n",
      "Epoch 1/3, Loss: 0.1246\n",
      "Epoch 1/3, Loss: 0.1286\n",
      "Epoch 3/3, Loss: 0.0360\n",
      "Epoch 3/3, Loss: 0.0380\n",
      "Epoch 2/3, Loss: 0.0477\n",
      "Epoch 2/3, Loss: 0.0489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:17:33,682 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(16, 19), layer1.0.conv2:(25, 28), layer1.1.conv1:(28, 32), layer1.1.conv2:(41, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 102), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 204), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1573056,\n",
      "    \"flops\": 352642058,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.2024747510371441,\n",
      "    \"compression_rate\": 7.108228823385817,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:17:33,776 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(25, 32), layer1.1.conv1:(22, 19), layer1.1.conv2:(19, 54), layer2.0.conv1:(25, 32), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(22, 76), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 02:17:49,447 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(25, 32), layer1.1.conv1:(22, 19), layer1.1.conv2:(19, 54), layer2.0.conv1:(25, 32), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(22, 76), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 02:17:49,650 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 35), layer1.0.conv1:(19, 25), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 44), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(70, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1503472,\n",
      "    \"flops\": 310015194,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.19535889949515114,\n",
      "    \"compression_rate\": 7.43721333021167,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:17:49,689 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(35, 25), layer1.0.conv2:(25, 16), layer1.1.conv1:(32, 32), layer1.1.conv2:(41, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-30 02:18:05,013 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(35, 25), layer1.0.conv2:(25, 16), layer1.1.conv1:(32, 32), layer1.1.conv2:(41, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0366\n",
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 1/3, Loss: 0.1318\n",
      "Epoch 1/3, Loss: 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:21:36,680 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 25), layer1.1.conv2:(25, 19), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(32, 96), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1577912,\n",
      "    \"flops\": 517037450,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.19690763165743233,\n",
      "    \"compression_rate\": 7.08635335810869,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:21:36,767 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(44, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:21:50,614 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(44, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:22:52,148 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(25, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(28, 28), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 57), layer2.1.conv1:(51, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1503246,\n",
      "    \"flops\": 524162442,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.19405294730152042,\n",
      "    \"compression_rate\": 7.4383314507405975,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:22:52,183 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 38), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 22), layer2.0.conv1:(28, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 128), layer3.1.conv2:(76, 89), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n",
      "2025-03-30 02:23:06,680 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 38), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 22), layer2.0.conv1:(28, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 128), layer3.1.conv2:(76, 89), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0481\n",
      "Epoch 2/3, Loss: 0.0497\n",
      "Epoch 1/3, Loss: 0.1311\n",
      "Epoch 1/3, Loss: 0.1332\n",
      "Epoch 3/3, Loss: 0.0370\n",
      "Epoch 3/3, Loss: 0.0375\n",
      "Epoch 2/3, Loss: 0.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:30:09,078 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(25, 32), layer1.1.conv1:(22, 19), layer1.1.conv2:(19, 54), layer2.0.conv1:(25, 32), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(22, 76), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1546510,\n",
      "    \"flops\": 349079562,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.19535791241186184,\n",
      "    \"compression_rate\": 7.230242287473085,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:30:09,131 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(25, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 28), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(70, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:30:23,079 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(25, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 28), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(70, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:30:23,199 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(35, 25), layer1.0.conv2:(25, 16), layer1.1.conv1:(32, 32), layer1.1.conv2:(41, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\",\n",
      "    \"params\": 1581196,\n",
      "    \"flops\": 361510323,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.18858126875195025,\n",
      "    \"compression_rate\": 7.071635647952562,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:30:23,265 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(35, 19), layer1.0.conv2:(19, 35), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(51, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 02:30:35,393 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(35, 19), layer1.0.conv2:(19, 35), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(51, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 1/3, Loss: 0.1331\n",
      "Epoch 3/3, Loss: 0.0367\n",
      "Epoch 1/3, Loss: 0.1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:34:27,447 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(44, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1513198,\n",
      "    \"flops\": 492038826,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.2053774400374945,\n",
      "    \"compression_rate\": 7.389411035436209,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:34:27,568 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(28, 25), layer1.1.conv1:(35, 16), layer1.1.conv2:(25, 28), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 02:34:27,569 - MainProcess - INFO - Evaluated 140 configurations, found 140 accepted models\n",
      "2025-03-30 02:34:43,582 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(28, 25), layer1.1.conv1:(35, 16), layer1.1.conv2:(25, 28), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 02:35:58,753 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(19, 38), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 22), layer2.0.conv1:(28, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 128), layer3.1.conv2:(76, 89), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\",\n",
      "    \"params\": 1726032,\n",
      "    \"flops\": 537383622,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.20414277854239105,\n",
      "    \"compression_rate\": 6.478235629466893,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:35:58,852 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(32, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(28, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(57, 70), layer2.1.conv2:(38, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:36:14,994 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(32, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(28, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(57, 70), layer2.1.conv2:(38, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0485\n",
      "Epoch 2/3, Loss: 0.0489\n",
      "Epoch 1/3, Loss: 0.1236\n",
      "Epoch 1/3, Loss: 0.1321\n",
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 3/3, Loss: 0.0371\n",
      "Epoch 2/3, Loss: 0.0482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:42:44,363 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 28), layer1.0.conv1:(25, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 28), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(70, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1524208,\n",
      "    \"flops\": 319145658,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.1943711333467196,\n",
      "    \"compression_rate\": 7.33603418955943,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:42:44,500 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(38, 22), layer1.0.conv2:(28, 32), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 02:42:58,645 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(38, 22), layer1.0.conv2:(28, 32), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 02:42:58,701 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(35, 19), layer1.0.conv2:(19, 35), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(51, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1582763,\n",
      "    \"flops\": 324483130,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.18796425969231154,\n",
      "    \"compression_rate\": 7.064634439900352,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:42:58,742 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(28, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:43:12,403 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(28, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0494\n",
      "Epoch 3/3, Loss: 0.0357\n",
      "Epoch 1/3, Loss: 0.1406\n",
      "Epoch 1/3, Loss: 0.1362\n",
      "Epoch 3/3, Loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:47:34,061 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(28, 25), layer1.1.conv1:(35, 16), layer1.1.conv2:(25, 28), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\",\n",
      "    \"params\": 1598414,\n",
      "    \"flops\": 519759498,\n",
      "    \"accuracy\": 0.9899,\n",
      "    \"inference_time\": 0.19675355909230097,\n",
      "    \"compression_rate\": 6.995460500220844,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:47:34,133 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(22, 44), layer1.1.conv1:(22, 25), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 51), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(115, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:47:47,680 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(22, 44), layer1.1.conv1:(22, 25), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 51), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(115, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:49:08,533 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(32, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(28, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(57, 70), layer2.1.conv2:(38, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1499772,\n",
      "    \"flops\": 339456746,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.18659942418400144,\n",
      "    \"compression_rate\": 7.455561245309287,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:49:08,627 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 25), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:49:19,594 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 25), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0499\n",
      "Epoch 2/3, Loss: 0.0509\n",
      "Epoch 1/3, Loss: 0.1117\n",
      "Epoch 1/3, Loss: 0.1345\n",
      "Epoch 3/3, Loss: 0.0376\n",
      "Epoch 3/3, Loss: 0.0376\n",
      "Epoch 2/3, Loss: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 02:55:37,750 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 28), layer1.0.conv1:(38, 22), layer1.0.conv2:(28, 32), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1529051,\n",
      "    \"flops\": 322361626,\n",
      "    \"accuracy\": 0.9895,\n",
      "    \"inference_time\": 0.2113604702514195,\n",
      "    \"compression_rate\": 7.312798592067891,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:55:37,882 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 38), layer1.0.conv2:(48, 16), layer1.1.conv1:(32, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 70), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 02:55:49,819 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 38), layer1.0.conv2:(48, 16), layer1.1.conv1:(32, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 70), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 02:55:50,380 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(28, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1451781,\n",
      "    \"flops\": 449436266,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.1992676931328581,\n",
      "    \"compression_rate\": 7.702017039760129,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 02:55:50,453 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 28), layer1.1.conv2:(35, 16), layer2.0.conv1:(19, 57), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 02:56:03,692 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 28), layer1.1.conv2:(35, 16), layer2.0.conv1:(19, 57), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0507\n",
      "Epoch 3/3, Loss: 0.0348\n",
      "Epoch 1/3, Loss: 0.1286\n",
      "Epoch 1/3, Loss: 0.1367\n",
      "Epoch 3/3, Loss: 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:00:58,296 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(22, 44), layer1.1.conv1:(22, 25), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 51), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(115, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1646611,\n",
      "    \"flops\": 553640842,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.2007099539357892,\n",
      "    \"compression_rate\": 6.790700414366235,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:00:58,382 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(44, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(22, 19), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(51, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 03:01:12,117 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(44, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(22, 19), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(51, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 03:02:37,044 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 25), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1528657,\n",
      "    \"flops\": 493895338,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.1975199244837346,\n",
      "    \"compression_rate\": 7.3146834116482635,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:02:37,117 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(35, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(54, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 03:02:51,067 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(35, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(54, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0490\n",
      "Epoch 2/3, Loss: 0.0494\n",
      "Epoch 1/3, Loss: 0.1346\n",
      "Epoch 3/3, Loss: 0.0376\n",
      "Epoch 1/3, Loss: 0.1276\n",
      "Epoch 3/3, Loss: 0.0377\n",
      "Epoch 2/3, Loss: 0.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:08:22,665 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 38), layer1.0.conv2:(48, 16), layer1.1.conv1:(32, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 70), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1623831,\n",
      "    \"flops\": 359738042,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.2070087080548523,\n",
      "    \"compression_rate\": 6.885964118187176,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:08:22,765 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(16, 32), layer1.1.conv2:(16, 28), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:08:22,766 - MainProcess - INFO - Evaluated 150 configurations, found 150 accepted models\n",
      "2025-03-30 03:08:35,436 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 28), layer1.1.conv2:(35, 16), layer2.0.conv1:(19, 57), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1576493,\n",
      "    \"flops\": 534397562,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.20449264996117597,\n",
      "    \"compression_rate\": 7.092731778701205,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:08:35,570 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(25, 32), layer1.0.conv2:(28, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(28, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(76, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:08:38,937 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(16, 32), layer1.1.conv2:(16, 28), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:08:51,750 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(25, 32), layer1.0.conv2:(28, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(28, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(76, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0479\n",
      "Epoch 3/3, Loss: 0.0376\n",
      "Epoch 1/3, Loss: 0.1346\n",
      "Epoch 1/3, Loss: 0.1149\n",
      "Epoch 3/3, Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:14:12,012 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(44, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(22, 19), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(51, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1546470,\n",
      "    \"flops\": 331713962,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.20736392592168917,\n",
      "    \"compression_rate\": 7.230429300277406,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:14:12,076 - MainProcess - INFO - Compressing to:conv1:(2, 41), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 03:14:25,700 - MainProcess - INFO - finetuning:conv1:(2, 41), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:15:56,433 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(35, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(54, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1524992,\n",
      "    \"flops\": 323003722,\n",
      "    \"accuracy\": 0.9918,\n",
      "    \"inference_time\": 0.2009120230462141,\n",
      "    \"compression_rate\": 7.33226272662414,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:15:56,515 - MainProcess - INFO - Compressing to:conv1:(2, 35), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 22), layer1.1.conv2:(51, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(51, 57), layer2.1.conv2:(32, 51), layer3.0.conv1:(44, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:16:10,142 - MainProcess - INFO - finetuning:conv1:(2, 35), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 22), layer1.1.conv2:(51, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(51, 57), layer2.1.conv2:(32, 51), layer3.0.conv1:(44, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1341\n",
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 3/3, Loss: 0.0350\n",
      "Epoch 1/3, Loss: 0.1203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:21:32,701 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(16, 32), layer1.1.conv2:(16, 28), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1493372,\n",
      "    \"flops\": 663730122,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.20127250636965352,\n",
      "    \"compression_rate\": 7.487512823328681,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:21:32,775 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 22), layer2.0.conv1:(28, 38), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:21:44,271 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(25, 32), layer1.0.conv2:(28, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(28, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(76, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1571230,\n",
      "    \"flops\": 744286955,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.19560853893336724,\n",
      "    \"compression_rate\": 7.116489629144047,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:21:44,309 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 03:21:47,280 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 22), layer2.0.conv1:(28, 38), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:21:57,743 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0480\n",
      "Epoch 1/3, Loss: 0.1347\n",
      "Epoch 3/3, Loss: 0.0363\n",
      "Epoch 1/3, Loss: 0.1381\n",
      "Epoch 3/3, Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:27:43,253 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 41), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 19), layer2.0.conv1:(32, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1510566,\n",
      "    \"flops\": 294439466,\n",
      "    \"accuracy\": 0.9918,\n",
      "    \"inference_time\": 0.21648680986619043,\n",
      "    \"compression_rate\": 7.402286295335656,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:27:43,327 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(35, 32), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 03:27:58,953 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(35, 32), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0495\n",
      "Epoch 2/3, Loss: 0.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:29:30,786 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 35), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 22), layer1.1.conv2:(51, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(51, 57), layer2.1.conv2:(32, 51), layer3.0.conv1:(44, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1518547,\n",
      "    \"flops\": 342162330,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.2092270532231422,\n",
      "    \"compression_rate\": 7.363382233147871,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:29:30,824 - MainProcess - INFO - Compressing to:conv1:(1, 41), layer1.0.conv1:(32, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(38, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(102, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 153), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 03:29:45,578 - MainProcess - INFO - finetuning:conv1:(1, 41), layer1.0.conv1:(32, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(38, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(102, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 153), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1253\n",
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 3/3, Loss: 0.0382\n",
      "Epoch 1/3, Loss: 0.1416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:34:44,358 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 22), layer2.0.conv1:(28, 38), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1525263,\n",
      "    \"flops\": 331132234,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.1999285226161819,\n",
      "    \"compression_rate\": 7.330959972149065,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:34:44,461 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(32, 28), layer1.0.conv2:(16, 25), layer1.1.conv1:(19, 19), layer1.1.conv2:(25, 28), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 64), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(89, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:34:53,395 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 25), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1571394,\n",
      "    \"flops\": 495826330,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.1953725166887741,\n",
      "    \"compression_rate\": 7.115746910068385,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:34:53,474 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:34:58,288 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(32, 28), layer1.0.conv2:(16, 25), layer1.1.conv1:(19, 19), layer1.1.conv2:(25, 28), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 64), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(89, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:35:07,360 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0474\n",
      "Epoch 2/3, Loss: 0.0502\n",
      "Epoch 1/3, Loss: 0.1298\n",
      "Epoch 1/3, Loss: 0.1355\n",
      "Epoch 3/3, Loss: 0.0363\n",
      "Epoch 3/3, Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:41:01,674 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(35, 32), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1513439,\n",
      "    \"flops\": 499455466,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.18729548849117983,\n",
      "    \"compression_rate\": 7.388234345751629,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:41:01,771 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 35), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:41:01,772 - MainProcess - INFO - Evaluated 160 configurations, found 160 accepted models\n",
      "2025-03-30 03:41:17,410 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 35), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0482\n",
      "Epoch 2/3, Loss: 0.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:42:49,903 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 41), layer1.0.conv1:(32, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(38, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(102, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 153), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1704555,\n",
      "    \"flops\": 527851407,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.215895414352417,\n",
      "    \"compression_rate\": 6.559859904784533,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:42:49,978 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(44, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 54), layer1.1.conv2:(16, 22), layer2.0.conv1:(35, 32), layer2.0.conv2:(51, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(64, 38), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:43:06,005 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(44, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 54), layer1.1.conv2:(16, 22), layer2.0.conv1:(35, 32), layer2.0.conv2:(51, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(64, 38), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1272\n",
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 3/3, Loss: 0.0382\n",
      "Epoch 1/3, Loss: 0.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:47:52,717 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(32, 28), layer1.0.conv2:(16, 25), layer1.1.conv1:(19, 19), layer1.1.conv2:(25, 28), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(32, 64), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(89, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1566323,\n",
      "    \"flops\": 332674411,\n",
      "    \"accuracy\": 0.9918,\n",
      "    \"inference_time\": 0.2040172180046195,\n",
      "    \"compression_rate\": 7.13878427374175,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:47:52,829 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(28, 41), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(41, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:47:59,574 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1436382,\n",
      "    \"flops\": 279777098,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.19746614363036588,\n",
      "    \"compression_rate\": 7.784587943875654,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:47:59,659 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(48, 38), layer1.1.conv2:(22, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(57, 51), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 57), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 140), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 03:48:06,804 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(28, 41), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(41, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:48:13,860 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(48, 38), layer1.1.conv2:(22, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(57, 51), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 57), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 140), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0483\n",
      "Epoch 2/3, Loss: 0.0476\n",
      "Epoch 1/3, Loss: 0.1364\n",
      "Epoch 1/3, Loss: 0.1221\n",
      "Epoch 3/3, Loss: 0.0363\n",
      "Epoch 3/3, Loss: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:54:47,709 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 35), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1524058,\n",
      "    \"flops\": 338412458,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.2077681825925337,\n",
      "    \"compression_rate\": 7.3367562126900685,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:54:47,825 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(32, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(38, 64), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(76, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 03:55:01,183 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(32, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(38, 64), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(76, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0498\n",
      "Epoch 2/3, Loss: 0.0480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 03:56:33,514 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(44, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 54), layer1.1.conv2:(16, 22), layer2.0.conv1:(35, 32), layer2.0.conv2:(51, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(64, 38), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1538590,\n",
      "    \"flops\": 1132039962,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.20407843134205814,\n",
      "    \"compression_rate\": 7.267460467051001,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 03:56:33,599 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(25, 22), layer1.0.conv2:(22, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(51, 51), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 03:56:47,370 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(25, 22), layer1.0.conv2:(22, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(51, 51), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1274\n",
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 3/3, Loss: 0.0367\n",
      "Epoch 1/3, Loss: 0.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 04:00:52,694 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(28, 41), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(41, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1533331,\n",
      "    \"flops\": 524529354,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.20699708983143927,\n",
      "    \"compression_rate\": 7.292386314500914,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:00:52,818 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 28), layer2.0.conv1:(38, 32), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:00:59,131 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(48, 38), layer1.1.conv2:(22, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(57, 51), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 57), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 140), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1613376,\n",
      "    \"flops\": 569440794,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.20361935155913077,\n",
      "    \"compression_rate\": 6.930586546471498,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:00:59,200 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 32), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:01:08,847 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 28), layer2.0.conv1:(38, 32), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:01:16,275 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 32), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0471\n",
      "Epoch 2/3, Loss: 0.0519\n",
      "Epoch 1/3, Loss: 0.1372\n",
      "Epoch 1/3, Loss: 0.1521\n",
      "Epoch 3/3, Loss: 0.0357\n",
      "Epoch 3/3, Loss: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 04:08:20,119 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(32, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(35, 38), layer2.1.conv1:(38, 64), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(76, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1648050,\n",
      "    \"flops\": 339367370,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.20862566842648125,\n",
      "    \"compression_rate\": 6.784771093110039,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:08:20,231 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(16, 16), layer1.0.conv2:(35, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 25), layer2.0.conv1:(28, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(54, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0494\n",
      "Epoch 2/3, Loss: 0.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 04:08:34,212 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(16, 16), layer1.0.conv2:(35, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 25), layer2.0.conv1:(28, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(54, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:10:02,940 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(25, 22), layer1.0.conv2:(22, 19), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(51, 51), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1516971,\n",
      "    \"flops\": 334697474,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.2035798636717908,\n",
      "    \"compression_rate\": 7.371032142341548,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:10:03,028 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 32), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(22, 41), layer2.0.conv1:(35, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:10:17,238 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 32), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(22, 41), layer2.0.conv1:(35, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 3/3, Loss: 0.0394\n",
      "Epoch 1/3, Loss: 0.1330\n",
      "Epoch 1/3, Loss: 0.1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 04:14:08,540 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 28), layer2.0.conv1:(38, 32), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1537067,\n",
      "    \"flops\": 691840834,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.20010783819129765,\n",
      "    \"compression_rate\": 7.274661416841296,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:14:08,666 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 28), layer1.1.conv1:(25, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(70, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:14:08,666 - MainProcess - INFO - Evaluated 170 configurations, found 170 accepted models\n",
      "2025-03-30 04:14:10,992 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 32), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1518038,\n",
      "    \"flops\": 312843082,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.1948385724596157,\n",
      "    \"compression_rate\": 7.365851184225955,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:14:11,084 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 41), layer1.1.conv2:(28, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 51), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:14:21,595 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 28), layer1.1.conv1:(25, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(70, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:14:22,908 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 41), layer1.1.conv2:(28, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 51), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0503\n",
      "Epoch 2/3, Loss: 0.0499\n",
      "Epoch 1/3, Loss: 0.1261\n",
      "Epoch 1/3, Loss: 0.1238\n",
      "Epoch 3/3, Loss: 0.0380\n",
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 2/3, Loss: 0.0481\n",
      "Epoch 2/3, Loss: 0.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 04:21:59,252 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 28), layer1.0.conv1:(16, 16), layer1.0.conv2:(35, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 25), layer2.0.conv1:(28, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(54, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1480975,\n",
      "    \"flops\": 300618954,\n",
      "    \"accuracy\": 0.9889,\n",
      "    \"inference_time\": 0.2112822552901671,\n",
      "    \"compression_rate\": 7.550189571059606,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:21:59,314 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(35, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 38), layer1.1.conv2:(25, 16), layer2.0.conv1:(25, 64), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:22:13,621 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(35, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 38), layer1.1.conv2:(25, 16), layer2.0.conv1:(25, 64), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:23:18,975 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 32), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(22, 41), layer2.0.conv1:(35, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1477882,\n",
      "    \"flops\": 319660746,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.16440067777208464,\n",
      "    \"compression_rate\": 7.565991060179365,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:23:19,020 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 44), layer1.1.conv1:(25, 19), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:23:32,623 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 44), layer1.1.conv1:(25, 19), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0366\n",
      "Epoch 3/3, Loss: 0.0365\n",
      "Epoch 1/3, Loss: 0.1298\n",
      "Epoch 1/3, Loss: 0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 04:27:13,257 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 41), layer1.1.conv2:(28, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 51), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1579035,\n",
      "    \"flops\": 329975834,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.19508681479533008,\n",
      "    \"compression_rate\": 7.0813135870959165,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:27:13,342 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(25, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:27:13,775 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 28), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 28), layer1.1.conv1:(25, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(70, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1589840,\n",
      "    \"flops\": 309620842,\n",
      "    \"accuracy\": 0.9898,\n",
      "    \"inference_time\": 0.19888429479740735,\n",
      "    \"compression_rate\": 7.033186987369798,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:27:13,845 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(32, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 102), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 04:27:27,778 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(25, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:27:28,549 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(32, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 102), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0492\n",
      "Epoch 2/3, Loss: 0.0488\n",
      "Epoch 1/3, Loss: 0.1410\n",
      "Epoch 1/3, Loss: 0.1447\n",
      "Epoch 3/3, Loss: 0.0378\n",
      "Epoch 3/3, Loss: 0.0367\n",
      "Epoch 2/3, Loss: 0.0514\n",
      "Epoch 2/3, Loss: 0.0510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 04:34:57,716 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(35, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 38), layer1.1.conv2:(25, 16), layer2.0.conv1:(25, 64), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1487501,\n",
      "    \"flops\": 329067178,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.21675264455710244,\n",
      "    \"compression_rate\": 7.517065198611631,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:34:57,818 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(28, 22), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:35:13,304 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(28, 22), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:35:36,207 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 44), layer1.1.conv1:(25, 19), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1490669,\n",
      "    \"flops\": 333453658,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.17485731979337724,\n",
      "    \"compression_rate\": 7.50108977915285,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:35:36,249 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 41), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(51, 51), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 04:35:52,495 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 41), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(51, 51), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0390\n",
      "Epoch 3/3, Loss: 0.0393\n",
      "Epoch 1/3, Loss: 0.1278\n",
      "Epoch 1/3, Loss: 0.1502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 04:40:03,384 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(25, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1503051,\n",
      "    \"flops\": 500573450,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.19578411877788052,\n",
      "    \"compression_rate\": 7.4392964709780305,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:40:03,478 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(25, 32), layer1.0.conv2:(16, 25), layer1.1.conv1:(19, 19), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 89), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:40:04,460 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 22), layer1.1.conv1:(32, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 102), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1526278,\n",
      "    \"flops\": 304358634,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.19942208814519732,\n",
      "    \"compression_rate\": 7.3260847630641335,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:40:04,535 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 44), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 04:40:17,827 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(25, 32), layer1.0.conv2:(16, 25), layer1.1.conv1:(19, 19), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 89), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:40:18,981 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 44), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0485\n",
      "Epoch 2/3, Loss: 0.0518\n",
      "Epoch 1/3, Loss: 0.1447\n",
      "Epoch 1/3, Loss: 0.1285\n",
      "Epoch 3/3, Loss: 0.0377\n",
      "Epoch 3/3, Loss: 0.0386\n",
      "Epoch 2/3, Loss: 0.0507\n",
      "Epoch 2/3, Loss: 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 04:48:04,149 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 41), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(51, 51), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1566596,\n",
      "    \"flops\": 537826778,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.17276117351151324,\n",
      "    \"compression_rate\": 7.137540246496225,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:48:04,257 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(28, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(35, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:48:04,257 - MainProcess - INFO - Evaluated 180 configurations, found 180 accepted models\n",
      "2025-03-30 04:48:12,443 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(28, 22), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1490720,\n",
      "    \"flops\": 499896074,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.20463005752320504,\n",
      "    \"compression_rate\": 7.500833154448857,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:48:12,517 - MainProcess - INFO - Compressing to:conv1:(2, 44), layer1.0.conv1:(51, 28), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 19), layer2.0.conv1:(28, 51), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:48:17,319 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(28, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(35, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:48:24,935 - MainProcess - INFO - finetuning:conv1:(2, 44), layer1.0.conv1:(51, 28), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 19), layer2.0.conv1:(28, 51), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0387\n",
      "Epoch 3/3, Loss: 0.0360\n",
      "Epoch 1/3, Loss: 0.1459\n",
      "Epoch 1/3, Loss: 0.1354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 04:52:49,685 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(25, 32), layer1.0.conv2:(16, 25), layer1.1.conv1:(19, 19), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 89), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1481968,\n",
      "    \"flops\": 329405082,\n",
      "    \"accuracy\": 0.9895,\n",
      "    \"inference_time\": 0.20411435813660836,\n",
      "    \"compression_rate\": 7.545130529134232,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:52:49,791 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:52:52,805 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 44), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1612215,\n",
      "    \"flops\": 320124482,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.20677701379083524,\n",
      "    \"compression_rate\": 6.935577450898299,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 04:52:52,877 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(38, 64), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 04:53:06,456 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 04:53:08,917 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(38, 64), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0531\n",
      "Epoch 2/3, Loss: 0.0509\n",
      "Epoch 1/3, Loss: 0.1470\n",
      "Epoch 1/3, Loss: 0.1268\n",
      "Epoch 3/3, Loss: 0.0394\n",
      "Epoch 3/3, Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:00:14,488 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 25), layer1.0.conv1:(28, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(35, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1520306,\n",
      "    \"flops\": 313376202,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.17036617080623684,\n",
      "    \"compression_rate\": 7.354862771047408,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:00:14,592 - MainProcess - INFO - Compressing to:conv1:(1, 35), layer1.0.conv1:(22, 16), layer1.0.conv2:(35, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0531\n",
      "Epoch 2/3, Loss: 0.0479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:00:28,524 - MainProcess - INFO - finetuning:conv1:(1, 35), layer1.0.conv1:(22, 16), layer1.0.conv2:(35, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 05:01:30,125 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 44), layer1.0.conv1:(51, 28), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 19), layer2.0.conv1:(28, 51), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1466470,\n",
      "    \"flops\": 576900554,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.20582684437940077,\n",
      "    \"compression_rate\": 7.624869243830423,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:01:30,201 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(19, 16), layer1.1.conv1:(44, 25), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 179), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 05:01:43,440 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(19, 16), layer1.1.conv1:(44, 25), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 179), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0396\n",
      "Epoch 3/3, Loss: 0.0360\n",
      "Epoch 1/3, Loss: 0.1314\n",
      "Epoch 1/3, Loss: 0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:05:47,375 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1497027,\n",
      "    \"flops\": 305308058,\n",
      "    \"accuracy\": 0.9887,\n",
      "    \"inference_time\": 0.19358057631555384,\n",
      "    \"compression_rate\": 7.469232017859397,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:05:47,496 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(25, 28), layer1.0.conv2:(48, 22), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(32, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 05:05:50,943 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(38, 64), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 89), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1599793,\n",
      "    \"flops\": 535525346,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.19543750524014677,\n",
      "    \"compression_rate\": 6.989430507571917,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:05:51,016 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(22, 19), layer1.0.conv2:(22, 38), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(32, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n",
      "2025-03-30 05:05:59,526 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(25, 28), layer1.0.conv2:(48, 22), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(32, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 05:06:03,852 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(22, 19), layer1.0.conv2:(22, 38), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(32, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0477\n",
      "Epoch 2/3, Loss: 0.0502\n",
      "Epoch 1/3, Loss: 0.1364\n",
      "Epoch 1/3, Loss: 0.1303\n",
      "Epoch 3/3, Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:12:38,247 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 35), layer1.0.conv1:(22, 16), layer1.0.conv2:(35, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1535316,\n",
      "    \"flops\": 300987434,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.17588080873914583,\n",
      "    \"compression_rate\": 7.282958036000406,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:12:38,354 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 28), layer2.0.conv1:(22, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:12:54,801 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 28), layer2.0.conv1:(22, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0506\n",
      "Epoch 2/3, Loss: 0.0473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:15:02,742 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 22), layer1.0.conv2:(19, 16), layer1.1.conv1:(44, 25), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 179), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1616485,\n",
      "    \"flops\": 531870730,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.20928281381125158,\n",
      "    \"compression_rate\": 6.917256887629641,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:15:02,870 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 57), layer2.0.conv1:(35, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 05:15:16,798 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 57), layer2.0.conv1:(35, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1395\n",
      "Epoch 3/3, Loss: 0.0386\n",
      "Epoch 3/3, Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:18:49,999 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(25, 28), layer1.0.conv2:(48, 22), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 16), layer2.0.conv1:(32, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1482252,\n",
      "    \"flops\": 338261930,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.19772423503252098,\n",
      "    \"compression_rate\": 7.543684879494175,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:18:50,127 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(41, 16), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 05:18:50,127 - MainProcess - INFO - Evaluated 190 configurations, found 190 accepted models\n",
      "2025-03-30 05:18:57,629 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(22, 19), layer1.0.conv2:(22, 38), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(32, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\",\n",
      "    \"params\": 1619228,\n",
      "    \"flops\": 663394570,\n",
      "    \"accuracy\": 0.9921,\n",
      "    \"inference_time\": 0.2003148882758592,\n",
      "    \"compression_rate\": 6.90553893583856,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:18:57,697 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(19, 25), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:19:04,289 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(41, 16), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 05:19:12,478 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(19, 25), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0510\n",
      "Epoch 1/3, Loss: 0.1224\n",
      "Epoch 2/3, Loss: 0.0498\n",
      "Epoch 1/3, Loss: 0.1389\n",
      "Epoch 3/3, Loss: 0.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:24:39,473 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(32, 28), layer2.0.conv1:(22, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1470330,\n",
      "    \"flops\": 325844938,\n",
      "    \"accuracy\": 0.9896,\n",
      "    \"inference_time\": 0.16566864143258195,\n",
      "    \"compression_rate\": 7.604851972006284,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:24:39,546 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(51, 38), layer1.0.conv2:(22, 25), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 05:24:55,596 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(51, 38), layer1.0.conv2:(22, 25), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0489\n",
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 2/3, Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:28:34,491 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(16, 57), layer2.0.conv1:(35, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1546712,\n",
      "    \"flops\": 330238474,\n",
      "    \"accuracy\": 0.9898,\n",
      "    \"inference_time\": 0.22401344143407864,\n",
      "    \"compression_rate\": 7.229298020575259,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:28:34,608 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 32), layer1.1.conv2:(28, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(38, 44), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:28:49,709 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 32), layer1.1.conv2:(28, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(38, 44), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0362\n",
      "Epoch 3/3, Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:31:53,641 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(41, 16), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1525554,\n",
      "    \"flops\": 327081306,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.1962501982468202,\n",
      "    \"compression_rate\": 7.329561588773652,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:31:53,734 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(32, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:32:03,522 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(19, 25), layer1.1.conv1:(28, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1497972,\n",
      "    \"flops\": 315339338,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.19807415808335485,\n",
      "    \"compression_rate\": 7.4645200310820226,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:32:03,583 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 35), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(57, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 05:32:07,030 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(32, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:32:18,087 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 35), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(57, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0384\n",
      "Epoch 1/3, Loss: 0.1296\n",
      "Epoch 2/3, Loss: 0.0490\n",
      "Epoch 1/3, Loss: 0.1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:37:04,722 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(51, 38), layer1.0.conv2:(22, 25), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1498910,\n",
      "    \"flops\": 368371254,\n",
      "    \"accuracy\": 0.9895,\n",
      "    \"inference_time\": 0.17123085171806837,\n",
      "    \"compression_rate\": 7.459848823478394,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:37:04,791 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(38, 32), layer1.0.conv2:(48, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(16, 25), layer2.0.conv1:(35, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(51, 44), layer3.0.conv1:(38, 102), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 05:37:18,177 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(38, 32), layer1.0.conv2:(48, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(16, 25), layer2.0.conv1:(35, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(51, 44), layer3.0.conv1:(38, 102), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0508\n",
      "Epoch 3/3, Loss: 0.0371\n",
      "Epoch 2/3, Loss: 0.0504\n",
      "Epoch 1/3, Loss: 0.1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:40:44,700 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 32), layer1.1.conv2:(28, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(38, 44), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1616794,\n",
      "    \"flops\": 319810490,\n",
      "    \"accuracy\": 0.9897,\n",
      "    \"inference_time\": 0.16266220947233226,\n",
      "    \"compression_rate\": 6.915934868635089,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:40:44,798 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 44), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(51, 76), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-30 05:40:56,618 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 44), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(51, 76), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0378\n",
      "Epoch 3/3, Loss: 0.0370\n",
      "Epoch 2/3, Loss: 0.0480\n",
      "Epoch 1/3, Loss: 0.1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:44:28,808 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(32, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1501881,\n",
      "    \"flops\": 490757770,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.20514499660257068,\n",
      "    \"compression_rate\": 7.445091854814063,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:44:28,909 - MainProcess - INFO - Compressing to:conv1:(1, 32), layer1.0.conv1:(16, 16), layer1.0.conv2:(38, 25), layer1.1.conv1:(25, 35), layer1.1.conv2:(16, 41), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(28, 83), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=83, which is larger than max(matrix.shape)=64. Setting n_eigenvecs to 64.\n",
      "  warnings.warn(\n",
      "2025-03-30 05:44:42,488 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 35), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(57, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1590845,\n",
      "    \"flops\": 325915498,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.20381426203782393,\n",
      "    \"compression_rate\": 7.02874384368056,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:44:42,534 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(32, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(19, 22), layer1.1.conv2:(32, 19), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(41, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 05:44:44,471 - MainProcess - INFO - finetuning:conv1:(1, 32), layer1.0.conv1:(16, 16), layer1.0.conv2:(38, 25), layer1.1.conv1:(25, 35), layer1.1.conv2:(16, 41), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(28, 83), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 05:44:58,533 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(32, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(19, 22), layer1.1.conv2:(32, 19), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(41, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 2/3, Loss: 0.0474\n",
      "Epoch 1/3, Loss: 0.1253\n",
      "Epoch 1/3, Loss: 0.1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:49:12,665 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(38, 32), layer1.0.conv2:(48, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(16, 25), layer2.0.conv1:(35, 51), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(51, 44), layer3.0.conv1:(38, 102), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1650900,\n",
      "    \"flops\": 698168351,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.16745966407144144,\n",
      "    \"compression_rate\": 6.773058331819008,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:49:12,770 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(76, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 05:49:12,770 - MainProcess - INFO - Evaluated 200 configurations, found 200 accepted models\n",
      "2025-03-30 05:49:26,611 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(76, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0367\n",
      "Epoch 2/3, Loss: 0.0464\n",
      "Epoch 2/3, Loss: 0.0471\n",
      "Epoch 1/3, Loss: 0.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:53:00,195 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 44), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(51, 76), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\",\n",
      "    \"params\": 1607171,\n",
      "    \"flops\": 314906227,\n",
      "    \"accuracy\": 0.9919,\n",
      "    \"inference_time\": 0.1677432358897669,\n",
      "    \"compression_rate\": 6.957344302504214,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:53:00,284 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 22), layer2.0.conv1:(32, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(38, 89), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 05:53:14,785 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 22), layer2.0.conv1:(32, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(38, 89), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0348\n",
      "Epoch 3/3, Loss: 0.0360\n",
      "Epoch 2/3, Loss: 0.0490\n",
      "Epoch 1/3, Loss: 0.1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 05:57:11,969 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 32), layer1.0.conv1:(16, 16), layer1.0.conv2:(38, 25), layer1.1.conv1:(25, 35), layer1.1.conv2:(16, 41), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(28, 83), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1574967,\n",
      "    \"flops\": 357111446,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.17530457684948186,\n",
      "    \"compression_rate\": 7.099603991702684,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:57:12,072 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(76, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(115, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-30 05:57:25,413 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(76, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(115, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-30 05:57:36,665 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(32, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(19, 22), layer1.1.conv2:(32, 19), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(41, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1576869,\n",
      "    \"flops\": 325554074,\n",
      "    \"accuracy\": 0.9918,\n",
      "    \"inference_time\": 0.19224376992308664,\n",
      "    \"compression_rate\": 7.0910405366584035,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 05:57:36,735 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 25), layer1.1.conv2:(28, 35), layer2.0.conv1:(28, 32), layer2.0.conv2:(70, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(57, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 05:57:49,636 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 25), layer1.1.conv2:(28, 35), layer2.0.conv1:(28, 32), layer2.0.conv2:(70, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(57, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0366\n",
      "Epoch 2/3, Loss: 0.0492\n",
      "Epoch 1/3, Loss: 0.1271\n",
      "Epoch 1/3, Loss: 0.1423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:01:25,211 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(76, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1529204,\n",
      "    \"flops\": 319048246,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.18280423320276215,\n",
      "    \"compression_rate\": 7.312066931553932,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:01:25,340 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 57), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:01:41,425 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 57), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 2/3, Loss: 0.0484\n",
      "Epoch 2/3, Loss: 0.0509\n",
      "Epoch 1/3, Loss: 0.1327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:05:23,975 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 22), layer2.0.conv1:(32, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(38, 89), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1554281,\n",
      "    \"flops\": 306757282,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.18000812034444955,\n",
      "    \"compression_rate\": 7.194092960024603,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:05:24,098 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 22), layer1.0.conv2:(25, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(38, 22), layer2.0.conv1:(16, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:05:37,336 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 22), layer1.0.conv2:(25, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(38, 22), layer2.0.conv1:(16, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0373\n",
      "Epoch 3/3, Loss: 0.0382\n",
      "Epoch 2/3, Loss: 0.0488\n",
      "Epoch 1/3, Loss: 0.1338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:09:35,467 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(76, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(115, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 153)\",\n",
      "    \"params\": 1651935,\n",
      "    \"flops\": 296902451,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.17560172182232966,\n",
      "    \"compression_rate\": 6.768814753607133,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:09:35,583 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(22, 22), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 64), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:09:49,685 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(22, 22), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 64), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:10:24,108 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 28), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 25), layer1.1.conv2:(28, 35), layer2.0.conv1:(28, 32), layer2.0.conv2:(70, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(57, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1591057,\n",
      "    \"flops\": 346464138,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.19287928451651473,\n",
      "    \"compression_rate\": 7.02780730042984,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:10:24,160 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(28, 19), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(115, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:10:38,255 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(28, 19), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(115, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0372\n",
      "Epoch 2/3, Loss: 0.0512\n",
      "Epoch 1/3, Loss: 0.1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:13:42,605 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(28, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 57), layer2.0.conv2:(44, 57), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1505382,\n",
      "    \"flops\": 505222570,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.17174487407546643,\n",
      "    \"compression_rate\": 7.427777135637333,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:13:42,646 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(28, 41), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(32, 51), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(32, 70), layer2.1.conv2:(44, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:13:56,825 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(28, 41), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(32, 51), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(32, 70), layer2.1.conv2:(44, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1231\n",
      "Epoch 3/3, Loss: 0.0385\n",
      "Epoch 2/3, Loss: 0.0510\n",
      "Epoch 1/3, Loss: 0.1332\n",
      "Epoch 2/3, Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:17:24,541 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(16, 22), layer1.0.conv2:(25, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(38, 22), layer2.0.conv1:(16, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1526462,\n",
      "    \"flops\": 315872458,\n",
      "    \"accuracy\": 0.9895,\n",
      "    \"inference_time\": 0.18359257309300125,\n",
      "    \"compression_rate\": 7.325201675508463,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:17:24,655 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(35, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:17:39,882 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(35, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0368\n",
      "Epoch 2/3, Loss: 0.0494\n",
      "Epoch 3/3, Loss: 0.0368\n",
      "Epoch 1/3, Loss: 0.1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:21:54,793 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(22, 22), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 64), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1516721,\n",
      "    \"flops\": 293377930,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.18538045832559055,\n",
      "    \"compression_rate\": 7.372247104114732,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:21:54,913 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:21:54,913 - MainProcess - INFO - Evaluated 210 configurations, found 210 accepted models\n",
      "2025-03-30 06:22:07,748 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:23:06,952 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 25), layer1.0.conv2:(28, 19), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(115, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1488979,\n",
      "    \"flops\": 409673354,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.1989063259902274,\n",
      "    \"compression_rate\": 7.509603560560626,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:23:07,084 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(32, 22), layer1.1.conv1:(41, 16), layer1.1.conv2:(16, 32), layer2.0.conv1:(16, 32), layer2.0.conv2:(64, 51), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:23:20,874 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(32, 22), layer1.1.conv1:(41, 16), layer1.1.conv2:(16, 32), layer2.0.conv1:(16, 32), layer2.0.conv2:(64, 51), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0378\n",
      "Epoch 2/3, Loss: 0.0492\n",
      "Epoch 1/3, Loss: 0.1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:26:05,875 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(28, 41), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 25), layer2.0.conv1:(32, 51), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(32, 70), layer2.1.conv2:(44, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1516500,\n",
      "    \"flops\": 354660074,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.1778687276657979,\n",
      "    \"compression_rate\": 7.373321463897131,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:26:05,988 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(38, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:26:19,376 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(38, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1233\n",
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 2/3, Loss: 0.0480\n",
      "Epoch 1/3, Loss: 0.1375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:29:52,200 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(35, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1503117,\n",
      "    \"flops\": 322094282,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.17338621439194732,\n",
      "    \"compression_rate\": 7.438969820712559,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:29:52,308 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(25, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 06:30:06,606 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(25, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0481\n",
      "Epoch 3/3, Loss: 0.0359\n",
      "Epoch 2/3, Loss: 0.0500\n",
      "Epoch 1/3, Loss: 0.1307\n",
      "Epoch 3/3, Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:34:00,945 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1518750,\n",
      "    \"flops\": 477490922,\n",
      "    \"accuracy\": 0.9891,\n",
      "    \"inference_time\": 0.17648964120577348,\n",
      "    \"compression_rate\": 7.362398024691358,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:34:00,994 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 35), layer1.0.conv2:(16, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(32, 16), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 70), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:34:16,133 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 35), layer1.0.conv2:(16, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(32, 16), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 70), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:35:46,347 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(32, 22), layer1.1.conv1:(41, 16), layer1.1.conv2:(16, 32), layer2.0.conv1:(16, 32), layer2.0.conv2:(64, 51), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1574349,\n",
      "    \"flops\": 824280138,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.20831157447426182,\n",
      "    \"compression_rate\": 7.102390892997677,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:35:46,427 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 32), layer1.1.conv1:(16, 28), layer1.1.conv2:(22, 32), layer2.0.conv1:(28, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(51, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:36:02,612 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 32), layer1.1.conv1:(16, 28), layer1.1.conv2:(22, 32), layer2.0.conv1:(28, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(51, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0380\n",
      "Epoch 2/3, Loss: 0.0504\n",
      "Epoch 1/3, Loss: 0.1354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:38:31,291 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(38, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1473161,\n",
      "    \"flops\": 301506442,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.1896588528991505,\n",
      "    \"compression_rate\": 7.590237591139054,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:38:31,415 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(22, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 22), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:38:45,934 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(22, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 22), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1398\n",
      "Epoch 3/3, Loss: 0.0380\n",
      "Epoch 2/3, Loss: 0.0502\n",
      "Epoch 1/3, Loss: 0.1359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:42:14,154 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(25, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1526395,\n",
      "    \"flops\": 296470026,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.17396803975358385,\n",
      "    \"compression_rate\": 7.325523209916175,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:42:14,287 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 16), layer2.0.conv1:(28, 57), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(76, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 06:42:27,907 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 16), layer2.0.conv1:(28, 57), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(76, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0514\n",
      "Epoch 3/3, Loss: 0.0375\n",
      "Epoch 2/3, Loss: 0.0515\n",
      "Epoch 1/3, Loss: 0.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:46:22,792 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 35), layer1.0.conv2:(16, 22), layer1.1.conv1:(19, 22), layer1.1.conv2:(32, 16), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 70), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1535101,\n",
      "    \"flops\": 337201962,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.173964970683849,\n",
      "    \"compression_rate\": 7.2839780574698345,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:46:22,903 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(25, 28), layer1.1.conv1:(19, 28), layer1.1.conv2:(22, 28), layer2.0.conv1:(44, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:46:36,604 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(25, 28), layer1.1.conv1:(19, 28), layer1.1.conv2:(22, 28), layer2.0.conv1:(44, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:48:33,792 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 32), layer1.1.conv1:(16, 28), layer1.1.conv2:(22, 32), layer2.0.conv1:(28, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(51, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1511779,\n",
      "    \"flops\": 323261658,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.20180676646546447,\n",
      "    \"compression_rate\": 7.396346952828423,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:48:33,913 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(44, 25), layer1.0.conv2:(25, 35), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(76, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:48:47,226 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(44, 25), layer1.0.conv2:(25, 35), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(76, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0382\n",
      "Epoch 2/3, Loss: 0.0468\n",
      "Epoch 1/3, Loss: 0.1448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:50:37,892 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 28), layer1.0.conv1:(22, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 22), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1454887,\n",
      "    \"flops\": 658656074,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.16694082474759178,\n",
      "    \"compression_rate\": 7.685574206106729,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:50:37,976 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 54), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:50:37,977 - MainProcess - INFO - Evaluated 220 configurations, found 220 accepted models\n",
      "2025-03-30 06:50:54,136 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 54), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1189\n",
      "Epoch 3/3, Loss: 0.0355\n",
      "Epoch 2/3, Loss: 0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:54:36,338 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 16), layer2.0.conv1:(28, 57), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(76, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1624209,\n",
      "    \"flops\": 321680330,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.1844899431661942,\n",
      "    \"compression_rate\": 6.88436155691786,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:54:36,444 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(38, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 38), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(48, 44), layer2.1.conv1:(38, 76), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:54:51,913 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(38, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 38), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(48, 44), layer2.1.conv1:(38, 76), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0480\n",
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 2/3, Loss: 0.0505\n",
      "Epoch 1/3, Loss: 0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 06:58:37,389 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(25, 28), layer1.1.conv1:(19, 28), layer1.1.conv2:(22, 28), layer2.0.conv1:(44, 32), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 51), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1568406,\n",
      "    \"flops\": 351052890,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.17543338413198029,\n",
      "    \"compression_rate\": 7.129303254386938,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 06:58:37,501 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(28, 28), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(76, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(76, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 204), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 06:58:51,917 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(28, 28), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(76, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(76, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 204), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0361\n",
      "Epoch 3/3, Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:01:34,580 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(44, 25), layer1.0.conv2:(25, 35), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(76, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1567416,\n",
      "    \"flops\": 353578154,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.19966201367145384,\n",
      "    \"compression_rate\": 7.133806213538716,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:01:34,706 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(28, 22), layer1.0.conv2:(19, 25), layer1.1.conv1:(28, 35), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(64, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:01:48,837 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(28, 22), layer1.0.conv2:(19, 25), layer1.1.conv1:(28, 35), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(64, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:03:21,521 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 54), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1468678,\n",
      "    \"flops\": 308719242,\n",
      "    \"accuracy\": 0.9895,\n",
      "    \"inference_time\": 0.17873508256964876,\n",
      "    \"compression_rate\": 7.613406069948621,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:03:21,588 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(38, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 102), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:03:35,245 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(38, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 102), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0363\n",
      "Epoch 1/3, Loss: 0.1321\n",
      "Epoch 2/3, Loss: 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:06:53,358 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(38, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(22, 38), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(48, 44), layer2.1.conv1:(38, 76), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1573999,\n",
      "    \"flops\": 348204618,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.1610779585099271,\n",
      "    \"compression_rate\": 7.103970205826052,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:06:53,420 - MainProcess - INFO - Compressing to:conv1:(1, 41), layer1.0.conv1:(16, 32), layer1.0.conv2:(19, 28), layer1.1.conv1:(22, 22), layer1.1.conv2:(19, 25), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:07:04,289 - MainProcess - INFO - finetuning:conv1:(1, 41), layer1.0.conv1:(16, 32), layer1.0.conv2:(19, 28), layer1.1.conv1:(22, 22), layer1.1.conv2:(19, 25), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 2/3, Loss: 0.0491\n",
      "Epoch 2/3, Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:10:10,738 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(28, 28), layer1.0.conv2:(22, 16), layer1.1.conv1:(22, 19), layer1.1.conv2:(16, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(76, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(76, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 204), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1577419,\n",
      "    \"flops\": 328948794,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.16231890443530558,\n",
      "    \"compression_rate\": 7.088568097632906,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:10:10,826 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 28), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:10:20,212 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 28), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0362\n",
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 2/3, Loss: 0.0490\n",
      "Epoch 1/3, Loss: 0.1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:13:30,738 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(28, 22), layer1.0.conv2:(19, 25), layer1.1.conv1:(28, 35), layer1.1.conv2:(19, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(64, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1573685,\n",
      "    \"flops\": 542765194,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.17911509647490872,\n",
      "    \"compression_rate\": 7.105387672882438,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:13:30,825 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(19, 54), layer1.1.conv1:(22, 19), layer1.1.conv2:(28, 25), layer2.0.conv1:(16, 57), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(89, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 07:13:41,209 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(19, 54), layer1.1.conv1:(22, 19), layer1.1.conv2:(28, 25), layer2.0.conv1:(16, 57), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(89, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 07:14:42,571 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(38, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 102), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1515650,\n",
      "    \"flops\": 313496938,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.15749893471946635,\n",
      "    \"compression_rate\": 7.377456536799393,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:14:42,649 - MainProcess - INFO - Compressing to:conv1:(1, 32), layer1.0.conv1:(16, 19), layer1.0.conv2:(38, 16), layer1.1.conv1:(35, 54), layer1.1.conv2:(22, 41), layer2.0.conv1:(32, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 57), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 07:14:52,738 - MainProcess - INFO - finetuning:conv1:(1, 32), layer1.0.conv1:(16, 19), layer1.0.conv2:(38, 16), layer1.1.conv1:(35, 54), layer1.1.conv2:(22, 41), layer2.0.conv1:(32, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 57), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0363\n",
      "Epoch 2/3, Loss: 0.0489\n",
      "Epoch 1/3, Loss: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:17:51,303 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 41), layer1.0.conv1:(16, 32), layer1.0.conv2:(19, 28), layer1.1.conv1:(22, 22), layer1.1.conv2:(19, 25), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(57, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1548189,\n",
      "    \"flops\": 530748042,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.1582718244783438,\n",
      "    \"compression_rate\": 7.22240114094597,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:17:51,429 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(22, 16), layer1.0.conv2:(28, 16), layer1.1.conv1:(25, 22), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 102), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:18:01,706 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(22, 16), layer1.0.conv2:(28, 16), layer1.1.conv1:(25, 22), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 102), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0365\n",
      "Epoch 2/3, Loss: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:20:51,309 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 28), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1575102,\n",
      "    \"flops\": 297927923,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.15604600936743865,\n",
      "    \"compression_rate\": 7.098995493625175,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:20:51,429 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 28), layer2.0.conv1:(19, 57), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(44, 89), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:20:51,430 - MainProcess - INFO - Evaluated 230 configurations, found 230 accepted models\n",
      "2025-03-30 07:21:01,813 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 28), layer2.0.conv1:(19, 57), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(44, 89), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0475\n",
      "Epoch 1/3, Loss: 0.1153\n",
      "Epoch 3/3, Loss: 0.0354\n",
      "Epoch 1/3, Loss: 0.1422\n",
      "Epoch 3/3, Loss: 0.0354\n",
      "Epoch 2/3, Loss: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:24:55,746 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(19, 54), layer1.1.conv1:(22, 19), layer1.1.conv2:(28, 25), layer2.0.conv1:(16, 57), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(44, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(89, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(179, 128)\",\n",
      "    \"params\": 1695168,\n",
      "    \"flops\": 359436398,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.1819970000321698,\n",
      "    \"compression_rate\": 6.596185156869407,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:24:55,842 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 28), layer1.0.conv2:(22, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 07:25:06,405 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 28), layer1.0.conv2:(22, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 07:25:46,978 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 32), layer1.0.conv1:(16, 19), layer1.0.conv2:(38, 16), layer1.1.conv1:(35, 54), layer1.1.conv2:(22, 41), layer2.0.conv1:(32, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 57), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1585859,\n",
      "    \"flops\": 585521075,\n",
      "    \"accuracy\": 0.9921,\n",
      "    \"inference_time\": 0.1591677498665585,\n",
      "    \"compression_rate\": 7.050842477168525,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:25:47,047 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(22, 22), layer1.1.conv1:(35, 22), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:25:56,953 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(22, 22), layer1.1.conv1:(35, 22), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0488\n",
      "Epoch 3/3, Loss: 0.0357\n",
      "Epoch 1/3, Loss: 0.1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:28:50,699 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(22, 16), layer1.0.conv2:(28, 16), layer1.1.conv1:(25, 22), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 102), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1540067,\n",
      "    \"flops\": 317450650,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.1564326078775329,\n",
      "    \"compression_rate\": 7.260490615018697,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:28:50,805 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 28), layer1.1.conv1:(28, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(51, 44), layer2.1.conv2:(38, 70), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:29:00,636 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 28), layer1.1.conv1:(28, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(51, 44), layer2.1.conv2:(38, 70), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1220\n",
      "Epoch 3/3, Loss: 0.0367\n",
      "Epoch 2/3, Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:31:34,834 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 28), layer2.0.conv1:(19, 57), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(44, 89), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1519381,\n",
      "    \"flops\": 302684010,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.15673359893183292,\n",
      "    \"compression_rate\": 7.35934041560346,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:31:34,958 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(25, 25), layer1.0.conv2:(28, 19), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(83, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:31:44,913 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(25, 25), layer1.0.conv2:(28, 19), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(83, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1323\n",
      "Epoch 2/3, Loss: 0.0476\n",
      "Epoch 3/3, Loss: 0.0366\n",
      "Epoch 1/3, Loss: 0.1289\n",
      "Epoch 2/3, Loss: 0.0481\n",
      "Epoch 3/3, Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:36:30,568 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(16, 28), layer1.0.conv2:(22, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1540721,\n",
      "    \"flops\": 476234954,\n",
      "    \"accuracy\": 0.9901,\n",
      "    \"inference_time\": 0.1868719533244009,\n",
      "    \"compression_rate\": 7.2574087067029005,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:36:30,675 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(25, 22), layer1.0.conv2:(25, 19), layer1.1.conv1:(22, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:36:40,896 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(25, 22), layer1.0.conv2:(25, 19), layer1.1.conv1:(22, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:37:02,854 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(22, 22), layer1.1.conv1:(35, 22), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1588491,\n",
      "    \"flops\": 322705802,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.16423207939050757,\n",
      "    \"compression_rate\": 7.039159806382283,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:37:02,931 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:37:12,772 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0484\n",
      "Epoch 3/3, Loss: 0.0361\n",
      "Epoch 1/3, Loss: 0.1418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:39:59,636 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 28), layer1.1.conv1:(28, 25), layer1.1.conv2:(19, 16), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 51), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(51, 44), layer2.1.conv2:(38, 70), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1554515,\n",
      "    \"flops\": 350114442,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.16071064001435686,\n",
      "    \"compression_rate\": 7.193010038500754,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:39:59,723 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(28, 19), layer1.1.conv2:(48, 25), layer2.0.conv1:(38, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(128, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 07:40:09,172 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(28, 19), layer1.1.conv2:(48, 25), layer2.0.conv1:(38, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(128, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1462\n",
      "Epoch 3/3, Loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:42:28,476 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(25, 25), layer1.0.conv2:(28, 19), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(83, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1466656,\n",
      "    \"flops\": 324792810,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.1620266979160835,\n",
      "    \"compression_rate\": 7.6239022647437436,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:42:28,574 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(38, 22), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 64), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:42:38,475 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(38, 22), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 64), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0508\n",
      "Epoch 1/3, Loss: 0.1220\n",
      "Epoch 2/3, Loss: 0.0507\n",
      "Epoch 1/3, Loss: 0.1402\n",
      "Epoch 3/3, Loss: 0.0384\n",
      "Epoch 2/3, Loss: 0.0464\n",
      "Epoch 3/3, Loss: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:48:09,855 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(25, 22), layer1.0.conv2:(25, 19), layer1.1.conv1:(22, 19), layer1.1.conv2:(28, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1467895,\n",
      "    \"flops\": 307510314,\n",
      "    \"accuracy\": 0.9898,\n",
      "    \"inference_time\": 0.18767521791397387,\n",
      "    \"compression_rate\": 7.617467189410687,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:48:09,979 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(35, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(128, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:48:20,128 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(35, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(128, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:48:23,575 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 51), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1459625,\n",
      "    \"flops\": 475893130,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.16752788165066146,\n",
      "    \"compression_rate\": 7.660626530787018,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:48:23,661 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(35, 16), layer1.1.conv2:(25, 22), layer2.0.conv1:(44, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 07:48:23,661 - MainProcess - INFO - Evaluated 240 configurations, found 240 accepted models\n",
      "2025-03-30 07:48:33,613 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(35, 16), layer1.1.conv2:(25, 22), layer2.0.conv1:(44, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0503\n",
      "Epoch 3/3, Loss: 0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:51:11,904 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(28, 19), layer1.1.conv2:(48, 25), layer2.0.conv1:(38, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(128, 128), layer4.1.conv1:(179, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1635191,\n",
      "    \"flops\": 346169354,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.1620639251295928,\n",
      "    \"compression_rate\": 6.838125943697097,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:51:11,992 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(25, 35), layer1.1.conv1:(22, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(41, 38), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 89), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:51:22,058 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(25, 35), layer1.1.conv1:(22, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(41, 38), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 89), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1341\n",
      "Epoch 3/3, Loss: 0.0384\n",
      "Epoch 1/3, Loss: 0.1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:53:27,459 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(38, 22), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(28, 64), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1530722,\n",
      "    \"flops\": 371000202,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.16367555322667343,\n",
      "    \"compression_rate\": 7.304815636020127,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:53:27,539 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 32), layer1.0.conv2:(22, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 64), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(44, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:53:37,572 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 32), layer1.0.conv2:(22, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 64), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(44, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1468\n",
      "Epoch 2/3, Loss: 0.0499\n",
      "Epoch 2/3, Loss: 0.0489\n",
      "Epoch 1/3, Loss: 0.1318\n",
      "Epoch 2/3, Loss: 0.0513\n",
      "Epoch 3/3, Loss: 0.0380\n",
      "Epoch 3/3, Loss: 0.0362\n",
      "Epoch 2/3, Loss: 0.0498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 07:59:57,553 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 25), layer1.0.conv1:(25, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(35, 16), layer1.1.conv2:(25, 22), layer2.0.conv1:(44, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1552620,\n",
      "    \"flops\": 518450218,\n",
      "    \"accuracy\": 0.9897,\n",
      "    \"inference_time\": 0.17457800407571653,\n",
      "    \"compression_rate\": 7.201789233682421,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:59:57,637 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(41, 16), layer1.0.conv2:(38, 19), layer1.1.conv1:(16, 35), layer1.1.conv2:(22, 57), layer2.0.conv1:(16, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 07:59:58,535 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(35, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(128, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1520420,\n",
      "    \"flops\": 310359370,\n",
      "    \"accuracy\": 0.9917,\n",
      "    \"inference_time\": 0.1905825629102703,\n",
      "    \"compression_rate\": 7.354311308717328,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 07:59:58,546 - MainProcess - INFO - Compressing to:conv1:(2, 38), layer1.0.conv1:(16, 19), layer1.0.conv2:(44, 22), layer1.1.conv1:(16, 38), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(51, 70), layer2.1.conv2:(44, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:00:08,619 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(41, 16), layer1.0.conv2:(38, 19), layer1.1.conv1:(16, 35), layer1.1.conv2:(22, 57), layer2.0.conv1:(16, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:00:10,230 - MainProcess - INFO - finetuning:conv1:(2, 38), layer1.0.conv1:(16, 19), layer1.0.conv2:(44, 22), layer1.1.conv1:(16, 38), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(51, 70), layer2.1.conv2:(44, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:02:29,131 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(25, 35), layer1.1.conv1:(22, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(41, 38), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 89), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1528681,\n",
      "    \"flops\": 738946690,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.15814892855925672,\n",
      "    \"compression_rate\": 7.3145685725144745,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:02:29,186 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(25, 28), layer1.0.conv2:(28, 19), layer1.1.conv1:(48, 19), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 64), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(76, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:02:38,715 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(25, 28), layer1.0.conv2:(28, 19), layer1.1.conv1:(48, 19), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 64), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(76, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0372\n",
      "Epoch 1/3, Loss: 0.1372\n",
      "Epoch 1/3, Loss: 0.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:04:28,617 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(22, 32), layer1.0.conv2:(22, 16), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 64), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(44, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1528314,\n",
      "    \"flops\": 525808842,\n",
      "    \"accuracy\": 0.9894,\n",
      "    \"inference_time\": 0.16136423949223413,\n",
      "    \"compression_rate\": 7.316325048386654,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:04:28,729 - MainProcess - INFO - Compressing to:conv1:(2, 38), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(38, 89), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(54, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:04:38,707 - MainProcess - INFO - finetuning:conv1:(2, 38), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(38, 89), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(54, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1284\n",
      "Epoch 2/3, Loss: 0.0513\n",
      "Epoch 2/3, Loss: 0.0473\n",
      "Epoch 1/3, Loss: 0.1325\n",
      "Epoch 2/3, Loss: 0.0471\n",
      "Epoch 3/3, Loss: 0.0385\n",
      "Epoch 3/3, Loss: 0.0363\n",
      "Epoch 2/3, Loss: 0.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:11:26,762 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(41, 16), layer1.0.conv2:(38, 19), layer1.1.conv1:(16, 35), layer1.1.conv2:(22, 57), layer2.0.conv1:(16, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 57), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1520471,\n",
      "    \"flops\": 364121386,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.17080080230777683,\n",
      "    \"compression_rate\": 7.35406462865783,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:11:26,890 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(25, 22), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:11:36,981 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(25, 22), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:11:40,608 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 38), layer1.0.conv1:(16, 19), layer1.0.conv2:(44, 22), layer1.1.conv1:(16, 38), layer1.1.conv2:(16, 32), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(51, 70), layer2.1.conv2:(44, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1578473,\n",
      "    \"flops\": 360870922,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.18252871142830818,\n",
      "    \"compression_rate\": 7.083834820107787,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:11:40,660 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 41), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 08:11:51,056 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 41), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0359\n",
      "Epoch 3/3, Loss: 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:13:42,629 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(25, 28), layer1.0.conv2:(28, 19), layer1.1.conv1:(48, 19), layer1.1.conv2:(25, 16), layer2.0.conv1:(22, 64), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(76, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1548541,\n",
      "    \"flops\": 538243082,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.1639966412967431,\n",
      "    \"compression_rate\": 7.220759411600985,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:13:42,752 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(38, 22), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 41), layer1.1.conv2:(35, 25), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 96), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 08:13:52,675 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(38, 22), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 41), layer1.1.conv2:(35, 25), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 96), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1356\n",
      "Epoch 1/3, Loss: 0.1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:15:22,698 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 38), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(38, 89), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(54, 32), layer2.1.conv1:(44, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1497894,\n",
      "    \"flops\": 325017034,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.1615079775484251,\n",
      "    \"compression_rate\": 7.464908731859531,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:15:22,754 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(28, 38), layer1.0.conv2:(35, 25), layer1.1.conv1:(16, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:15:22,754 - MainProcess - INFO - Evaluated 250 configurations, found 250 accepted models\n",
      "2025-03-30 08:15:32,367 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(28, 38), layer1.0.conv2:(35, 25), layer1.1.conv1:(16, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1419\n",
      "Epoch 2/3, Loss: 0.0504\n",
      "Epoch 2/3, Loss: 0.0505\n",
      "Epoch 1/3, Loss: 0.1418\n",
      "Epoch 2/3, Loss: 0.0499\n",
      "Epoch 3/3, Loss: 0.0389\n",
      "Epoch 3/3, Loss: 0.0378\n",
      "Epoch 2/3, Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:23:03,352 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 25), layer1.1.conv2:(25, 22), layer2.0.conv1:(25, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1515399,\n",
      "    \"flops\": 297939242,\n",
      "    \"accuracy\": 0.9899,\n",
      "    \"inference_time\": 0.17895003286390043,\n",
      "    \"compression_rate\": 7.37867848665599,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:23:03,435 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(44, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:23:16,202 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(44, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:23:40,464 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 41), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1508158,\n",
      "    \"flops\": 299706378,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.1890817154238432,\n",
      "    \"compression_rate\": 7.414105153438831,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:23:40,543 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(35, 25), layer1.1.conv2:(16, 41), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(64, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:23:54,768 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(35, 25), layer1.1.conv2:(16, 41), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(64, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:25:37,755 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 25), layer1.0.conv1:(38, 22), layer1.0.conv2:(25, 22), layer1.1.conv1:(16, 41), layer1.1.conv2:(35, 25), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 96), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\",\n",
      "    \"params\": 1590179,\n",
      "    \"flops\": 771635766,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.1707466063732301,\n",
      "    \"compression_rate\": 7.031687627619281,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:25:37,859 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 57), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 57), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:25:51,026 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 57), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 57), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:27:16,456 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 28), layer1.0.conv1:(28, 38), layer1.0.conv2:(35, 25), layer1.1.conv1:(16, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(102, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1484336,\n",
      "    \"flops\": 335676298,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.16384256164485989,\n",
      "    \"compression_rate\": 7.533093585279882,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:27:16,504 - MainProcess - INFO - Compressing to:conv1:(2, 44), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(22, 32), layer2.0.conv1:(22, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 08:27:30,935 - MainProcess - INFO - finetuning:conv1:(2, 44), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(22, 32), layer2.0.conv1:(22, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1360\n",
      "Epoch 1/3, Loss: 0.1274\n",
      "Epoch 1/3, Loss: 0.1282\n",
      "Epoch 1/3, Loss: 0.1243\n",
      "Epoch 2/3, Loss: 0.0490\n",
      "Epoch 2/3, Loss: 0.0496\n",
      "Epoch 2/3, Loss: 0.0487\n",
      "Epoch 2/3, Loss: 0.0484\n",
      "Epoch 3/3, Loss: 0.0366\n",
      "Epoch 3/3, Loss: 0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:40:26,198 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(44, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1541501,\n",
      "    \"flops\": 308157898,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.17564524257765202,\n",
      "    \"compression_rate\": 7.25373645557155,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:40:26,315 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(32, 22), layer1.1.conv1:(25, 44), layer1.1.conv2:(35, 44), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:40:40,041 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(32, 22), layer1.1.conv1:(25, 44), layer1.1.conv2:(35, 44), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0370\n",
      "Epoch 3/3, Loss: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:41:11,286 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(28, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(35, 25), layer1.1.conv2:(16, 41), layer2.0.conv1:(25, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(64, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1523942,\n",
      "    \"flops\": 544156010,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.1858511765797933,\n",
      "    \"compression_rate\": 7.337314674705468,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:41:11,359 - MainProcess - INFO - Compressing to:conv1:(2, 41), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(28, 38), layer1.1.conv2:(19, 19), layer2.0.conv1:(16, 76), layer2.0.conv2:(44, 64), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(140, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 08:41:24,065 - MainProcess - INFO - finetuning:conv1:(2, 41), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(28, 38), layer1.1.conv2:(19, 19), layer2.0.conv1:(16, 76), layer2.0.conv2:(44, 64), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(140, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 08:42:48,665 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 44), layer1.0.conv1:(16, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(22, 32), layer2.0.conv1:(22, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1562251,\n",
      "    \"flops\": 517399658,\n",
      "    \"accuracy\": 0.9889,\n",
      "    \"inference_time\": 0.16771295065586225,\n",
      "    \"compression_rate\": 7.157391481906557,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:42:48,735 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(32, 28), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(57, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:42:59,229 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(16, 22), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 57), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 57), layer3.0.conv1:(70, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1527068,\n",
      "    \"flops\": 701489130,\n",
      "    \"accuracy\": 0.9918,\n",
      "    \"inference_time\": 0.1634322397268502,\n",
      "    \"compression_rate\": 7.322294750462978,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:42:59,253 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(38, 16), layer1.1.conv1:(44, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:43:02,517 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(32, 28), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(57, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:43:12,507 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(38, 16), layer1.1.conv1:(44, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1341\n",
      "Epoch 1/3, Loss: 0.1183\n",
      "Epoch 1/3, Loss: 0.1376\n",
      "Epoch 1/3, Loss: 0.1269\n",
      "Epoch 2/3, Loss: 0.0499\n",
      "Epoch 2/3, Loss: 0.0467\n",
      "Epoch 2/3, Loss: 0.0508\n",
      "Epoch 2/3, Loss: 0.0479\n",
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 3/3, Loss: 0.0350\n",
      "Epoch 3/3, Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:57:43,966 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 19), layer1.0.conv2:(32, 22), layer1.1.conv1:(25, 44), layer1.1.conv2:(35, 44), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1553778,\n",
      "    \"flops\": 379581866,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.18294545495586031,\n",
      "    \"compression_rate\": 7.196421882662774,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:57:44,097 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(38, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(57, 38), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 89), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:57:56,080 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(38, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(57, 38), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 89), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:58:29,432 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 41), layer1.0.conv1:(16, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(28, 38), layer1.1.conv2:(19, 19), layer2.0.conv1:(16, 76), layer2.0.conv2:(44, 64), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(140, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1706800,\n",
      "    \"flops\": 743317686,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.18072211312134048,\n",
      "    \"compression_rate\": 6.551231544410593,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:58:29,454 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(28, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(57, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:58:29,454 - MainProcess - INFO - Evaluated 260 configurations, found 260 accepted models\n",
      "2025-03-30 08:58:37,131 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(32, 28), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(57, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1603796,\n",
      "    \"flops\": 323055466,\n",
      "    \"accuracy\": 0.9896,\n",
      "    \"inference_time\": 0.16770586997840056,\n",
      "    \"compression_rate\": 6.971985215077229,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 08:58:37,158 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 08:58:42,551 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(28, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(57, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 08:58:50,425 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:00:30,027 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 19), layer1.0.conv2:(38, 16), layer1.1.conv1:(44, 22), layer1.1.conv2:(22, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1480254,\n",
      "    \"flops\": 321746186,\n",
      "    \"accuracy\": 0.9877,\n",
      "    \"inference_time\": 0.16754576861225623,\n",
      "    \"compression_rate\": 7.5538671065911664,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:00:30,141 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(32, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(19, 25), layer1.1.conv2:(25, 48), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(64, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(102, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:00:44,710 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(32, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(19, 25), layer1.1.conv2:(25, 48), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(64, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(102, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1342\n",
      "Epoch 1/3, Loss: 0.1266\n",
      "Epoch 1/3, Loss: 0.1415\n",
      "Epoch 1/3, Loss: 0.1467\n",
      "Epoch 2/3, Loss: 0.0492\n",
      "Epoch 2/3, Loss: 0.0491\n",
      "Epoch 2/3, Loss: 0.0520\n",
      "Epoch 2/3, Loss: 0.0503\n",
      "Epoch 3/3, Loss: 0.0375\n",
      "Epoch 3/3, Loss: 0.0366\n",
      "Epoch 3/3, Loss: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:14:58,775 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(38, 16), layer1.1.conv1:(19, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(57, 38), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 89), layer3.1.conv1:(64, 89), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1628817,\n",
      "    \"flops\": 723390562,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.18418461097020758,\n",
      "    \"compression_rate\": 6.864885373863363,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:14:58,906 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(35, 48), layer1.1.conv1:(22, 16), layer1.1.conv2:(38, 38), layer2.0.conv1:(25, 44), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(89, 102), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:14:59,614 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(32, 102), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1514943,\n",
      "    \"flops\": 309925034,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.1769424087176151,\n",
      "    \"compression_rate\": 7.380899479386353,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:14:59,649 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 35), layer1.0.conv2:(16, 28), layer1.1.conv1:(16, 22), layer1.1.conv2:(28, 19), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:15:11,809 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(35, 48), layer1.1.conv1:(22, 16), layer1.1.conv2:(38, 38), layer2.0.conv1:(25, 44), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(89, 102), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:15:12,720 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 35), layer1.0.conv2:(16, 28), layer1.1.conv1:(16, 22), layer1.1.conv2:(28, 19), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:15:15,157 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 22), layer1.1.conv2:(28, 25), layer2.0.conv1:(16, 38), layer2.0.conv2:(32, 51), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(57, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1475826,\n",
      "    \"flops\": 304755338,\n",
      "    \"accuracy\": 0.9897,\n",
      "    \"inference_time\": 0.1667726697942001,\n",
      "    \"compression_rate\": 7.576531379715495,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:15:15,201 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(35, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(64, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:15:29,484 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(35, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(64, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:17:46,997 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(32, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(19, 25), layer1.1.conv2:(25, 48), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(64, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(102, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1528746,\n",
      "    \"flops\": 550288458,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.16234340839831438,\n",
      "    \"compression_rate\": 7.314257567967472,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:17:47,097 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(22, 28), layer1.0.conv2:(22, 16), layer1.1.conv1:(32, 22), layer1.1.conv2:(19, 28), layer2.0.conv1:(16, 76), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 09:18:01,394 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(22, 28), layer1.0.conv2:(22, 16), layer1.1.conv1:(32, 22), layer1.1.conv2:(19, 28), layer2.0.conv1:(16, 76), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1329\n",
      "Epoch 1/3, Loss: 0.1242\n",
      "Epoch 1/3, Loss: 0.1290\n",
      "Epoch 1/3, Loss: 0.1197\n",
      "Epoch 2/3, Loss: 0.0487\n",
      "Epoch 2/3, Loss: 0.0484\n",
      "Epoch 2/3, Loss: 0.0481\n",
      "Epoch 3/3, Loss: 0.0376\n",
      "Epoch 2/3, Loss: 0.0468\n",
      "Epoch 3/3, Loss: 0.0360\n",
      "Epoch 3/3, Loss: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:30:57,639 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 35), layer1.0.conv2:(16, 28), layer1.1.conv1:(16, 22), layer1.1.conv2:(28, 19), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1457226,\n",
      "    \"flops\": 300973322,\n",
      "    \"accuracy\": 0.9916,\n",
      "    \"inference_time\": 0.16419162163056134,\n",
      "    \"compression_rate\": 7.673238056416781,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:30:57,755 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(35, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(41, 32), layer2.0.conv2:(89, 57), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 179), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:31:10,216 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(35, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(41, 32), layer2.0.conv2:(89, 57), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 179), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:32:04,708 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(28, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 16), layer2.0.conv1:(35, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(64, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1592345,\n",
      "    \"flops\": 322224622,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.16222386603142805,\n",
      "    \"compression_rate\": 7.022122718380753,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:32:04,758 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(28, 25), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 25), layer1.1.conv2:(19, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(28, 70), layer2.1.conv1:(44, 51), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(76, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "/home/fmokadem/miniconda3/envs/NAS/lib/python3.9/site-packages/tensorly/tenalg/svd.py:200: UserWarning: Trying to compute SVD with n_eigenvecs=70, which is larger than max(matrix.shape)=64. Setting n_eigenvecs to 64.\n",
      "  warnings.warn(\n",
      "2025-03-30 09:32:18,903 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(28, 25), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 25), layer1.1.conv2:(19, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(28, 70), layer2.1.conv1:(44, 51), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(76, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:32:21,138 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(35, 48), layer1.1.conv1:(22, 16), layer1.1.conv2:(38, 38), layer2.0.conv1:(25, 44), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(64, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(89, 102), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1648060,\n",
      "    \"flops\": 1182453218,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.16741936323242834,\n",
      "    \"compression_rate\": 6.7847299248813755,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:32:21,187 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(22, 22), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 09:32:35,225 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(22, 22), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:35:16,802 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(22, 28), layer1.0.conv2:(22, 16), layer1.1.conv1:(32, 22), layer1.1.conv2:(19, 28), layer2.0.conv1:(16, 76), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1570923,\n",
      "    \"flops\": 714340458,\n",
      "    \"accuracy\": 0.99,\n",
      "    \"inference_time\": 0.17150477796096963,\n",
      "    \"compression_rate\": 7.117880379878581,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:35:16,912 - MainProcess - INFO - Compressing to:conv1:(1, 38), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 38), layer1.1.conv1:(32, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 09:35:16,912 - MainProcess - INFO - Evaluated 270 configurations, found 270 accepted models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:35:31,035 - MainProcess - INFO - finetuning:conv1:(1, 38), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 38), layer1.1.conv1:(32, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1373\n",
      "Epoch 1/3, Loss: 0.1298\n",
      "Epoch 2/3, Loss: 0.0489\n",
      "Epoch 1/3, Loss: 0.1311\n",
      "Epoch 2/3, Loss: 0.0501\n",
      "Epoch 2/3, Loss: 0.0492\n",
      "Epoch 3/3, Loss: 0.0368\n",
      "Epoch 2/3, Loss: 0.0482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:46:55,514 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(35, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(41, 32), layer2.0.conv2:(89, 57), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 179), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1554299,\n",
      "    \"flops\": 530176506,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.16512805944795061,\n",
      "    \"compression_rate\": 7.194009646792542,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:46:55,606 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 22), layer1.1.conv2:(28, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 179), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:47:09,502 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 22), layer1.1.conv2:(28, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 179), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:48:47,789 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(28, 25), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 25), layer1.1.conv2:(19, 32), layer2.0.conv1:(16, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(28, 70), layer2.1.conv1:(44, 51), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(76, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1499565,\n",
      "    \"flops\": 731281914,\n",
      "    \"accuracy\": 0.9907,\n",
      "    \"inference_time\": 0.16155103968966542,\n",
      "    \"compression_rate\": 7.456590411219254,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:48:47,942 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(25, 32), layer1.0.conv2:(54, 19), layer1.1.conv1:(22, 44), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(102, 38), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 09:49:01,124 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(25, 32), layer1.0.conv2:(54, 19), layer1.1.conv1:(22, 44), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(102, 38), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 09:49:35,251 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(16, 22), layer1.0.conv2:(22, 22), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 57), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1538715,\n",
      "    \"flops\": 301671866,\n",
      "    \"accuracy\": 0.9899,\n",
      "    \"inference_time\": 0.17314338987799968,\n",
      "    \"compression_rate\": 7.2668700831538,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:49:35,322 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 38), layer1.0.conv2:(28, 32), layer1.1.conv1:(22, 25), layer1.1.conv2:(35, 22), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 57), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 09:49:50,548 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 38), layer1.0.conv2:(28, 32), layer1.1.conv1:(22, 25), layer1.1.conv2:(35, 22), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 57), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 1/3, Loss: 0.1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:52:31,966 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 38), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 38), layer1.1.conv1:(32, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1524342,\n",
      "    \"flops\": 728255674,\n",
      "    \"accuracy\": 0.9899,\n",
      "    \"inference_time\": 0.1704021239230081,\n",
      "    \"compression_rate\": 7.3353893024006425,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 09:52:32,075 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 32), layer1.0.conv2:(25, 32), layer1.1.conv1:(16, 32), layer1.1.conv2:(44, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 70), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 38), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(76, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 09:52:46,714 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 32), layer1.0.conv2:(25, 32), layer1.1.conv1:(16, 32), layer1.1.conv2:(44, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 70), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 38), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(76, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1312\n",
      "Epoch 1/3, Loss: 0.1273\n",
      "Epoch 2/3, Loss: 0.0505\n",
      "Epoch 1/3, Loss: 0.1222\n",
      "Epoch 2/3, Loss: 0.0488\n",
      "Epoch 2/3, Loss: 0.0472\n",
      "Epoch 3/3, Loss: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:02:47,158 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(22, 28), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 22), layer1.1.conv2:(28, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(51, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 179), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1584991,\n",
      "    \"flops\": 321288330,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.1777707077641902,\n",
      "    \"compression_rate\": 7.054703780652383,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:02:47,298 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(22, 28), layer1.0.conv2:(22, 25), layer1.1.conv1:(22, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(48, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(32, 57), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 115), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 10:03:01,800 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(22, 28), layer1.0.conv2:(22, 25), layer1.1.conv1:(22, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(48, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(32, 57), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 115), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0372\n",
      "Epoch 2/3, Loss: 0.0460\n",
      "Epoch 3/3, Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:05:40,099 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(25, 32), layer1.0.conv2:(54, 19), layer1.1.conv1:(22, 44), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(102, 38), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(38, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1567583,\n",
      "    \"flops\": 783588042,\n",
      "    \"accuracy\": 0.9899,\n",
      "    \"inference_time\": 0.1715321657257728,\n",
      "    \"compression_rate\": 7.133046224665616,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:05:40,221 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(19, 28), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(25, 44), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 10:05:53,920 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(19, 28), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(25, 44), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 10:07:17,117 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 38), layer1.0.conv2:(28, 32), layer1.1.conv1:(22, 25), layer1.1.conv2:(35, 22), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(38, 57), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1566593,\n",
      "    \"flops\": 365558458,\n",
      "    \"accuracy\": 0.9917,\n",
      "    \"inference_time\": 0.17671487994507873,\n",
      "    \"compression_rate\": 7.1375539147691835,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:07:17,194 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 32), layer1.0.conv2:(22, 32), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:07:29,612 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 32), layer1.0.conv2:(22, 32), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:10:30,337 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(16, 32), layer1.0.conv2:(25, 32), layer1.1.conv1:(16, 32), layer1.1.conv2:(44, 16), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 70), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 38), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(76, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(102, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1617531,\n",
      "    \"flops\": 536208602,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.16804087794763523,\n",
      "    \"compression_rate\": 6.912783742629971,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:10:30,427 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(28, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:10:45,219 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(28, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0485\n",
      "Epoch 1/3, Loss: 0.1282\n",
      "Epoch 2/3, Loss: 0.0505\n",
      "Epoch 1/3, Loss: 0.1301\n",
      "Epoch 3/3, Loss: 0.0368\n",
      "Epoch 2/3, Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:18:34,223 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(22, 28), layer1.0.conv2:(22, 25), layer1.1.conv1:(22, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(48, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(32, 57), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 115), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1668309,\n",
      "    \"flops\": 403188106,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.16127465839345492,\n",
      "    \"compression_rate\": 6.7023806740837575,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:18:34,341 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 10:18:48,397 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0372\n",
      "Epoch 2/3, Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:22:16,520 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(19, 28), layer1.1.conv1:(19, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(25, 44), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(19, 44), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1515785,\n",
      "    \"flops\": 310444042,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.1630181623365722,\n",
      "    \"compression_rate\": 7.376799480137355,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:22:16,661 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(32, 16), layer1.1.conv1:(25, 22), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 102), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 10:22:16,661 - MainProcess - INFO - Evaluated 280 configurations, found 280 accepted models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:22:31,271 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(32, 16), layer1.1.conv1:(25, 22), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 102), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:24:16,459 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 32), layer1.0.conv2:(22, 32), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(89, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1516667,\n",
      "    \"flops\": 309084586,\n",
      "    \"accuracy\": 0.9912,\n",
      "    \"inference_time\": 0.1711994153931895,\n",
      "    \"compression_rate\": 7.372509588459431,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:24:16,546 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 28), layer1.0.conv2:(16, 19), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 10:24:31,339 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 28), layer1.0.conv2:(16, 19), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0375\n",
      "Epoch 1/3, Loss: 0.1227\n",
      "Epoch 2/3, Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:27:53,813 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(28, 22), layer1.1.conv1:(19, 16), layer1.1.conv2:(28, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1527918,\n",
      "    \"flops\": 301773002,\n",
      "    \"accuracy\": 0.9911,\n",
      "    \"inference_time\": 0.1660455138819992,\n",
      "    \"compression_rate\": 7.318221265800913,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:27:53,902 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 32), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 10:28:07,718 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 32), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1308\n",
      "Epoch 2/3, Loss: 0.0466\n",
      "Epoch 3/3, Loss: 0.0365\n",
      "Epoch 1/3, Loss: 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:34:18,487 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 22), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1627319,\n",
      "    \"flops\": 684531651,\n",
      "    \"accuracy\": 0.9895,\n",
      "    \"inference_time\": 0.16114112323509913,\n",
      "    \"compression_rate\": 6.871204723843327,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:34:18,592 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(25, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:34:32,937 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(25, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0354\n",
      "Epoch 2/3, Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:38:33,693 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(32, 16), layer1.1.conv1:(25, 22), layer1.1.conv2:(19, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 64), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(32, 102), layer3.1.conv1:(64, 102), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1536476,\n",
      "    \"flops\": 640779306,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.16040122028115955,\n",
      "    \"compression_rate\": 7.27745958934601,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:38:33,794 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 32), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(32, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 10:38:48,394 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 32), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(32, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1256\n",
      "Epoch 3/3, Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:41:18,046 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(16, 28), layer1.0.conv2:(16, 19), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(44, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1525776,\n",
      "    \"flops\": 300140714,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.17445311677936792,\n",
      "    \"compression_rate\": 7.328495139522446,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:41:18,149 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(35, 16), layer1.1.conv1:(32, 51), layer1.1.conv2:(25, 25), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 10:41:32,874 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(35, 16), layer1.1.conv1:(32, 51), layer1.1.conv2:(25, 25), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0473\n",
      "Epoch 3/3, Loss: 0.0386\n",
      "Epoch 1/3, Loss: 0.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:45:14,406 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(19, 32), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1500963,\n",
      "    \"flops\": 313062602,\n",
      "    \"accuracy\": 0.9903,\n",
      "    \"inference_time\": 0.16505828683290258,\n",
      "    \"compression_rate\": 7.449645327699617,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:45:14,521 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 32), layer1.1.conv2:(32, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 10:45:29,403 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 32), layer1.1.conv2:(32, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1172\n",
      "Epoch 3/3, Loss: 0.0359\n",
      "Epoch 2/3, Loss: 0.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:49:38,197 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(25, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(16, 44), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1575855,\n",
      "    \"flops\": 497440586,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.16068822107497294,\n",
      "    \"compression_rate\": 7.095603339139705,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:49:38,318 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 32), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(57, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 10:49:52,988 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 32), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(57, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1339\n",
      "Epoch 2/3, Loss: 0.0480\n",
      "Epoch 3/3, Loss: 0.0384\n",
      "Epoch 1/3, Loss: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:55:01,512 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 32), layer1.1.conv2:(22, 22), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(32, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1523888,\n",
      "    \"flops\": 514811674,\n",
      "    \"accuracy\": 0.9898,\n",
      "    \"inference_time\": 0.16338559472636813,\n",
      "    \"compression_rate\": 7.337574677404113,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:55:01,586 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(44, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(32, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 10:55:15,532 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(44, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(32, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0506\n",
      "Epoch 3/3, Loss: 0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:58:22,361 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(35, 16), layer1.1.conv1:(32, 51), layer1.1.conv2:(25, 25), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(64, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1530644,\n",
      "    \"flops\": 535428522,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.16982535647738514,\n",
      "    \"compression_rate\": 7.305187881702081,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 10:58:22,457 - MainProcess - INFO - Compressing to:conv1:(2, 28), layer1.0.conv1:(48, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 28), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 115), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 10:58:37,591 - MainProcess - INFO - finetuning:conv1:(2, 28), layer1.0.conv1:(48, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 28), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 115), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0485\n",
      "Epoch 1/3, Loss: 0.1250\n",
      "Epoch 3/3, Loss: 0.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:02:39,473 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 25), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 32), layer1.1.conv2:(32, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1493721,\n",
      "    \"flops\": 301678922,\n",
      "    \"accuracy\": 0.9897,\n",
      "    \"inference_time\": 0.1661167407997601,\n",
      "    \"compression_rate\": 7.485763405615908,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:02:39,635 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(25, 16), layer1.0.conv2:(32, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(32, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(83, 57), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:02:39,635 - MainProcess - INFO - Evaluated 290 configurations, found 290 accepted models\n",
      "2025-03-30 11:02:53,711 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(25, 16), layer1.0.conv2:(32, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(32, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(83, 57), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 1/3, Loss: 0.1332\n",
      "Epoch 2/3, Loss: 0.0497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:05:20,353 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(16, 32), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(57, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1552317,\n",
      "    \"flops\": 316828154,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.16385790749973048,\n",
      "    \"compression_rate\": 7.203194965976666,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:05:20,513 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(19, 19), layer1.0.conv2:(28, 16), layer1.1.conv1:(32, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:05:34,773 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(19, 19), layer1.0.conv2:(28, 16), layer1.1.conv1:(32, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1289\n",
      "Epoch 2/3, Loss: 0.0496\n",
      "Epoch 3/3, Loss: 0.0369\n",
      "Epoch 1/3, Loss: 0.1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:11:19,891 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(44, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(32, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1503516,\n",
      "    \"flops\": 310894058,\n",
      "    \"accuracy\": 0.9909,\n",
      "    \"inference_time\": 0.16474271073715954,\n",
      "    \"compression_rate\": 7.4369956821211085,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:11:19,972 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(22, 32), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 22), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(64, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(89, 128), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:11:34,245 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(22, 32), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 22), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(64, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(89, 128), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0476\n",
      "Epoch 3/3, Loss: 0.0371\n",
      "Epoch 2/3, Loss: 0.0504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:15:24,638 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 28), layer1.0.conv1:(48, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 28), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(32, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 115), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1510963,\n",
      "    \"flops\": 452593042,\n",
      "    \"accuracy\": 0.9896,\n",
      "    \"inference_time\": 0.16929922083633975,\n",
      "    \"compression_rate\": 7.40034137169474,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:15:24,796 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(19, 16), layer1.0.conv2:(28, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 44), layer2.0.conv1:(16, 44), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:15:38,519 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(19, 16), layer1.0.conv2:(28, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 44), layer2.0.conv1:(16, 44), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1243\n",
      "Epoch 3/3, Loss: 0.0355\n",
      "Epoch 3/3, Loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:19:58,730 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(25, 16), layer1.0.conv2:(32, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(32, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(83, 57), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1512140,\n",
      "    \"flops\": 336826426,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.16457211794114165,\n",
      "    \"compression_rate\": 7.394581189572394,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:19:58,819 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 11:20:12,429 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(179, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1228\n",
      "Epoch 2/3, Loss: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:21:01,049 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(19, 19), layer1.0.conv2:(28, 16), layer1.1.conv1:(32, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(28, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1489927,\n",
      "    \"flops\": 494046650,\n",
      "    \"accuracy\": 0.9902,\n",
      "    \"inference_time\": 0.1617798628068021,\n",
      "    \"compression_rate\": 7.504825404197655,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:21:01,153 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 35), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 51), layer2.1.conv2:(38, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 11:21:15,848 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 35), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 51), layer2.1.conv2:(38, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 11:22:08,769 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (16, 22), 'layer1.0.conv2': (22, 32), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (19, 22), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (64, 32), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (64, 89), 'layer3.0.downsample.0': (51, 64), 'layer3.1.conv1': (89, 128), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 179), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 13.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 7.21 GiB memory in use. Process 2462655 has 37.13 GiB memory in use. Of the allocated memory 6.60 GiB is allocated by PyTorch, and 208.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:22:08,792 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:22:23,381 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0469\n",
      "Epoch 1/3, Loss: 0.1271\n",
      "Epoch 1/3, Loss: 0.1373\n",
      "Epoch 1/3, Loss: 0.1362\n",
      "Epoch 3/3, Loss: 0.0362\n",
      "Epoch 2/3, Loss: 0.0505\n",
      "Epoch 2/3, Loss: 0.0507\n",
      "Epoch 2/3, Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:32:14,534 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 28), layer1.0.conv1:(19, 16), layer1.0.conv2:(28, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 44), layer2.0.conv1:(16, 44), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1489656,\n",
      "    \"flops\": 327207530,\n",
      "    \"accuracy\": 0.991,\n",
      "    \"inference_time\": 0.17279185965309227,\n",
      "    \"compression_rate\": 7.5061906910051714,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:32:14,617 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(22, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:32:28,910 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 25), layer1.0.conv2:(22, 25), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(41, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0377\n",
      "Epoch 3/3, Loss: 0.0374\n",
      "Epoch 3/3, Loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:37:01,230 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(22, 35), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 51), layer2.1.conv2:(38, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1533231,\n",
      "    \"flops\": 324632090,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.17050681245807883,\n",
      "    \"compression_rate\": 7.2928619366553376,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:37:01,360 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 25), layer1.0.conv2:(25, 16), layer1.1.conv1:(35, 38), layer1.1.conv2:(16, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(48, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(57, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(70, 64), layer3.1.conv1:(64, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 11:37:14,623 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 25), layer1.0.conv2:(25, 16), layer1.1.conv1:(35, 38), layer1.1.conv2:(16, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(48, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(57, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(70, 64), layer3.1.conv1:(64, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:37:26,642 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 35), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(179, 128)\",\n",
      "    \"params\": 1646120,\n",
      "    \"flops\": 707233498,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.1705508738313258,\n",
      "    \"compression_rate\": 6.792725925205938,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:37:26,684 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(35, 38), layer1.1.conv1:(25, 28), layer1.1.conv2:(19, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(57, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:37:41,067 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(35, 38), layer1.1.conv1:(25, 28), layer1.1.conv2:(19, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(57, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(51, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:38:21,211 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 64), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1508425,\n",
      "    \"flops\": 294767178,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.16055519818753447,\n",
      "    \"compression_rate\": 7.412792813696405,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 11:38:21,263 - MainProcess - INFO - Compressing to:conv1:(2, 35), layer1.0.conv1:(16, 48), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(22, 64), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(83, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 11:38:35,117 - MainProcess - INFO - finetuning:conv1:(2, 35), layer1.0.conv1:(16, 48), layer1.0.conv2:(22, 19), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 32), layer2.0.conv1:(19, 32), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(22, 64), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(83, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 11:38:35,394 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (16, 25), 'layer1.0.conv2': (22, 25), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (41, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (25, 32), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (51, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 23.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.11 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.62 GiB is allocated by PyTorch, and 87.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:38:35,402 - MainProcess - ERROR - Error processing config: {'conv1': (2, 35), 'layer1.0.conv1': (16, 48), 'layer1.0.conv2': (22, 19), 'layer1.1.conv1': (22, 16), 'layer1.1.conv2': (22, 32), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (51, 32), 'layer2.0.downsample.0': (22, 64), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (83, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (179, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 23.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.11 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.61 GiB is allocated by PyTorch, and 104.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:38:35,432 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(16, 25), layer1.0.conv2:(51, 28), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 38), layer2.0.conv1:(19, 44), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(48, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(115, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:38:35,438 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(25, 51), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 57), layer2.1.conv2:(32, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 140), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 11:38:49,574 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(16, 25), layer1.0.conv2:(51, 28), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 38), layer2.0.conv1:(19, 44), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(48, 32), layer2.1.conv1:(57, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(115, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:38:49,928 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(25, 51), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 19), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 57), layer2.1.conv2:(32, 57), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 140), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 11:38:51,376 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (25, 51), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (32, 19), 'layer1.1.conv2': (16, 25), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (44, 57), 'layer2.1.conv2': (32, 57), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 140), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 153)}. Error: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 5.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.13 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.33 GiB is allocated by PyTorch, and 404.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:38:51,380 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (16, 25), 'layer1.0.conv2': (25, 16), 'layer1.1.conv1': (35, 38), 'layer1.1.conv2': (16, 32), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (48, 38), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (57, 38), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (70, 64), 'layer3.1.conv1': (64, 102), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 5.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.13 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.32 GiB is allocated by PyTorch, and 417.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:38:51,404 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(35, 28), layer1.0.conv2:(19, 44), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(64, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 89), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(115, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:38:51,408 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(32, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 44), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:39:05,964 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(35, 28), layer1.0.conv2:(19, 44), layer1.1.conv1:(19, 25), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 38), layer2.0.conv2:(51, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(64, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 89), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(115, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:39:06,058 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(32, 19), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 44), layer1.1.conv2:(19, 22), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(51, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:39:12,426 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (32, 19), 'layer1.0.conv2': (16, 19), 'layer1.1.conv1': (16, 44), 'layer1.1.conv2': (19, 22), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (38, 51), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (51, 38), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 143.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.99 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.53 GiB is allocated by PyTorch, and 1.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:39:12,444 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(57, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:39:12,444 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (35, 28), 'layer1.0.conv2': (19, 44), 'layer1.1.conv1': (19, 25), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (51, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (44, 32), 'layer2.1.conv2': (51, 32), 'layer3.0.conv1': (64, 64), 'layer3.0.conv2': (89, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (89, 89), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (115, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.12 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.56 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:39:12,456 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 32), layer1.0.conv2:(25, 16), layer1.1.conv1:(35, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(44, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(204, 128), layer4.0.downsample.0:(115, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:39:26,124 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 32), layer1.0.conv2:(25, 16), layer1.1.conv1:(35, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(44, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(204, 128), layer4.0.downsample.0:(115, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:39:27,206 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 22), layer1.0.conv2:(16, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(32, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 51), layer3.0.conv1:(57, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:39:33,232 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 32), 'layer1.0.conv2': (25, 16), 'layer1.1.conv1': (35, 16), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (44, 44), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (204, 128), 'layer4.0.downsample.0': (115, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 59.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.08 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.85 GiB is allocated by PyTorch, and 841.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:39:33,245 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 57), layer2.1.conv2:(32, 89), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:39:33,250 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (19, 22), 'layer1.0.conv2': (16, 19), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (44, 44), 'layer2.0.downsample.0': (25, 44), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 51), 'layer3.0.conv1': (57, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 109.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.03 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.76 GiB is allocated by PyTorch, and 890.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:39:33,270 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 35), layer1.1.conv1:(25, 28), layer1.1.conv2:(35, 38), layer2.0.conv1:(25, 44), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(64, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:39:47,669 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(19, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(32, 57), layer2.1.conv2:(32, 89), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:39:48,203 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 35), layer1.1.conv1:(25, 28), layer1.1.conv2:(35, 38), layer2.0.conv1:(25, 44), layer2.0.conv2:(64, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(64, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:39:48,513 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (25, 28), 'layer1.0.conv2': (35, 38), 'layer1.1.conv1': (25, 28), 'layer1.1.conv2': (19, 25), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (57, 38), 'layer2.0.downsample.0': (19, 38), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (51, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 73.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.06 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.27 GiB is allocated by PyTorch, and 404.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:39:48,518 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 38), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(19, 28), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:39:48,533 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (19, 35), 'layer1.1.conv1': (25, 28), 'layer1.1.conv2': (35, 38), 'layer2.0.conv1': (25, 44), 'layer2.0.conv2': (64, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (64, 44), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 39.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.10 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.04 GiB is allocated by PyTorch, and 670.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:39:48,558 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 28), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 57), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:02,950 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 28), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 57), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:03,310 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 38), layer1.0.conv2:(19, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(19, 28), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(51, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:40:04,121 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (19, 28), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (25, 57), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (44, 89), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 107.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.03 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.51 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:40:04,132 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(22, 16), layer1.1.conv1:(38, 32), layer1.1.conv2:(16, 19), layer2.0.conv1:(32, 44), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 64), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(83, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(128, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:04,134 - MainProcess - ERROR - Error processing config: {'conv1': (2, 25), 'layer1.0.conv1': (16, 25), 'layer1.0.conv2': (51, 28), 'layer1.1.conv1': (25, 19), 'layer1.1.conv2': (16, 38), 'layer2.0.conv1': (19, 44), 'layer2.0.conv2': (51, 32), 'layer2.0.downsample.0': (48, 32), 'layer2.1.conv1': (57, 38), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (115, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 109.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.03 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.54 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:40:04,141 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(48, 25), layer1.1.conv1:(25, 25), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:17,963 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(48, 25), layer1.1.conv1:(25, 25), layer1.1.conv2:(19, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:18,485 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(22, 16), layer1.1.conv1:(38, 32), layer1.1.conv2:(16, 19), layer2.0.conv1:(32, 44), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 64), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(83, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(128, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:19,168 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (22, 25), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (38, 32), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (32, 44), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 64), 'layer3.0.conv1': (44, 89), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (83, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (128, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 133.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.00 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.28 GiB is allocated by PyTorch, and 333.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:40:19,174 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 38), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (22, 28), 'layer1.1.conv2': (19, 28), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (51, 32), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 89), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 5.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.13 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.48 GiB is allocated by PyTorch, and 250.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:40:19,200 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 35), layer1.0.conv2:(35, 22), layer1.1.conv1:(25, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:19,202 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 102), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:33,816 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 35), layer1.0.conv2:(35, 22), layer1.1.conv1:(25, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:33,911 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(22, 16), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 102), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:38,628 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (19, 35), 'layer1.0.conv2': (35, 22), 'layer1.1.conv1': (25, 19), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (16, 44), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (44, 44), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (44, 76), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 19.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.12 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.06 GiB is allocated by PyTorch, and 673.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:40:38,661 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(35, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(38, 51), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 89), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:53,512 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(35, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(38, 51), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(57, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 89), layer3.0.downsample.0:(44, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:40:56,977 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (16, 32), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (22, 16), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (19, 51), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (19, 38), 'layer2.1.conv1': (32, 57), 'layer2.1.conv2': (32, 89), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (89, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (89, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 61.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.07 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:40:56,996 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:41:11,165 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 19), layer1.0.conv2:(16, 22), layer1.1.conv1:(25, 16), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(38, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:41:14,434 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (35, 19), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (38, 51), 'layer2.0.conv2': (44, 44), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (57, 32), 'layer3.0.conv1': (38, 76), 'layer3.0.conv2': (89, 89), 'layer3.0.downsample.0': (44, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 141.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.00 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.43 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:41:14,454 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (25, 19), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (25, 16), 'layer1.1.conv2': (16, 22), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (38, 44), 'layer2.0.downsample.0': (38, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (76, 76), 'layer3.0.downsample.0': (57, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 175.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.96 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.34 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:41:14,454 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(25, 22), layer1.1.conv2:(28, 38), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:41:14,459 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 35), layer1.0.conv2:(16, 35), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(25, 44), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(44, 108), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(115, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:41:28,144 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 25), layer1.0.conv2:(16, 19), layer1.1.conv1:(25, 22), layer1.1.conv2:(28, 38), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:41:28,805 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 35), layer1.0.conv2:(16, 35), layer1.1.conv1:(16, 16), layer1.1.conv2:(22, 16), layer2.0.conv1:(25, 44), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(38, 38), layer2.1.conv1:(44, 108), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(115, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:41:29,977 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 25), 'layer1.0.conv2': (16, 19), 'layer1.1.conv1': (25, 22), 'layer1.1.conv2': (28, 38), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (32, 57), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 167.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.97 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.24 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:41:30,005 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (48, 25), 'layer1.1.conv1': (25, 25), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (22, 38), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (25, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (76, 76), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 33.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.10 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.15 GiB is allocated by PyTorch, and 1.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:41:30,018 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(38, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 19), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:41:30,019 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(25, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(25, 19), layer1.1.conv2:(22, 22), layer2.0.conv1:(28, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:41:43,776 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(25, 22), layer1.0.conv2:(19, 19), layer1.1.conv1:(25, 19), layer1.1.conv2:(22, 22), layer2.0.conv1:(28, 32), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:41:45,003 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(38, 16), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 19), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 51), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:41:50,562 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (38, 16), 'layer1.0.conv2': (22, 19), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (22, 19), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (32, 51), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (89, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 63.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.07 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.33 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:41:50,601 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 16), layer1.1.conv2:(22, 22), layer2.0.conv1:(48, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 51), layer3.0.conv1:(70, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(102, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:42:05,012 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(32, 16), layer1.1.conv2:(22, 22), layer2.0.conv1:(48, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(51, 51), layer3.0.conv1:(70, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(102, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:42:07,208 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (25, 32), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (32, 16), 'layer1.1.conv2': (22, 22), 'layer2.0.conv1': (48, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (51, 51), 'layer3.0.conv1': (70, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (102, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 155.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.98 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.44 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:42:07,225 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (25, 19), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (19, 16), 'layer1.1.conv2': (16, 25), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (51, 32), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 102), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 175.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.96 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.37 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:42:07,227 - MainProcess - INFO - Compressing to:conv1:(1, 41), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 38), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 51), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(76, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:07,230 - MainProcess - INFO - Compressing to:conv1:(1, 28), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(28, 35), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:21,262 - MainProcess - INFO - finetuning:conv1:(1, 41), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 16), layer1.1.conv1:(16, 38), layer1.1.conv2:(16, 22), layer2.0.conv1:(22, 51), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(76, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(89, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:21,262 - MainProcess - INFO - finetuning:conv1:(1, 28), layer1.0.conv1:(19, 19), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(28, 35), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:25,453 - MainProcess - ERROR - Error processing config: {'conv1': (1, 41), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (22, 16), 'layer1.1.conv1': (16, 38), 'layer1.1.conv2': (16, 22), 'layer2.0.conv1': (22, 51), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (76, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (51, 76), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (89, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 33.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.10 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:42:25,476 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 35), 'layer1.0.conv2': (16, 35), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (25, 44), 'layer2.0.conv2': (57, 32), 'layer2.0.downsample.0': (38, 38), 'layer2.1.conv1': (44, 108), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (115, 64), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (153, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 47.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.09 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.16 GiB is allocated by PyTorch, and 1.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:42:25,482 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(25, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(22, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 57), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:25,483 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 22), layer1.0.conv2:(22, 32), layer1.1.conv1:(16, 44), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:39,640 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 22), layer1.0.conv2:(22, 32), layer1.1.conv1:(16, 44), layer1.1.conv2:(19, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(38, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:39,713 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(25, 22), layer1.0.conv2:(16, 16), layer1.1.conv1:(22, 28), layer1.1.conv2:(22, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 57), layer2.1.conv2:(32, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:41,156 - MainProcess - ERROR - Error processing config: {'conv1': (1, 28), 'layer1.0.conv1': (19, 19), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (28, 16), 'layer1.1.conv2': (28, 35), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 139.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.00 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.86 GiB is allocated by PyTorch, and 754.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:42:41,173 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(35, 51), layer2.1.conv1:(32, 76), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:41,179 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (25, 22), 'layer1.0.conv2': (22, 32), 'layer1.1.conv1': (16, 44), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (44, 44), 'layer2.0.downsample.0': (38, 44), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (44, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (44, 89), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 61.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.07 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.44 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:42:41,200 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 19), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(25, 32), layer2.0.conv1:(35, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:55,372 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(19, 25), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(35, 38), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(35, 51), layer2.1.conv1:(32, 76), layer2.1.conv2:(32, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 64), layer4.0.conv1:(76, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:42:55,456 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 19), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 25), layer1.1.conv2:(25, 32), layer2.0.conv1:(35, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:43:02,506 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (16, 19), 'layer1.0.conv2': (28, 16), 'layer1.1.conv1': (16, 25), 'layer1.1.conv2': (25, 32), 'layer2.0.conv1': (35, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (19, 38), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 91.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.04 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:43:02,535 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 35), layer1.0.conv2:(38, 44), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(64, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:43:16,714 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 35), layer1.0.conv2:(38, 44), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(64, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(57, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:43:17,347 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (25, 35), 'layer1.0.conv2': (38, 44), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (19, 25), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (64, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (57, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 85.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.05 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.47 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:43:17,377 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(19, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(28, 70), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:43:31,396 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(19, 16), layer1.1.conv2:(19, 19), layer2.0.conv1:(28, 70), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:43:36,123 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (25, 22), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (22, 28), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (22, 38), 'layer2.0.conv2': (38, 44), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (32, 57), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (44, 89), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 107.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.03 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.31 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:43:36,198 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(22, 32), layer1.0.conv2:(28, 19), layer1.1.conv1:(25, 38), layer1.1.conv2:(51, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(89, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 153)\n",
      "2025-03-30 11:43:51,237 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(22, 32), layer1.0.conv2:(28, 19), layer1.1.conv1:(25, 38), layer1.1.conv2:(51, 22), layer2.0.conv1:(22, 32), layer2.0.conv2:(89, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 102), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 153)\n",
      "2025-03-30 11:43:57,623 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (16, 19), 'layer1.1.conv1': (19, 16), 'layer1.1.conv2': (19, 19), 'layer2.0.conv1': (28, 70), 'layer2.0.conv2': (44, 38), 'layer2.0.downsample.0': (16, 51), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 141.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.00 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.50 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:43:57,644 - MainProcess - ERROR - Error processing config: {'conv1': (1, 25), 'layer1.0.conv1': (25, 22), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (25, 19), 'layer1.1.conv2': (22, 22), 'layer2.0.conv1': (28, 32), 'layer2.0.conv2': (38, 44), 'layer2.0.downsample.0': (22, 44), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 189.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.95 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.42 GiB is allocated by PyTorch, and 1.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:43:57,652 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(44, 28), layer1.0.conv2:(32, 19), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 32), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(76, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n",
      "2025-03-30 11:43:57,654 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(44, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 38), layer1.1.conv2:(16, 41), layer2.0.conv1:(19, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:44:12,257 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(44, 32), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 38), layer1.1.conv2:(16, 41), layer2.0.conv1:(19, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 51), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:44:12,804 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(44, 28), layer1.0.conv2:(32, 19), layer1.1.conv1:(16, 28), layer1.1.conv2:(19, 32), layer2.0.conv1:(25, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(28, 44), layer2.1.conv1:(32, 38), layer2.1.conv2:(38, 32), layer3.0.conv1:(76, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 179)\n",
      "2025-03-30 11:44:18,642 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (44, 28), 'layer1.0.conv2': (32, 19), 'layer1.1.conv1': (16, 28), 'layer1.1.conv2': (19, 32), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (28, 44), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (76, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 179)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 51.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.08 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.47 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:44:18,651 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (22, 32), 'layer1.0.conv2': (28, 19), 'layer1.1.conv1': (25, 38), 'layer1.1.conv2': (51, 22), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (89, 38), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (44, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (89, 102), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (179, 153)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 53.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.08 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.39 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:44:18,656 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(32, 22), layer1.0.conv2:(28, 22), layer1.1.conv1:(32, 35), layer1.1.conv2:(19, 32), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 102), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:44:18,657 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(44, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 25), layer1.1.conv2:(22, 25), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(44, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:44:33,059 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(32, 22), layer1.0.conv2:(28, 22), layer1.1.conv1:(32, 35), layer1.1.conv2:(19, 32), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 102), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:44:33,143 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(44, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 25), layer1.1.conv2:(22, 25), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(44, 44), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:44:40,509 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (44, 16), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (16, 25), 'layer1.1.conv2': (22, 25), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (41, 38), 'layer2.1.conv1': (44, 44), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 179), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 63.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.07 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.32 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:44:40,568 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 28), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:44:55,500 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 28), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(28, 38), layer2.1.conv1:(38, 44), layer2.1.conv2:(38, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(115, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:44:56,640 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (16, 28), 'layer1.0.conv2': (28, 16), 'layer1.1.conv1': (16, 28), 'layer1.1.conv2': (22, 25), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (28, 38), 'layer2.1.conv1': (38, 44), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (51, 64), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (115, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 73.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.06 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.52 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:44:56,655 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (32, 22), 'layer1.0.conv2': (28, 22), 'layer1.1.conv1': (32, 35), 'layer1.1.conv2': (19, 32), 'layer2.0.conv1': (16, 44), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (25, 38), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (38, 44), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (76, 102), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 75.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.06 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.55 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:44:56,660 - MainProcess - INFO - Compressing to:conv1:(1, 44), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 38), layer1.1.conv2:(28, 16), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:44:56,662 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(44, 28), layer1.0.conv2:(19, 25), layer1.1.conv1:(22, 25), layer1.1.conv2:(28, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 51), layer2.1.conv1:(51, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:45:11,068 - MainProcess - INFO - finetuning:conv1:(1, 44), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 16), layer1.1.conv1:(28, 38), layer1.1.conv2:(28, 16), layer2.0.conv1:(32, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:45:11,167 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(44, 28), layer1.0.conv2:(19, 25), layer1.1.conv1:(22, 25), layer1.1.conv2:(28, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(22, 51), layer2.1.conv1:(51, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:45:17,896 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (44, 28), 'layer1.0.conv2': (19, 25), 'layer1.1.conv1': (22, 25), 'layer1.1.conv2': (28, 16), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (22, 51), 'layer2.1.conv1': (51, 32), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (76, 89), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 89), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 69.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.07 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.43 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:45:17,933 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(25, 38), layer1.1.conv1:(22, 22), layer1.1.conv2:(19, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:45:32,421 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 28), layer1.0.conv2:(25, 38), layer1.1.conv1:(22, 22), layer1.1.conv2:(19, 38), layer2.0.conv1:(16, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:45:35,552 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (16, 28), 'layer1.0.conv2': (25, 38), 'layer1.1.conv1': (22, 22), 'layer1.1.conv2': (19, 38), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (44, 44), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (44, 76), 'layer3.0.conv2': (76, 76), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 141.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.00 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.53 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:45:35,565 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (19, 25), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (35, 38), 'layer2.0.conv2': (32, 44), 'layer2.0.downsample.0': (35, 51), 'layer2.1.conv1': (32, 76), 'layer2.1.conv2': (32, 51), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (89, 64), 'layer4.0.conv1': (76, 153), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 143.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.99 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.53 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:45:35,571 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(25, 41), layer1.1.conv2:(16, 44), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 64), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:45:35,573 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 22), layer1.0.conv2:(22, 48), layer1.1.conv1:(16, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:45:49,618 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(19, 19), layer1.1.conv1:(25, 41), layer1.1.conv2:(16, 44), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(44, 64), layer3.0.conv1:(38, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:45:50,588 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 22), layer1.0.conv2:(22, 48), layer1.1.conv1:(16, 28), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 51), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 64), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 11:45:52,471 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (19, 22), 'layer1.0.conv2': (22, 48), 'layer1.1.conv1': (16, 28), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (22, 51), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (25, 44), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 64), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 157.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.98 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.50 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:45:52,479 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(32, 19), layer1.0.conv2:(19, 28), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 44), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(32, 44), layer2.1.conv2:(51, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:45:52,480 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (44, 32), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (28, 38), 'layer1.1.conv2': (16, 41), 'layer2.0.conv1': (19, 51), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (44, 51), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 193.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.95 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.49 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:45:52,487 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(22, 28), layer1.0.conv2:(16, 41), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 25), layer2.0.conv1:(28, 64), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 38), layer2.1.conv2:(64, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 11:46:06,647 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(32, 19), layer1.0.conv2:(19, 28), layer1.1.conv1:(19, 16), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 44), layer2.0.conv2:(44, 38), layer2.0.downsample.0:(41, 44), layer2.1.conv1:(32, 44), layer2.1.conv2:(51, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 153), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:46:07,754 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(22, 28), layer1.0.conv2:(16, 41), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 25), layer2.0.conv1:(28, 64), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(44, 38), layer2.1.conv2:(64, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 11:46:51,074 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (32, 19), 'layer1.0.conv2': (19, 28), 'layer1.1.conv1': (19, 16), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (25, 44), 'layer2.0.conv2': (44, 38), 'layer2.0.downsample.0': (41, 44), 'layer2.1.conv1': (32, 44), 'layer2.1.conv2': (51, 51), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (89, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 153), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 21.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.11 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.44 GiB is allocated by PyTorch, and 1.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:46:51,140 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 32), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(16, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 11:47:05,343 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 32), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(16, 44), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(41, 38), layer2.1.conv1:(44, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 11:47:06,095 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (19, 32), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (16, 44), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (41, 38), 'layer2.1.conv1': (44, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (44, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 153)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 187.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.95 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.43 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:47:06,113 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 32), layer1.1.conv1:(22, 25), layer1.1.conv2:(25, 25), layer2.0.conv1:(28, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:47:20,197 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(16, 19), layer1.0.conv2:(22, 32), layer1.1.conv1:(22, 25), layer1.1.conv2:(25, 25), layer2.0.conv1:(28, 32), layer2.0.conv2:(44, 44), layer2.0.downsample.0:(16, 57), layer2.1.conv1:(38, 32), layer2.1.conv2:(44, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:47:30,053 - MainProcess - ERROR - Error processing config: {'conv1': (1, 25), 'layer1.0.conv1': (16, 19), 'layer1.0.conv2': (22, 32), 'layer1.1.conv1': (22, 25), 'layer1.1.conv2': (25, 25), 'layer2.0.conv1': (28, 32), 'layer2.0.conv2': (44, 44), 'layer2.0.downsample.0': (16, 57), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 159.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.98 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.89 GiB is allocated by PyTorch, and 700.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:47:30,086 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(64, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:47:30,088 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (22, 28), 'layer1.0.conv2': (16, 41), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (19, 25), 'layer2.0.conv1': (28, 64), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (44, 38), 'layer2.1.conv2': (64, 44), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 76), 'layer3.0.downsample.0': (57, 76), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (179, 128)}. Error: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 5.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.13 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.57 GiB is allocated by PyTorch, and 163.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:47:30,101 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 35), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(44, 44), layer2.1.conv2:(44, 38), layer3.0.conv1:(57, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:47:43,691 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 35), layer1.0.conv2:(19, 16), layer1.1.conv1:(16, 16), layer1.1.conv2:(19, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 38), layer2.1.conv1:(44, 44), layer2.1.conv2:(44, 38), layer3.0.conv1:(57, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:47:45,140 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(19, 16), layer1.0.conv2:(19, 28), layer1.1.conv1:(16, 22), layer1.1.conv2:(22, 19), layer2.0.conv1:(16, 32), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(64, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:47:51,164 - MainProcess - ERROR - Error processing config: {'conv1': (1, 44), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (28, 38), 'layer1.1.conv2': (28, 16), 'layer2.0.conv1': (32, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (32, 38), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 35.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.10 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.49 GiB is allocated by PyTorch, and 213.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:47:51,216 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 35), layer1.0.conv2:(19, 38), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 179), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:48:04,417 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 35), layer1.0.conv2:(19, 38), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(57, 32), layer2.0.downsample.0:(22, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 179), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:48:28,868 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (19, 28), 'layer1.1.conv1': (16, 22), 'layer1.1.conv2': (22, 19), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (38, 51), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (38, 32), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (64, 76), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 37.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.10 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.45 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:48:28,876 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (16, 35), 'layer1.0.conv2': (19, 38), 'layer1.1.conv1': (32, 16), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (57, 32), 'layer2.0.downsample.0': (22, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (38, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (89, 76), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 179), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 37.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.10 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.28 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:48:28,881 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(44, 25), layer1.0.conv2:(22, 22), layer1.1.conv1:(25, 25), layer1.1.conv2:(25, 22), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(25, 57), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:48:28,883 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(25, 16), layer1.1.conv2:(41, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(76, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:48:43,456 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(44, 25), layer1.0.conv2:(22, 22), layer1.1.conv1:(25, 25), layer1.1.conv2:(25, 22), layer2.0.conv1:(25, 32), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(25, 57), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 38), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:48:43,495 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(25, 16), layer1.0.conv2:(19, 19), layer1.1.conv1:(25, 16), layer1.1.conv2:(41, 19), layer2.0.conv1:(19, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(25, 38), layer2.1.conv1:(32, 32), layer2.1.conv2:(32, 44), layer3.0.conv1:(51, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(57, 76), layer3.1.conv1:(76, 89), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:48:45,058 - MainProcess - ERROR - Error processing config: {'conv1': (2, 16), 'layer1.0.conv1': (25, 16), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (25, 16), 'layer1.1.conv2': (41, 19), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (25, 38), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (57, 76), 'layer3.1.conv1': (76, 89), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 123.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.01 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.49 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:48:45,076 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (16, 35), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (19, 22), 'layer2.0.conv1': (19, 44), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (19, 38), 'layer2.1.conv1': (44, 44), 'layer2.1.conv2': (44, 38), 'layer3.0.conv1': (57, 76), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 195.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.94 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.63 GiB is allocated by PyTorch, and 933.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:48:45,082 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(28, 38), layer1.1.conv2:(16, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:48:45,084 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 32), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 57), layer2.1.conv2:(51, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:48:59,926 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 28), layer1.0.conv2:(16, 16), layer1.1.conv1:(28, 38), layer1.1.conv2:(16, 19), layer2.0.conv1:(22, 38), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(32, 38), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:49:00,015 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 22), layer1.1.conv1:(16, 32), layer1.1.conv2:(22, 22), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 57), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(32, 57), layer2.1.conv2:(51, 32), layer3.0.conv1:(44, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:49:16,199 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (16, 22), 'layer1.1.conv1': (16, 32), 'layer1.1.conv2': (22, 22), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (32, 57), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (32, 57), 'layer2.1.conv2': (51, 32), 'layer3.0.conv1': (44, 76), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 17.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.12 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.36 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:49:16,207 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (22, 19), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (25, 41), 'layer1.1.conv2': (16, 44), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (44, 64), 'layer3.0.conv1': (38, 76), 'layer3.0.conv2': (89, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (153, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 49.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.09 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.19 GiB is allocated by PyTorch, and 1.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:49:16,215 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(32, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:49:16,217 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(19, 28), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 44), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 51), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:49:30,056 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(19, 28), layer1.0.conv2:(28, 16), layer1.1.conv1:(16, 44), layer1.1.conv2:(22, 25), layer2.0.conv1:(16, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(32, 51), layer2.1.conv2:(38, 38), layer3.0.conv1:(44, 76), layer3.0.conv2:(89, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:49:31,428 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(32, 19), layer1.0.conv2:(22, 19), layer1.1.conv1:(16, 16), layer1.1.conv2:(16, 16), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(38, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 89), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 89), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:49:38,039 - MainProcess - ERROR - Error processing config: {'conv1': (1, 19), 'layer1.0.conv1': (19, 28), 'layer1.0.conv2': (28, 16), 'layer1.1.conv1': (16, 44), 'layer1.1.conv2': (22, 25), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (16, 51), 'layer2.1.conv1': (32, 51), 'layer2.1.conv2': (38, 38), 'layer3.0.conv1': (44, 76), 'layer3.0.conv2': (89, 64), 'layer3.0.downsample.0': (38, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 11.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.12 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.17 GiB is allocated by PyTorch, and 1.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:49:38,073 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(41, 35), layer1.1.conv2:(16, 32), layer2.0.conv1:(28, 38), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(35, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:49:38,128 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (44, 25), 'layer1.0.conv2': (22, 22), 'layer1.1.conv1': (25, 25), 'layer1.1.conv2': (25, 22), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (44, 32), 'layer2.0.downsample.0': (25, 57), 'layer2.1.conv1': (32, 44), 'layer2.1.conv2': (44, 38), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 195.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.94 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 3.80 GiB is allocated by PyTorch, and 1.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:49:38,152 - MainProcess - INFO - Compressing to:conv1:(1, 25), layer1.0.conv1:(22, 25), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(28, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-30 11:49:51,765 - MainProcess - INFO - finetuning:conv1:(1, 25), layer1.0.conv1:(22, 25), layer1.0.conv2:(19, 19), layer1.1.conv1:(16, 19), layer1.1.conv2:(22, 16), layer2.0.conv1:(28, 38), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(44, 51), layer2.1.conv2:(32, 38), layer3.0.conv1:(64, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(153, 153)\n",
      "2025-03-30 11:49:51,856 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(41, 35), layer1.1.conv2:(16, 32), layer2.0.conv1:(28, 38), layer2.0.conv2:(38, 51), layer2.0.downsample.0:(35, 32), layer2.1.conv1:(44, 32), layer2.1.conv2:(44, 38), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 76), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:50:04,874 - MainProcess - ERROR - Error processing config: {'conv1': (2, 19), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (16, 19), 'layer1.1.conv1': (41, 35), 'layer1.1.conv2': (16, 32), 'layer2.0.conv1': (28, 38), 'layer2.0.conv2': (38, 51), 'layer2.0.downsample.0': (35, 32), 'layer2.1.conv1': (44, 32), 'layer2.1.conv2': (44, 38), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 9.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.12 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.20 GiB is allocated by PyTorch, and 532.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:50:04,945 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(57, 41), layer1.1.conv1:(25, 22), layer1.1.conv2:(51, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(70, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:50:19,477 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 16), layer1.0.conv2:(57, 41), layer1.1.conv1:(25, 22), layer1.1.conv2:(51, 25), layer2.0.conv1:(19, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(22, 44), layer2.1.conv1:(32, 32), layer2.1.conv2:(70, 44), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(76, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:50:38,708 - MainProcess - ERROR - Error processing config: {'conv1': (2, 25), 'layer1.0.conv1': (32, 19), 'layer1.0.conv2': (22, 19), 'layer1.1.conv1': (16, 16), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (32, 44), 'layer2.0.downsample.0': (16, 32), 'layer2.1.conv1': (38, 38), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (32, 89), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 89), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 173.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 5.96 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.25 GiB is allocated by PyTorch, and 317.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:50:38,754 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 35), layer1.1.conv1:(35, 22), layer1.1.conv2:(28, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:50:53,488 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 35), layer1.1.conv1:(35, 22), layer1.1.conv2:(28, 19), layer2.0.conv1:(22, 32), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(51, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:51:02,528 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (22, 16), 'layer1.0.conv2': (57, 41), 'layer1.1.conv1': (25, 22), 'layer1.1.conv2': (51, 25), 'layer2.0.conv1': (19, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (22, 44), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (70, 44), 'layer3.0.conv1': (57, 64), 'layer3.0.conv2': (64, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (76, 76), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 73.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.06 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.17 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:51:02,535 - MainProcess - ERROR - Error processing config: {'conv1': (1, 25), 'layer1.0.conv1': (22, 25), 'layer1.0.conv2': (19, 19), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (22, 16), 'layer2.0.conv1': (28, 38), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (44, 51), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (64, 64), 'layer3.0.conv2': (76, 76), 'layer3.0.downsample.0': (51, 76), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 179), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (153, 128), 'layer4.1.conv2': (153, 153)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 73.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.06 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.06 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:51:02,544 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(32, 54), layer1.0.conv2:(28, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(57, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 102), layer3.0.downsample.0:(44, 102), layer3.1.conv1:(89, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:51:02,545 - MainProcess - INFO - Compressing to:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 28), layer1.1.conv1:(19, 22), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 44), layer2.1.conv1:(64, 38), layer2.1.conv2:(64, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:51:16,968 - MainProcess - INFO - finetuning:conv1:(1, 22), layer1.0.conv1:(16, 16), layer1.0.conv2:(22, 28), layer1.1.conv1:(19, 22), layer1.1.conv2:(28, 22), layer2.0.conv1:(19, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(35, 44), layer2.1.conv1:(64, 38), layer2.1.conv2:(64, 44), layer3.0.conv1:(38, 64), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:51:17,019 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(32, 54), layer1.0.conv2:(28, 22), layer1.1.conv1:(16, 19), layer1.1.conv2:(19, 16), layer2.0.conv1:(16, 32), layer2.0.conv2:(57, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 51), layer3.0.conv1:(32, 64), layer3.0.conv2:(76, 102), layer3.0.downsample.0:(44, 102), layer3.1.conv1:(89, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:51:49,272 - MainProcess - ERROR - Error processing config: {'conv1': (1, 22), 'layer1.0.conv1': (16, 16), 'layer1.0.conv2': (22, 28), 'layer1.1.conv1': (19, 22), 'layer1.1.conv2': (28, 22), 'layer2.0.conv1': (19, 44), 'layer2.0.conv2': (32, 38), 'layer2.0.downsample.0': (35, 44), 'layer2.1.conv1': (64, 38), 'layer2.1.conv2': (64, 44), 'layer3.0.conv1': (38, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (76, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 67.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.07 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.19 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:51:49,288 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(32, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 204), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:51:49,288 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (19, 28), 'layer1.0.conv2': (16, 16), 'layer1.1.conv1': (28, 38), 'layer1.1.conv2': (16, 19), 'layer2.0.conv1': (22, 38), 'layer2.0.conv2': (51, 38), 'layer2.0.downsample.0': (32, 38), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (32, 38), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 76), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 107.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.03 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.19 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:51:49,298 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 57), layer1.0.conv2:(19, 16), layer1.1.conv1:(35, 28), layer1.1.conv2:(16, 35), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 44), layer2.1.conv1:(44, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(128, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 11:52:03,169 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 57), layer1.0.conv2:(19, 16), layer1.1.conv1:(35, 28), layer1.1.conv2:(16, 35), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 44), layer2.1.conv1:(44, 44), layer2.1.conv2:(32, 44), layer3.0.conv1:(32, 64), layer3.0.conv2:(89, 76), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(128, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 179), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 11:52:03,257 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 28), layer1.0.conv2:(32, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 44), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(64, 102), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 204), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 153), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:52:34,804 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (32, 54), 'layer1.0.conv2': (28, 22), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (19, 16), 'layer2.0.conv1': (16, 32), 'layer2.0.conv2': (57, 38), 'layer2.0.downsample.0': (16, 44), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (38, 51), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 102), 'layer3.0.downsample.0': (44, 102), 'layer3.1.conv1': (89, 76), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 153), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 49.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.09 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 4.19 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:52:34,832 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 38), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(64, 44), layer2.1.conv2:(38, 44), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:52:49,358 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(22, 25), layer1.0.conv2:(19, 22), layer1.1.conv1:(22, 16), layer1.1.conv2:(22, 38), layer2.0.conv1:(16, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(16, 51), layer2.1.conv1:(64, 44), layer2.1.conv2:(38, 44), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 76), layer3.1.conv1:(64, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:53:05,052 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (22, 25), 'layer1.0.conv2': (19, 22), 'layer1.1.conv1': (22, 16), 'layer1.1.conv2': (22, 38), 'layer2.0.conv1': (16, 38), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (16, 51), 'layer2.1.conv1': (64, 44), 'layer2.1.conv2': (38, 44), 'layer3.0.conv1': (44, 89), 'layer3.0.conv2': (64, 76), 'layer3.0.downsample.0': (51, 76), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (76, 64), 'layer4.0.conv1': (89, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 45.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.09 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.36 GiB is allocated by PyTorch, and 335.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:53:05,056 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (25, 28), 'layer1.0.conv2': (32, 16), 'layer1.1.conv1': (16, 19), 'layer1.1.conv2': (16, 16), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (32, 44), 'layer2.0.downsample.0': (19, 32), 'layer2.1.conv1': (32, 32), 'layer2.1.conv2': (38, 44), 'layer3.0.conv1': (44, 64), 'layer3.0.conv2': (64, 102), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (76, 76), 'layer3.1.conv2': (64, 76), 'layer4.0.conv1': (64, 204), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 45.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.09 GiB memory in use. Process 2462655 has 38.22 GiB memory in use. Of the allocated memory 5.35 GiB is allocated by PyTorch, and 347.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 11:53:05,123 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 25), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 11:53:05,127 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(25, 25), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 32), layer1.1.conv2:(41, 54), layer2.0.conv1:(32, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(32, 51), layer2.1.conv1:(44, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 115), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 11:53:19,853 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(25, 25), layer1.0.conv2:(16, 25), layer1.1.conv1:(16, 32), layer1.1.conv2:(41, 54), layer2.0.conv1:(32, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(32, 51), layer2.1.conv1:(44, 44), layer2.1.conv2:(44, 32), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 115), layer3.0.downsample.0:(38, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(179, 128)\n",
      "2025-03-30 11:53:19,943 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 25), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1321\n",
      "Epoch 1/3, Loss: 0.1156\n",
      "Epoch 1/3, Loss: 0.1289\n",
      "Epoch 1/3, Loss: 0.1272\n",
      "Epoch 2/3, Loss: 0.0490\n",
      "Epoch 2/3, Loss: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:03:03,136 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (19, 16), 'layer1.0.conv2': (16, 35), 'layer1.1.conv1': (35, 22), 'layer1.1.conv2': (28, 19), 'layer2.0.conv1': (22, 32), 'layer2.0.conv2': (38, 32), 'layer2.0.downsample.0': (16, 38), 'layer2.1.conv1': (51, 32), 'layer2.1.conv2': (32, 32), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (76, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (153, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 23.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.47 GiB memory in use. Process 2462655 has 37.86 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 255.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 12:03:03,165 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(22, 25), layer1.0.conv2:(25, 22), layer1.1.conv1:(28, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(38, 51), layer2.1.conv1:(38, 32), layer2.1.conv2:(64, 57), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:03:17,864 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(22, 25), layer1.0.conv2:(25, 22), layer1.1.conv1:(28, 22), layer1.1.conv2:(16, 25), layer2.0.conv1:(19, 38), layer2.0.conv2:(38, 38), layer2.0.downsample.0:(38, 51), layer2.1.conv1:(38, 32), layer2.1.conv2:(64, 57), layer3.0.conv1:(32, 76), layer3.0.conv2:(76, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 153), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:04:47,466 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (16, 57), 'layer1.0.conv2': (19, 16), 'layer1.1.conv1': (35, 28), 'layer1.1.conv2': (16, 35), 'layer2.0.conv1': (25, 32), 'layer2.0.conv2': (32, 32), 'layer2.0.downsample.0': (32, 44), 'layer2.1.conv1': (44, 44), 'layer2.1.conv2': (32, 44), 'layer3.0.conv1': (32, 64), 'layer3.0.conv2': (89, 76), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (128, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 179), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 153), 'layer4.1.conv2': (128, 153)}. Error: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 141.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.07 GiB memory in use. Process 2462655 has 38.15 GiB memory in use. Of the allocated memory 5.05 GiB is allocated by PyTorch, and 629.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 12:04:47,487 - MainProcess - INFO - Compressing to:conv1:(2, 22), layer1.0.conv1:(16, 38), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 70), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 64), layer2.1.conv2:(32, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:05:01,202 - MainProcess - INFO - finetuning:conv1:(2, 22), layer1.0.conv1:(16, 38), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 70), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 64), layer2.1.conv2:(32, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:05:09,971 - MainProcess - ERROR - Error processing config: {'conv1': (1, 16), 'layer1.0.conv1': (25, 25), 'layer1.0.conv2': (16, 25), 'layer1.1.conv1': (16, 32), 'layer1.1.conv2': (41, 54), 'layer2.0.conv1': (32, 38), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (32, 51), 'layer2.1.conv1': (44, 44), 'layer2.1.conv2': (44, 32), 'layer3.0.conv1': (51, 64), 'layer3.0.conv2': (64, 115), 'layer3.0.downsample.0': (38, 64), 'layer3.1.conv1': (64, 64), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 128), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (76, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (179, 128)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 49.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.16 GiB memory in use. Process 2462655 has 38.15 GiB memory in use. Of the allocated memory 5.54 GiB is allocated by PyTorch, and 219.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 12:05:09,976 - MainProcess - ERROR - Error processing config: {'conv1': (2, 22), 'layer1.0.conv1': (22, 25), 'layer1.0.conv2': (25, 22), 'layer1.1.conv1': (28, 22), 'layer1.1.conv2': (16, 25), 'layer2.0.conv1': (19, 38), 'layer2.0.conv2': (38, 38), 'layer2.0.downsample.0': (38, 51), 'layer2.1.conv1': (38, 32), 'layer2.1.conv2': (64, 57), 'layer3.0.conv1': (32, 76), 'layer3.0.conv2': (76, 64), 'layer3.0.downsample.0': (32, 64), 'layer3.1.conv1': (64, 76), 'layer3.1.conv2': (64, 64), 'layer4.0.conv1': (64, 153), 'layer4.0.conv2': (128, 128), 'layer4.0.downsample.0': (64, 128), 'layer4.1.conv1': (128, 128), 'layer4.1.conv2': (128, 153)}. Error: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 49.12 MiB is free. Process 3928929 has 3.16 GiB memory in use. Including non-PyTorch memory, this process has 6.16 GiB memory in use. Process 2462655 has 38.15 GiB memory in use. Of the allocated memory 5.54 GiB is allocated by PyTorch, and 219.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "2025-03-30 12:05:10,010 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(32, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(140, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:05:10,012 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(25, 19), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 35), layer2.0.conv1:(25, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:05:24,764 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(32, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(140, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:05:24,848 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(25, 19), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 35), layer2.0.conv1:(25, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0367\n",
      "Epoch 1/3, Loss: 0.1238\n",
      "Epoch 1/3, Loss: 0.1426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:10:26,015 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(16, 16), layer1.0.conv2:(16, 16), layer1.1.conv1:(28, 16), layer1.1.conv2:(25, 25), layer2.0.conv1:(22, 32), layer2.0.conv2:(32, 32), layer2.0.downsample.0:(32, 32), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 44), layer3.0.conv1:(44, 89), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1478310,\n",
      "    \"flops\": 298708346,\n",
      "    \"accuracy\": 0.9894,\n",
      "    \"inference_time\": 0.16846890004070955,\n",
      "    \"compression_rate\": 7.563800556040343,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:10:26,083 - MainProcess - INFO - Compressing to:conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(35, 19), layer1.1.conv1:(16, 41), layer1.1.conv2:(32, 16), layer2.0.conv1:(48, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(51, 44), layer2.1.conv2:(51, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:10:26,083 - MainProcess - INFO - Evaluated 300 configurations, found 300 accepted models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:10:40,596 - MainProcess - INFO - finetuning:conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(35, 19), layer1.1.conv1:(16, 41), layer1.1.conv2:(32, 16), layer2.0.conv1:(48, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(51, 44), layer2.1.conv2:(51, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0512\n",
      "Epoch 2/3, Loss: 0.0477\n",
      "Epoch 1/3, Loss: 0.1312\n",
      "Epoch 2/3, Loss: 0.0473\n",
      "Epoch 3/3, Loss: 0.0378\n",
      "Epoch 3/3, Loss: 0.0360\n",
      "Epoch 2/3, Loss: 0.0492\n",
      "Epoch 3/3, Loss: 0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:21:49,674 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 19), layer1.0.conv2:(32, 25), layer1.1.conv1:(16, 22), layer1.1.conv2:(25, 19), layer2.0.conv1:(19, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(28, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(38, 38), layer3.0.conv1:(32, 76), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 89), layer3.1.conv1:(64, 64), layer3.1.conv2:(140, 64), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 153), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1566268,\n",
      "    \"flops\": 326629722,\n",
      "    \"accuracy\": 0.9913,\n",
      "    \"inference_time\": 0.17703578527819075,\n",
      "    \"compression_rate\": 7.139034954426701,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:21:49,829 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(25, 51), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 57), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 128), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:22:04,420 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(25, 51), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 57), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 128), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:22:30,209 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 22), layer1.0.conv1:(16, 38), layer1.0.conv2:(25, 19), layer1.1.conv1:(19, 25), layer1.1.conv2:(22, 22), layer2.0.conv1:(22, 44), layer2.0.conv2:(44, 70), layer2.0.downsample.0:(16, 38), layer2.1.conv1:(38, 64), layer2.1.conv2:(32, 44), layer3.0.conv1:(44, 64), layer3.0.conv2:(76, 76), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(76, 64), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1526467,\n",
      "    \"flops\": 349728714,\n",
      "    \"accuracy\": 0.992,\n",
      "    \"inference_time\": 0.19010273008083337,\n",
      "    \"compression_rate\": 7.325177681535205,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:22:30,237 - MainProcess - INFO - Compressing to:conv1:(1, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(35, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:22:45,570 - MainProcess - INFO - finetuning:conv1:(1, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(35, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:23:10,751 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(22, 16), layer1.0.conv2:(25, 19), layer1.1.conv1:(25, 19), layer1.1.conv2:(16, 35), layer2.0.conv1:(25, 51), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(38, 32), layer2.1.conv2:(32, 32), layer3.0.conv1:(38, 76), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(44, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(76, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1497610,\n",
      "    \"flops\": 313853658,\n",
      "    \"accuracy\": 0.9905,\n",
      "    \"inference_time\": 0.17301752967186543,\n",
      "    \"compression_rate\": 7.466324343453903,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:23:10,805 - MainProcess - INFO - Compressing to:conv1:(1, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 48), layer1.1.conv2:(22, 22), layer2.0.conv1:(38, 44), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(16, 64), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n",
      "2025-03-30 12:23:26,532 - MainProcess - INFO - finetuning:conv1:(1, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 48), layer1.1.conv2:(22, 22), layer2.0.conv1:(38, 44), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(16, 64), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0368\n",
      "Epoch 1/3, Loss: 0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:27:12,054 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 19), layer1.0.conv1:(16, 22), layer1.0.conv2:(35, 19), layer1.1.conv1:(16, 41), layer1.1.conv2:(32, 16), layer2.0.conv1:(48, 38), layer2.0.conv2:(44, 32), layer2.0.downsample.0:(22, 38), layer2.1.conv1:(51, 44), layer2.1.conv2:(51, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 76), layer3.0.downsample.0:(51, 64), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(89, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(153, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1599732,\n",
      "    \"flops\": 353079530,\n",
      "    \"accuracy\": 0.9914,\n",
      "    \"inference_time\": 0.1621134073617858,\n",
      "    \"compression_rate\": 6.989697024251562,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:27:12,208 - MainProcess - INFO - Compressing to:conv1:(2, 25), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n",
      "2025-03-30 12:27:28,887 - MainProcess - INFO - finetuning:conv1:(2, 25), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.1258\n",
      "Epoch 1/3, Loss: 0.1270\n",
      "Epoch 2/3, Loss: 0.0479\n",
      "Epoch 1/3, Loss: 0.1366\n",
      "Epoch 2/3, Loss: 0.0463\n",
      "Epoch 2/3, Loss: 0.0484\n",
      "Epoch 3/3, Loss: 0.0359\n",
      "Epoch 2/3, Loss: 0.0505\n",
      "Epoch 3/3, Loss: 0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:38:15,089 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(16, 22), layer1.0.conv2:(16, 22), layer1.1.conv1:(32, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(25, 51), layer2.0.conv2:(51, 44), layer2.0.downsample.0:(16, 32), layer2.1.conv1:(32, 32), layer2.1.conv2:(57, 57), layer3.0.conv1:(51, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(44, 128), layer3.1.conv1:(64, 76), layer3.1.conv2:(64, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(76, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1523974,\n",
      "    \"flops\": 329849610,\n",
      "    \"accuracy\": 0.9906,\n",
      "    \"inference_time\": 0.17165110976832687,\n",
      "    \"compression_rate\": 7.337160607726903,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:38:15,228 - MainProcess - INFO - Compressing to:conv1:(2, 16), layer1.0.conv1:(32, 32), layer1.0.conv2:(22, 16), layer1.1.conv1:(35, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(64, 51), layer2.1.conv2:(51, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n",
      "2025-03-30 12:38:31,555 - MainProcess - INFO - finetuning:conv1:(2, 16), layer1.0.conv1:(32, 32), layer1.0.conv2:(22, 16), layer1.1.conv1:(35, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(64, 51), layer2.1.conv2:(51, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:39:52,490 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 16), layer1.0.conv1:(19, 16), layer1.0.conv2:(16, 19), layer1.1.conv1:(35, 22), layer1.1.conv2:(16, 19), layer2.0.conv1:(25, 32), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(19, 32), layer2.1.conv1:(32, 38), layer2.1.conv2:(32, 32), layer3.0.conv1:(57, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1450640,\n",
      "    \"flops\": 290343850,\n",
      "    \"accuracy\": 0.9904,\n",
      "    \"inference_time\": 0.18917328030693556,\n",
      "    \"compression_rate\": 7.708075056526774,\n",
      "    \"accepted\": true\n",
      "}\n",
      "2025-03-30 12:40:36,191 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(1, 19), layer1.0.conv1:(22, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(19, 48), layer1.1.conv2:(22, 22), layer2.0.conv1:(38, 44), layer2.0.conv2:(51, 38), layer2.0.downsample.0:(16, 64), layer2.1.conv1:(38, 32), layer2.1.conv2:(38, 32), layer3.0.conv1:(38, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(64, 64), layer3.1.conv2:(64, 76), layer4.0.conv1:(76, 128), layer4.0.conv2:(153, 128), layer4.0.downsample.0:(102, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(153, 128)\",\n",
      "    \"params\": 1597078,\n",
      "    \"flops\": 334417194,\n",
      "    \"accuracy\": 0.9908,\n",
      "    \"inference_time\": 0.1751598876499573,\n",
      "    \"compression_rate\": 7.001312396764591,\n",
      "    \"accepted\": true\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.0385\n",
      "Epoch 1/3, Loss: 0.1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:42:29,906 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 25), layer1.0.conv1:(19, 19), layer1.0.conv2:(16, 16), layer1.1.conv1:(16, 19), layer1.1.conv2:(16, 16), layer2.0.conv1:(16, 44), layer2.0.conv2:(32, 38), layer2.0.downsample.0:(25, 32), layer2.1.conv1:(32, 44), layer2.1.conv2:(44, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 89), layer3.0.downsample.0:(38, 76), layer3.1.conv1:(64, 64), layer3.1.conv2:(89, 76), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(64, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 153)\",\n",
      "    \"params\": 1530134,\n",
      "    \"flops\": 292237210,\n",
      "    \"accuracy\": 0.9915,\n",
      "    \"inference_time\": 0.1306201156284146,\n",
      "    \"compression_rate\": 7.307622731081069,\n",
      "    \"accepted\": true\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.0504\n",
      "Epoch 3/3, Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:48:27,144 - MainProcess - INFO - compressed_model:\n",
      "{\n",
      "    \"config_str\": \"conv1:(2, 16), layer1.0.conv1:(32, 32), layer1.0.conv2:(22, 16), layer1.1.conv1:(35, 16), layer1.1.conv2:(19, 16), layer2.0.conv1:(22, 38), layer2.0.conv2:(38, 32), layer2.0.downsample.0:(16, 44), layer2.1.conv1:(64, 51), layer2.1.conv2:(51, 38), layer3.0.conv1:(32, 64), layer3.0.conv2:(64, 64), layer3.0.downsample.0:(32, 64), layer3.1.conv1:(89, 76), layer3.1.conv2:(76, 64), layer4.0.conv1:(64, 128), layer4.0.conv2:(128, 128), layer4.0.downsample.0:(89, 128), layer4.1.conv1:(128, 128), layer4.1.conv2:(128, 128)\",\n",
      "    \"params\": 1528715,\n",
      "    \"flops\": 348779290,\n",
      "    \"accuracy\": 0.9899,\n",
      "    \"inference_time\": 0.09362038432159747,\n",
      "    \"compression_rate\": 7.314405889914078,\n",
      "    \"accepted\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import uuid\n",
    "\n",
    "\n",
    "num_workers = 4\n",
    "num_gpus = 1  # torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "results = []\n",
    "tried_count = 0\n",
    "accepted_models = []\n",
    "\n",
    "sensitivities = precompute_sensitivities(layer_dict)\n",
    "configs = generate_configs(layer_dict, sensitivities, num_cfg=500, alpha=1.0, beta=1.0)\n",
    "acceptance_threshold = ACCU_RQT * baseline_accuracy\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Submit tasks with device indices in round-robin\n",
    "    if num_gpus > 0:\n",
    "        futures = [executor.submit(process_config, config, 0) for config in configs] #- i % num_gpus) for i, config in enumerate(configs)]\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    results.append(result)\n",
    "                    \n",
    "                    if result['accepted']:\n",
    "                        accepted_models.append(result)\n",
    "                    \n",
    "                    tried_count += 1\n",
    "                    if tried_count % 10 == 0:\n",
    "                        logger.info(f\"Evaluated {tried_count} configurations, found {len(accepted_models)} accepted models\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in future processing: {str(e)}\")\n",
    "    else:\n",
    "        logger.warning('NO GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "280199f8-43db-452f-afc1-393324847cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 12:51:45,098 - MainProcess - INFO - Found 309 accepted models, saving top 10\n",
      "2025-03-30 12:51:45,099 - MainProcess - INFO - HTD experiment for resnet completed\n"
     ]
    }
   ],
   "source": [
    "# Save top 10 models\n",
    "if accepted_models:\n",
    "    accepted_models.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "    top_models = accepted_models[:10]\n",
    "    logger.info(f\"Found {len(accepted_models)} accepted models, saving top {len(top_models)}\")\n",
    "    \n",
    "else:\n",
    "    logger.info(\"No accepted models found\")\n",
    "\n",
    "logger.info(f\"HTD experiment for {MODEL_NAME} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f5033-f5bf-4ea6-a055-552ec877ab89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
